[
    {
        "title": "module_ai_plus_part1_王腾",
        "original_content": [
            "首先，为什么通用人工智能会在近两年受到如此大的关注，是什么让我们看到了实现通用人工智能的曙光呢？\n我想，随着计算量的增加而不断提升性能的大语言模型功不可没。让我们看到左下角这张图，该图的横轴是时间，而纵轴是困惑度（perplexity），它常用于反映大语言模型的能力，其值越低模型性能越好，而图中的圆圈大小则表示模型的训练计算量。不难发现，随着时间轴不断向右移动，圆圈越来越大，即AI模型的计算量不断增加，而与此同时，困惑度不断下降，表明模型的性能也在随之变好，这一趋势揭示了增大模型规模和计算量的潜在价值。\n\n现在，大家看到右下这张条形图，它展示了GPT-4在各种专业考试中的表现，不仅仅是与人类比较，更是和它的前代模型GPT-3.5相比较。可以看到，GPT-4在很多领域的表现已经超过了大部分的人类考生。这真是令人惊叹！除了专业考试以外，以ChatGPT、GPT-4为代表的超大规模语言模型已经被证明可以在众多类目丰富的任务中取得优越的成绩，让人们看到了实现通用人工智能的希望。这种成绩的背后，是模型设计的不断创新和计算资源的巨大投入。这种进步不仅是量的积累，更是质的飞跃。",
            "超大规模的预训练模型同样展现出了令人惊叹的能力和智慧，让我们来看两个例子。\n\n正如左侧的图片中，GPT-4能够理解并描述出这一场景的滑稽之处：一个庞大、过时的VGA连接器竟然被插进了一个现代智能手机的细小充电口。这个描述不仅准确，而且还透露出了它对人类幽默感的理解。\n\n同时，看向右侧的[视频](https://cloud.tsinghua.edu.cn/f/ee6f862bec9c4f099ef6/)，我们见证了Sora这样的视频大模型在视觉内容创作方面取得的深刻进步。无人机航拍视频的制作，通常需要专业的技能和创意，更需要对空间、方向、角度等概念的充分理解，而现在AI能够自主完成这样的任务，这标志着我们在迈向融合多感官的通用智能的路上迈出了一大步。",
            "说到此处，相信有不少同学会关心一个问题，当下的人工智能技术发展如此迅猛，迈向通用人工智能也是必然趋势，那么它究竟什么时候能够实现呢？\n\n为了回答这个问题，我们可以看一下来自这些知名AI企业、企业家和顶尖学者们的观点。为了得到更强大的人工智能，OpenAI组建了Superalignment（超级对齐）团队，目标是四年内能够实现“引导和控制比我们聪明得多的AI系统”。这是一个雄心勃勃的愿景，意味着在短短几年的时间内，人工智能将有可能在大量的任务上真正地超越人类。\n而Elon Musk则预测，AI在三年内就能写出像《哈利波特》那样好的小说，或者是发现新的物理学理论和新技术。这也体现出他对于AI发展出艺术创作、科学研究、新技术开发等比肩人类的高级能力抱有深切期待。\n图灵奖得主Yoshua Bengio、Geoffrey Hinton、姚期智等人在一篇合著论文中也指出，AI技术的进步速度令人震惊，在当前十年或下一个十年内，人工智能系统就有可能在许多关键领域超越人类，对此，我们必须认真对待这种可能性，并积极预防AI的发展所带来的风险与挑战。\n\n综合以上观点，我们不难发现，与人类比肩甚至超越人类能力的通用人工智能，已经不再是存在于科幻小说中的天方夜谭，而是很有可能在不久的将来被真正实现的。",
            "正如我们之前讨论“人工智能”的界定一样，通用人工智能的定义同样值得琢磨。\n\n通用人工智能的英语表述为Artificial General Intelligence，简称AGI，该词最早于1997年为物理学家Mark Gubrud所提出。他认为高级的通用人工智能，是那些在复杂度和处理速度上能够匹敌甚至超过人脑的AI系统。随着时间的推移，AGI 的概念已经扩展，不再局限于特定的实现机制或应用，而是指一种类似人类乃至超越人类的能力，包括学习、适应和解决问题的能力。正如OpenAI在其一篇博客中所阐述的那样，通用人工智能需要在绝大多数有经济价值的工作中，具备超越人类的能力，同时必须能够高度自主地运作。\n\n可以看到，AGI 的发展焦点已经转移到其普遍的应用和效用上，而不仅仅是技术本身。这种理念预示着我们正在朝着创造出真正能够在各种环境和情境中，以人类般的智能和适应性执行任务的机器迈进。这不仅对于技术领域是一个巨大的挑战，同时也为人类的工作方式、生活方式带来了前所未有的变革潜力。",
            "不过，要如何界定通用人工智能的实现与否，AI的能力强大到什么程度才可以算作通用人工智能，这些问题确实难以给出一个共识性的解答。为了更好地理解已有AGI的发展，Google DeepMind提出了一个系统化的分级方法，它旨在量化AGI进步的不同阶段。这个分级包括能力级别和自动化程度两个维度，有助于我们评估AGI的成熟度和应用范围。\n\n在能力级别上，起点是“无智能”，然后是“涌现”阶段，其能力相当于或略高于非专业人士。随着技术的发展，“能干”的AI至少能胜过一半的专业人员。再进一步，“专家”阶段的AI超过90%的专业人员，而“大师”级别的AI能力则超越了99%的人类专家。最终，“超人”级别的AGI将会超越所有人类的智能水平。我们现在所处的阶段大致处于“涌现”与“能干”之间。\n\n从自动化程度来看，起点是“无智能”。然后AGI从“工具”级开始，这是人类完全控制AI的阶段，然后是“顾问”级，AI在决策中发挥重要作用但仍需要人类主导。接下来的“合作者”级别，AI能与人类平等合作；“专家”级则是AI主导，人类仅提供必要的支持；最后，达到“智能体”级别，AGI可以完全自主运作。目前所处的阶段，大致在“工具”与“顾问”之间。\n\n这一分级体系的思想非常有用，它提供了一种框架来观察和评估AGI的技术进展，同时也为研究人员和工程师提供了明确的目标。",
            "看了之前那些问题呀，相信同学们已经有了不少想法，那就让我们先从最简单的问题开始看起吧，在我们的生活或者是专业学习中，人工智能有哪些应用，又有着怎样的地位。这些身边的例子会帮助我们理解人工智能技术的普及程度和它们所带来的便利。\n\n例如，在清华校园中，人脸识别技术帮助我们快速通过门禁，无需翻找校园卡；自动驾驶技术让图书馆的书籍能够自动送达，节省了我们的时间和精力；而在家庭环境中，智能家居助手能够理解我们的命令，控制家中的设备，提供方便快捷的服务。外卖和电商平台使用个性化推荐算法，让我们在海量商品中快速找到自己喜欢或需要的商品；搜索引擎则利用复杂的信息检索算法，帮助我们精准地找到所需信息。这些都是人工智能技术融入我们生活的具体例子。\n\n这些智能系统的背后，是AI领域学者和工程师的辛勤研究和创新，在他们的努力下，人工智能已经成为我们生活中不可或缺的部分，大大提高了人类社会运作的效率。当我们谈论人工智能的应用时，我们不仅是在讨论技术本身，更是在讨论这项技术如何与我们的生活、工作、学习相互融合，以及它们如何提高我们处理日常任务和复杂问题的能力。",
            "了解了人工智能在我们日常生活中的应用后，现在让我们来看看AI在更广阔领域的作用。在科学研究的前沿，人工智能同样变得至关重要，它不仅加速了既有知识的获取，还拓展了我们探索潜在新知的能力。\n我们不妨来聆听一下那些AI业界领军人物的看法，感受到他们对人工智能的期待。比如，创造ChatGPT的企业，OpenAI，其CEO Sam Altman认为，AI将极大提升每个人的生产力，包括顶尖科学家们，从而加速科学的进步，帮助我们掌握更多知识，发掘新的创意。DeepMind的CEO，Demis Hassabis，他认为AI最终的用途在于将科学加速到极致。Google的CEO，Sundar Pichai则认为，人工智能是人类进行的最为深刻的研究方向之一，其重要性甚至可能超过火和电的发现。\n\n这些观点描绘出了一个令人激动的前景：一个由AI驱动的世界，在这个世界中，信息获取和知识探索更为高效和深入。AI带来的技术革命不仅能提升我们社会运作的效率，更有潜力拓展人类的知识边界。\n作为人类智慧结晶的AI，将会在不远的将来帮助我们实现跨越性的进步。这个技术革命，就像火和电一样，将会成为推动人类社会发展的新引擎。所以，我们不仅要学习人工智能，还要思考如何利用它来推动人类文明的进步。",
            "当我们尝试理解人工智能时，就会发现它不仅仅是技术层面的概念。AI研究领域的学者们从多个角度探讨了这个概念，提出了不同的认识和理解。\n\n有的学者，比如Marvin Minsky，他是人工智能领域的先驱之一，他从“理性”的角度出发，将AI视为一种能够理性行动、解决复杂问题的系统。在Minsky看来，AI的本质在于执行那些需要智能才能完成的任务，而智能正是解决这些复杂问题的关键。另一种观点则是从“类人”的角度出发，如深度学习先驱之一、图灵奖得主Yoshua Bengio认为，人工智能就像是一种“聪明”的机器，可以进行学习、理解世界，并将所学知识应用到实际任务中，与人类行动非常相似。\n\n这些观点展现了学者们对AI的深层次认知，也指向了AI未来发展的重要方向：实现理性行动并解决复杂问题，以及发展出类似于人类的思维和认知能力。随着研究的不断进展，我们可以预见到人工智能在这些方向上会有更多的突破，进而在各个领域中发挥更重大的作用。",
            "正如你们可能已经意识到的，对于人工智能的定义确实存在一些差异。然而，尽管学术界对人工智能的精确定义尚未达成共识，我们还是有一个广泛接受的基本概念。\n\n人工智能（Artificial Intelligence），主要指的是由机器，特别是计算机系统所实现的智能系统。AI的核心追求是让机器能够模拟人类智能的行为，这包括了感知环境和在环境中采取行动以高效完成任务的能力。这些任务往往相对复杂，需要一定的人类智能和工作量才能精准完成。简单来说，AI旨在创造能够独立思考、学习知识和解决问题的机器，它们不仅仅按照预定的规则行动，而是可以通过学习和适应来增强其性能，不断进步以适应新的环境。这是一条既充满挑战也令人激动的探索之路。",
            "虽然人工智能作为一门学科被研究和重视，是在现代计算机技术出现并成熟以后。但事实上，对于这类能够自主思考和行动的机械的想象，在中西方的人类文明早期便已经悄然开始。接下来，让我们投身时光的洪流，从人类对人工智能的早期畅想开始，回溯AI的起源，以及其漫长坎坷的发展道路。\n\n早在古希腊时期的多部神话中，就记载着一位青铜巨人，其名为Talos，它全身由青铜铸就，所向无敌，一日之内能绕克里特岛三周，保护克里特岛免受入侵者的侵害。这也是西方典籍中已知最早的“机器人”。而在咱们中国古代的西周时期，也记载有一位“机器人”。《列子·汤问》中描述了这样一个故事，一位叫偃师的人给周穆王造了一个“偶人”（也就是人偶、机械人），它既会唱歌又会跳舞。在给周穆王表演的时候，它偷偷向周穆王左右侍妾抛媚眼。周穆王大怒，要杀偃师。偃师慌忙解释说，这是假人，不信拆开看看。拆开之后，周穆王发现，“偶人”是由革、木、胶、漆、白、黑、丹、青制成的，肝胆、心肺、脾肾、肠胃，筋骨、肢节、皮毛、齿发等都是假的。当周穆王把它的心拿出来，它就不能说话了，把肝拿出来，它就看不见东西了，把肾拿出来，它就不能走路了。如此看来，这个偶人极为高级，五脏与身体活动能力的对应关系，也体现了古人对人体的认识。偃师所打造的这个“偶人”，也是中国典籍中已知最早的“机器人”。\n\n尽管古时的技术与今日的人工智能相去甚远，但这些故事显露出人类对于创造可以自主执行任务、拥有智能的非生物实体的早期追求。无论是在东方还是西方，人们对于能够模仿人类行为的机械始终抱有深厚的兴趣和无限的想象。这些宏大而美好的梦想和理念，今日也化作了人工智能领域学者不断前进的动力与目标。",
            "说到人工智能的起源，我们就不能不提到艾伦·麦席森·图灵——他不仅是计算机科学的巨擘，也是人工智能领域的奠基人之一。1950年，图灵在他的开创性论文《计算机器与智能》中提出了一个著名的问题：“机器能思考吗？”他设想了一台会思考的机器，即所谓的“Thinking Machine”。图灵认为，这样的机器需要具备感知能力，它不仅要能够接收指令，还应能感知周围环境，包括视觉和听觉等感官信息，从而在没有人类干预的情况下，独立地做出决策。机器的“看”和“听”不仅限于复制人类感知，更关键的是要理解和处理收到的信息，从而实现真正的自主的智能。\n\n图灵的这些观点对我们今天所理解的人工智能有着深远的影响。他提出的思考机器的概念，实际上预见了当代智能系统所拥有的许多特性——包括学习、适应和处理复杂问题的能力。",
            "当然，图灵对于人工智能的贡献远不止于此。除了提出AI的早期概念以外，关于如何界定智能，他也同样有着自己的思考，著名的“图灵测试”便是他在《计算机器与智能》一文中所提出的，人工智能领域最具代表性的思想实验之一。它提出了一个标准，以判断机器是否具备人类智能。\n\n具体而言，测试者与被试者（被试者包括一个人和一台机器）隔开，测试者向被试者随机提出问题，并需要判定提供回答的是人还是机器。如果测试者无法以较高的准确率分辨出来对方的身份，那么被试机器便被认为具有人类智能。这一测试深度考验了机器理解和响应人类语言的能力，长期以来一直是人工智能研究中一个重要的理论基石和目标。\n\n然而，随着人工智能技术，特别是大语言模型如GPT-4的快速进展，一些学者开始质疑图灵测试是否还是一个充分的智能判定标准。顶尖的模型因为其惊人的语言生成和理解能力，让图灵测试的标准显得不够挑战性。这导致了对智能的定义和测试标准的进一步讨论，学界正在寻求更高标准，以更全面地评估AI的智能水平。但我们仍需要意识到，图灵测试的重要性不仅仅在于它为AI的智能评估提供了一个参照点，更在于它启发了关于智能本质的广泛讨论和思考。图灵对智能的深刻见解提醒我们，评估AI智能时，我们应考虑到智能的多个维度，包括逻辑推理、学习、适应、创造性和理解复杂概念等，正如今天我们在面对越来越高级的AI模型时所进行的讨论一样。",
            "“人工智能”作为一门真正意义上的学科诞生，是在达特茅斯会议上。这场会议在1956年举行，召集了一群有远见的科学家们，他们一同讨论了关于机器模仿人类学习和其他智能行为的可能性。这场会议定义了人工智能研究的基本议题，并预见了未来的研究方向。在会议上提出的议题，如使计算机使用语言、神经网络等，现在仍然是人工智能研究中最为活跃和关键的领域。例如，自然语言处理（NLP）技术正是从“让计算机使用语言”的议题中逐渐发展起来的，而今天的大型语言模型，则是NLP技术的最新成就。同样，神经网络作为当前大多数AI模型的基础架构，也在达特茅斯会议上被提出并讨论。那些参加会议的科学家，都为人工智能的发展做出了巨大贡献，其中，John McCarthy、Marvin Minsky、Allen Newell、Herbert Simon最终获得了计算机科学界的最高荣誉——图灵奖。\n\n这场会议不仅仅是学科发展的起点，更是一系列重大创新和突破的催化剂。它为人工智能科学家提供了一个集思广益、互相启发的平台。这一群科学家的远见和集体智慧，奠定了现代人工智能发展的基石，影响至深，使得原本只存在于科幻中的想法，转化为改变世界的现实技术。",
            "人工智能的发展历史就像一部跌宕起伏的史诗。AI首先作为一门学科在达特茅斯会议上诞生，使得1956年成为AI元年。紧接着，1957年，作为神经网络鼻祖的感知器算法被发明，它也曾一度被看作是人工智能向前迈进的关键技术。然而，历史的发展并不是一帆风顺，1970至1980年间，因为早期的翻译机和感知器的局限性，人工智能遭到了来自各界的批评，由此进入了AI发展史上的第一个“寒冬”，这是一个资金和研究兴趣都急剧减少的时期，大部分政界和学界人士不相信人工智能的潜力，而不愿投入资源进行研究。但如同凛冬将尽，春暖花开。1980年代，许多新的AI技术开始成熟，如多层神经网络和专家系统，它们重燃了人工智能的火花。到了1986年，BP、PDP等算法的提出为AI的发展注入了强大的生命力，时至今日，BP算法仍是我们高效训练深度神经网络的基础算法之一。不过，AI面临的挑战并未完全消失，1990至2000年间，随着日本五代机项目失败，人们对AI的热情满满退去，人工智能再次面临着资金和期望值的低谷。\n\n进入21世纪，随着深度学习的突破，人工智能开始在许多领域表现出它强大的潜力，这一次并没有陷入低谷，而是在2010年以后开始爆发。诸如AlphaGo、人脸识别等成功案例，都展示了人工智能技术的长足进步，人们对AI研究转化为实用价值的期望空前提高。\n\n这张时间线不仅仅是对过去的回顾，更是对未来的展望。每一次的低谷都为下一个高潮做准备，每一次的挑战都孕育着新的飞跃。如今，我们也正站在新的起点、新的高度上。AI大模型取得的突破，正在引领着AI技术快速地向更高处迈进。",
            "符号智能，也就是使用预定义的符号和规则表示知识，并基于此进行信息分析和推理的人工智能。符号智能曾一度主导AI领域，作为AI的早期范式，该技术在20世纪60到80年代左右取得了长足发展。在这个时期，像Noam Chomsky和Edward Feigenbaum这样的学者，分别在语言学和专家系统领域做出了重大的理论和实践贡献。Chomsky的语言学理论对于理解语言的结构和语言处理有着深远影响，而Feigenbaum在专家系统方面的工作则展示了如何将复杂的知识进行形式化的编码，使得计算机能够利用专家知识，在特定领域进行专家级的判断和决策。\n1997年，IBM的“深蓝”国际象棋程序击败世界冠军Garry Kasparov，这更是证明了符号智能能够在特定领域超越人类智能。这一里程碑事件不仅展示了计算机的巨大潜能，也引发了公众对AI能力和未来的广泛讨论。",
            "然而，随着时间的发展，符号智能的局限性也逐渐暴露出来，让我们来看一个专家系统的例子。如图所示，一个典型的专家系统由知识库和推理机构成。其中，知识库中涵盖了大量由专家手工总结的知识和规则，而推理机在接受用户的指令后，会从知识库中查询相关的知识，并经过推理算法生成最后的答案。例如，当询问“青蒿素抑制什么？”，专家系统会查找其知识库，找到与青蒿素相关的信息，表示“青蒿素”与“疟原虫”之间有“抑制”关系，因此经过简单推理，即可得到正确答案“疟原虫”。对于已经预编程和预设好的领域知识，这样的系统能够迅速而准确地给出答案。\n\n然而，专家系统，乃至整个符号智能的局限性就在于，它依赖的是事先定义好的知识和规则。但当遇到知识库没有的信息时，例如关于一个具体而未知的生物信息问题，它就无法提供答案。这种系统不能自行获取新知识，也不能处理未知类型的问题。此外，简单地扩充知识库并不能解决这一问题，一方面，知识难以被穷尽式枚举，另一方面，也并非所有知识都可以被形式化为知识库中的规则，知识的总结更需要耗费大量的人力，因此，我们亟需探索更加成熟、不依赖于预定义知识库的方法。",
            "在符号智能之后，我们迎来了针对特定任务的经典范式——专用智能。这一阶段的AI更加注重于在特定的任务上达到或超越人类的水平，通常依赖于数据驱动的机器学习方法，而非预先定义的规则。\n\n在这个时期，有几位学者的工作极具影响力。Judea Pearl，因其在因果推断领域的工作而知名，提出了概率图模型和贝叶斯网络，极大地推动了我们对机器如何模拟人类推理的理解，促进了数据驱动的机器学习的发展；Yann LeCun则是在深度学习领域做出了巨大贡献，尤其是通过卷积神经网络在多个计算机视觉任务上取得了性能的突破性进步，从而推动深度学习和数据驱动的范式走向新高位，成为当下通用人工智能的主流范式。\n\n在这一阶段，我们也同样看到了很多振奋人心的成果。例如，DeepMind团队将深度学习与蒙特卡洛树搜索相结合，创建了一个能够在复杂的围棋游戏中胜过世界冠军的程序AlphaGo。AlphaGo在2016年和2017年的比赛中分别战胜李世石和柯洁。这些成就显现了数据驱动的专用AI在复杂任务上的巨大潜力，并且对公众的认知产生了深远的影响，再次激发了对人工智能未来可能性的想象，提高了人们的预期。",
            "当然，专用智能也并非完美无缺，同样有着一定的局限性。具体来说，专用智能的方法往往需要高度特化的训练数据，这意味着模型通常在它们被训练执行的特定任务上表现出色，但却很难处理训练数据未覆盖的问题。\n举例来说，一个被训练用于中文、英语、法语翻译的专用模型，在翻译任务的数据上训练后，可能在被问及“计算机”的英文和法文对应词时回答得很准确，但当它面对一个数学问题如“1+2=？”时，则可能束手无策，因为他的训练数据根本没有覆盖任何的数学问题。这显示出专用智能的模型对训练数据的依赖性，无法泛化到数据分布外的问题。",
            "最后，我们来看看通用智能——这是一个致力于实现通用认知能力的范式，也是人工智能未来发展的一个重要方向，旨在创建能在广泛任务和环境中表现出色的AI模型。\n\n在这一方面，OpenAI的GPT，Google的BERT是前期具有代表性的工作。这些模型在大规模的文本语料上对模型做自监督的预训练后，只需要在专用数据上做少量的微调，即可于多种语言理解或生成任务上取得优异的表现，而无需再为每个任务都从头训练一个专用模型。\n2020年，OpenAI 发布的 GPT-3 则又是一个里程碑式的例子，这个模型拥有惊人的1750亿参数，展示了大语言模型能带来前所未有的能力，如语言理解、生成和任务适应性，初步揭示了增大模型的规模和数据量所能带来的能力飞跃。ChatGPT，作为 GPT-3 的后续版本，更是通过人类交互，可以处理多种复杂的问题。\n\n可以看到，自2018年起，我们见证了预训练语言模型的快速发展。这些模型不仅统一了文本任务的处理框架，而且在多项任务上取得了显著的性能提升。今天的通用智能模型正在快速进步，随着全球的团队投身到这一领域，AI的应用范围和能力势必会不断扩展。而在这些模型所体现出的丰富知识和通用能力背后，起到关键作用的，正是在海量通用域无标注数据上进行的自监督训练，而模型的巨大参数量则使得他们可以存储更多的知识。在不远的未来，我们可以期待更加强大、多功能和高度泛化的智能系统。这些系统不仅会在特定任务上表现出色，还能够跨任务和环境学习和适应，为我们的日常生活和工作带来革命性的变化。",
            "通用智能的范式之所以可以取得如此亮眼的成功，其核心优势在于可以利用大规模廉价可得的无标注训练数据，以及模型的大规模参数所带来的更加强大的知识学习和存储能力。以大语言模型为例，书籍、新闻、论文、报告，几乎任何的文本语料，在经过适当的筛选和清洗后，都可以拿来作为训练材料。在自监督预训练的过程中，大模型能够充分提取和利用海量文本数据中的模式，这些模式不仅包括语言的表面特征，而且包括文本中隐含的更深层次的结构和知识，使得模型能够在各个不同的领域中解决多种类型的问题。从基本的事实性问题（如“计算机的英文是什么？”），到具体的操作性问题（如“如何治疗疟疾？”），甚至数学计算（如“1+2=？”），都可以进行相应的回答，展现出了它们处理信息的强大能力。\n我们相信，未来的AI系统将更加强大，它们将不仅限于单一任务，而是能够跨领域进行学习和应用知识，向真正的通用人工智能迈进。"
        ],
        "recommend_content": [
            "第一小节我们将学习人工智能能力框架。",
            "为什么我们应该了解和学习人工智能？\r1.适应现代社会：AI 已深入我们的日常生活，如智能助手、推荐算法、自动驾驶等。理解 AI 的基本原理可以帮助非专业人士更好地适应这些技术。\r2.职业发展：AI 正逐渐渗透到各行业，如医疗、教育、金融、物流等。懂得 AI 的基础知识有助于提高职业竞争力。\r3.避免被误导：普通人若缺乏 AI 知识，容易被夸大的宣传或误导性信息影响。基本了解能帮助辨别信息真伪。\r4.创新与协作：非专业人士掌握 AI 能力可以更好地与技术团队合作，提出实际问题并共同制定解决方案。",
            "2024年8月，联合国教科文组织发布了一个专门面向学生的人工智能能力框架。这个框架旨在指导各国学生了解人工智能的潜力和风险，以便在教育和其他领域，人们都能以安全、道德和负责任的方式应用人工智能。\r人工智能正日益成为人们生活中不可或缺的一部分，因此将人工智能学习目标纳入官方学校课程，对于全球学生正确地使用人工智能至关重要。该框架强调对人工智能解决方案的批判性反思，在人工智能时代对公民责任的认识，终身学习所需的人工智能基础知识，以及要注重人工智能设计的包容性和可持续性。",
            "人工智能能力框架可以从四个维度来理解，每个维度都对应了AI素养的一部分，帮助我们全面构建面向未来的AI能力：\u000b以人为本的思维：这一维度强调在设计和使用AI工具时，首先要考虑人类的需求和福祉。我们要从批判性的角度思考AI是否有助于人类的长远发展，是否尊重环境和生态系统的可持续性。这种“以人为本”的思维有助于我们在技术进步的同时，保持对人类社会整体利益的关注。\r人工智能伦理：AI的应用并不仅仅是技术问题，还涉及深刻的社会伦理问题。这个维度要求我们培养思考AI对社会道德和人类生活的影响，比如隐私保护、公平性和责任问题。通过学习AI伦理，我们可以更好地理解如何在不同情境下做出道德的技术决策。\r人工智能技术和应用：在这个维度中，我们需要掌握使用特定AI工具所需的技能，并能将这些技能应用于实际任务中。这里不仅仅是学习工具的操作，而是理解AI如何帮助我们解决问题，提高工作和学习的效率。\r人工智能系统设计：这个维度涵盖了设计和构建AI系统的全过程，包括问题定义、系统架构设计、训练、测试以及优化。它关注的是如何从零开始构建一个AI系统，这对未来想从事AI技术开发的同学尤其重要。\r这四个维度共同构成了人工智能能力的整体框架，从思维方式、伦理观念到技术应用和系统设计，全方位提升我们的AI素养。希望大家能从中找到自己需要重点发展的领域，在AI的学习和应用中打下坚实的基础。",
            "在人工智能能力框架中，除了刚才提到的四个内容维度，还有三个认知层次，帮助我们更有次序地培养AI素养。这三个层次分别是理解、应用和创造。\r理解认知层次，我们需要对AI的基本概念、伦理问题以及技术方法有清晰的理解。这包括AI的工作原理、可能带来的社会影响，以及不同AI工具的用途和限制。通过理解，大家可以从更全面的视角看待AI，知道它是什么、能做什么、不能做什么。\r应用层次强调的是将AI知识付诸实践。理解AI只是第一步，掌握如何操作和应用它才能真正让AI为我们所用。在这个层次，大家将学习如何在不同情境下有效地使用AI工具，比如完成文献检索、数据分析，或是其他与学习、科研相关的任务。\r创造是最高层次的AI能力素养，它要求我们不仅能应用AI工具，还能创造出新的AI应用，或是影响AI的发展方向。成为AI领域的创造者意味着我们在使用AI的同时，也在推动技术的进步，甚至参与到新的AI工具或系统的设计中。\r这三个认知层次形成了一个由浅入深的学习路径：从基础知识的理解，到熟练的应用，最后达到创新性的创造。希望大家在未来的学习过程中，可以尝试遵循此次序，稳步地提升AI素养。",
            "在这张表格中，我们可以看到人工智能能力框架的四个内容维度是如何分布在理解、应用和创造三个认知层次上的。这种结构让我们更清晰地理解在每个维度上如何逐步提升自己的AI素养。\r首先是以人为本的思维上，我们要理解人类的主体性，认识到AI技术应服务于人类的需求。在应用AI时，我们要承担起人类责任，确保AI的使用符合伦理要求。在创造层次，大家应具备“AI时代公民”的身份意识，积极参与到AI相关的社会活动中，以更高的社会责任感面对AI的发展，造福人类更美好的生活。\r在人工智能伦理素养上，学习和掌握具体的伦理概念，理解AI在使用中可能带来的伦理挑战。在实际使用AI时，要做到安全且负责任地使用，避免潜在的负面影响。大家可以通过设计和开发符合伦理标准的AI系统，把伦理价值嵌入到技术中。\r在人工智能技术和应用素养维度，理解层次是掌握AI的基础知识和原理，为应用AI工具打下基础。应用层次是掌握AI的应用技能，将理论转化为实践，真正让AI帮助自己和他人解决实际问题。创造层次是能够独立创造AI工具，甚至开发出新的应用场景，实现技术创新。\r最后人工智能系统设计维度，首先在理解层次要学会界定问题的范围，知道AI系统的边界在哪里。\u000b其次在应用层次掌握系统架构设计的技能，例如算法和编程语言，能够设计出符合需求的AI系统。最后在创造层次，我们要能够迭代并反馈，通过持续改进，使AI系统更加完善。\r这个表格不仅展示了AI能力素养的多维度，也指出了从初学到精通的进阶路径。通过这样的学习框架，大家可以清晰地制定自己的学习目标和计划，从基础理解到高阶创造，逐步提升AI素养，最终在不同层次上都能实现突破。为了让大家更容易理解这12个能力素养目标，接下来我们讲逐一讲解。",
            "在“以人为本的思维”这一维度中，首先要理解的是人类主导性。在使用人工智能时，我们要意识到AI由人类主导，理解人类在AI控制中的重要性，以及失控可能带来的后果。这种认识帮助我们保持对AI的控制，确保技术应用符合人类的长远利益。\r这里我们有一个关于智能推荐选课系统的例子。某学校推出了一个智能系统，根据学生的学习偏好和需求自动推荐课程。虽然这个系统带来了方便，但系统仍会提示对于重要的选课决策，要多方获得信息验证做出判断。在这个过程中，学生逐渐认识到，AI可以辅助决策，但最终的决策权仍然应该掌握在人类手中。\r这个案例展示了AI在提高效率的同时，仍需人类的监督和指导。即使技术能够做出预测和建议，我们也需要理性思考，确保选择的结果符合自己的实际需求。这就是“以人为本”的重要性，它提醒我们，技术是工具，人类才是决策的主体。",
            "在“以人为本的思维”维度的应用层次，我们要特别关注人类责任。当我们使用AI进行高风险决策时，比如在招聘或金融领域中，AI带来了便捷性和效率，但我们也要承担相应的法律和伦理责任。任何重要决策都不应完全依赖AI，而应由人类进行监督和最终把关。\u000b例如，在某公司中，AI系统被用于筛选求职者，以提高招聘效率。然而，一些应聘者认为该系统存在不公平现象，导致一些有潜力的候选人被错误淘汰。公司意识到AI可能存在偏见，因此决定引入人工审核环节，以确保招聘过程中的公平性。\r这个例子提醒我们，即使AI在许多任务中表现优异，我们也不能忽视其可能存在的局限性。人类在AI系统设计和使用中的责任不可替代，特别是在涉及人类利益的领域，更需要严谨和负责任的态度。AI是我们的工具，但最终的判断和判断后的责任后果依然需要人类来承担。",
            "在“以人为本的思维”中，我们不仅要承担人类责任，还需要具备人工智能时代的公民身份。这意味着我们要批判性地理解AI对社会的影响，推动AI的负责任和包容性应用，并在学习中实现自我价值。这一身份要求我们关注社会责任，认识到AI不仅是技术工具，更是影响社会结构和公平的力量。\r例如，在某学校的“AI透明度”倡导活动中，学生们发现政府部门在使用AI进行社会福利分配时缺乏透明度，可能导致不公平。为了改善这种情况，他们组织了一场活动，撰写公开信呼吁政府部门提高AI系统的解释性和透明度，确保社会福利分配的公平性，同时还讨论了如何进一步提升AI在公共领域的应用。\r这个案例展示了“AI公民”的角 色——主动参与和推动AI在社会中的负责任使用。作为AI时代的公民，我们不仅要使用AI，更要确保其应用符合社会价值，促进公平和包容。这种公民身份让我们在AI技术发展中扮演积极的角色，用批判性的眼光推动技术进步，实现社会福祉。",
            "在人工智能伦理的维度中，首先要理解的是具体化的伦理，即对AI关键伦理问题的基本理解。这些问题包括AI对人权、社会正义、包容性、公平性以及气候变化等方面的影响。AI的应用可能会引发伦理争议，因此理解这些问题有助于我们在使用AI时做出更加负责任的选择。\r例如，在环境科学课程中，老师介绍了AI在预测气候变化中的应用。然而，同学们发现，一些AI模型的数据主要来源于发达国家，忽视了欠发达地区的数据。这种数据偏见可能导致气候政策建议缺乏全球视角，影响问题解决的公平性。通过讨论，大家逐渐认识到数据偏见对气候变化议题的潜在影响，明白了在AI应用中实现公平的重要性。\r这个例子表明，在使用AI进行数据分析和预测时，我们要警惕数据来源的广泛性和代表性，避免因偏见而影响决策的公正性。理解这些伦理问题，帮助我们在未来的AI设计和应用中，时刻关注社会的整体利益和公平性。",
            "在“人工智能伦理”维度的应用层次，我们强调安全且负责任的使用。这意味着在使用AI时，不仅要遵守伦理原则，还要确保符合法律规定。特别是涉及数据隐私的问题，我们要意识到可能存在的风险，确保数据的使用得到知情同意，从而保护自己和他人的安全。\r例如，某学校医院推出了一款健康管理App，要求同学们上传个人健康数据。小明在使用前仔细阅读了隐私政策，发现这些数据可能会用于研究。出于隐私保护的考虑，他决定只分享必要的信息，并提醒朋友们注意数据隐私。这种做法体现了他对数据隐私的重视，负责任地使用了AI应用。\r这个例子说明了在AI技术普及的今天，个人数据的保护变得尤为重要。我们在享受AI带来的便捷时，也要承担保护数据隐私的责任，做到合理分享、谨慎授权。通过这种方式，我们可以在最大限度地利用AI的同时，确保自身和他人的隐私和安全。",
            "在“人工智能伦理”维度的创造层次，强调通过设计体现伦理。这意味着在AI工具的设计、开发和使用的每个环节中，从一开始就融入伦理考量，确保AI产品在整个生命周期内符合伦理和法律的要求，从而提出相关的规范调整建议。\r例如，在某校的计算机系团队开发校园语音助手的过程中，团队发现对某些口音的识别效果不佳。为了提升工具的包容性，他们收集了不同口音的数据进行训练，确保语音助手能够准确识别多样化的声音，从而公平对待所有用户。通过在设计阶段就融入伦理考量，他们确保了AI工具的无偏见性和包容性。\r这个案例说明了如何在设计阶段就将伦理考虑融入AI产品，确保技术公平、包容地服务所有人。这提醒我们，在AI的创造过程中，不仅要关注技术功能，还要重视道德规范的实践，让AI真正为所有人服务。",
            "在人工智能技术和应用的维度中，理解层次的重点是掌握人工智能基础。这包括构建AI的基本知识和技能，理解AI概念与社会和日常生活的关联，以及AI的伦理原则。这种基础知识帮助我们具体化“以人为本”的思维模式，使我们能够更好地理解AI的作用与影响。\r例如，在某校的新生入学教育中，学校举办了一场关于人工智能基础的讲座。老师通过校园里的实际例子，如智能图书馆的自动推荐系统、食堂的AI结算台、宿舍的智能电力管理等，向同学们介绍了AI的基本概念。小明听后感叹道：“原来我们每天都在接触AI啊！”他意识到，人工智能并不遥远，而是与日常生活紧密相关。\r这个案例展示了AI在校园生活中的广泛应用，使学生们了解到AI如何融入他们的日常生活。掌握这些基础知识有助于我们理解AI的多样性，也为未来进一步学习和应用AI打下扎实的基础。AI不再是抽象的概念，而是成为我们生活中无处不在的助手。",
            "在“人工智能技术和应用”维度的应用层次，强调的是应用技能。这意味着我们需要理解数据、AI算法和编程，掌握可迁移的应用技能，并且能批判性地评估各种AI工具、编程库和数据集的使用价值。\r例如，某校举办了一个面向全校同学的AI编程工作坊，小华虽然是物理系的学生，但也报名参加了。在这个工作坊中，他学习了如何使用Python编程语言，掌握了处理简单数据集的技能，并且初步了解了机器学习模型的训练过程。\r这个案例展示了跨学科应用技能的重要性。即使没有计算机背景，通过这样的工作坊，同学们也可以掌握基本的AI编程技巧。这种技能的培养不仅有助于理解AI的应用原理，还为未来在更多领域应用AI打下了基础。通过学习编程和数据处理，同学们可以更好地适应科技驱动的社会，并成为更具竞争力的复合型人才。",
            "在“人工智能技术和应用”维度的创造层次，强调的是创建人工智能工具。这一层次要求我们深入理解并应用AI知识，能够根据具体需求定制现有工具或开发新的AI应用。同时，在设计过程中要融入以人为本的思维和伦理考量，评估AI资源的适用性，具备团队合作和沟通能力，以确保AI工具的实用性和用户友好性。\r例如，小李发现许多新生在校园里迷路，便决定和同学们一起开发一款智能导航App，帮助新生适应校园生活。在团队合作中，他们各自发挥特长，成功地将AI应用于任务导向的导航工具中。这款App不仅为新生提供了便捷的导航服务，也让他们更快地融入校园生活。\r这个案例展示了如何通过创造性思维将AI技术转化为实用工具，从而解决实际问题。通过这种实践，同学们不仅提升了自己的AI技能，还学会了在团队中合作，设计出符合用户需求的AI工具。这种创造性应用，不仅帮助了他人，也使他们自己在AI技术领域获得了宝贵的经验。",
            "在人工智能系统设计的维度中，理解层次的关键是问题范围界定。这一步骤包括审视AI是否适用于特定情境，明确问题的边界、目标和约束，获取必要的知识和规划技能，并评估AI技术的适用性。同时，还需要明确数据需求，并制定测试和反馈指标。\r例如，在某学校中，宿舍楼的用电量在某些时段急剧增加，导致局部电力不足。于是，有同学建议利用AI来管理用电分配。小李和同学们在讨论中提出了几个关键问题：“我们真的需要一个AI系统吗？问题的边界在哪里？” 他们明确了目标，即解决宿舍用电高峰期的负载问题，同时考虑了预算、技术可行性等因素。经过评估，他们设计了一个基于AI的系统，优化电力负载分配，使电力分配更加精准，便于提前预测用电情况，从而缓解电力压力。\r这个案例展示了在AI系统设计初期进行周全规划的重要性。通过仔细定义问题和目标，同学们能够更有效地利用AI解决复杂问题。在设计系统时，理解问题的范围和目标，不仅有助于确保AI应用的有效性，也能提升AI项目的可实施性。",
            "在“人工智能系统设计”维度的应用层次，核心在于架构设计。设计一个可扩展、可维护的AI系统架构需要基本的方法和技术技能，涵盖数据层、算法、模型和接口的配置。架构设计不仅需要跨学科的知识，还需熟练使用数据集和工具来构建系统的原型。\r例如，在智能校园用电管理系统的项目中，小李的团队通过搭建一个可扩展的系统架构来解决校园宿舍的用电高峰问题。首先，他们设计了数据层，用于收集宿舍的实时用电数据；接着，设计了算法和模型，通过预测用电高峰来优化电力分配；最后，他们开发了用户接口，方便管理人员查看用电数据和预测结果。通过将物联网传感器与AI建模工具结合，他们成功构建了一个原型系统，能够高效监控和管理校园宿舍的用电情况。\r这个案例展示了AI系统架构设计的全过程，从数据收集到模型应用，再到接口开发。通过这种方式，团队成员不仅掌握了AI系统的搭建，还积累了跨学科的协作经验，为未来的系统开发奠定了基础。",
            "在“人工智能系统设计”维度的创造层次，我们需要关注迭代和反馈。这一阶段包括评估AI模型的适用性和影响，通过数据和用户反馈优化系统，并改进算法。这种基于反馈的迭代流程有助于减轻AI可能带来的负面影响，同时提升系统的适应性和稳定性。\r例如，在智能校园用电管理系统投用后，小李团队收集了用户反馈和用电数据，评估AI模型的实际效果。他们发现，系统对部分突发情况的响应不够迅速，于是改进了算法，提高了预测电力需求的准确性。同时，他们还考虑到学生日常生活的需求，限制不必要的用电设备，确保系统对校园环境的适应性。\r小李团队还积极与AI社区交流，借鉴其他研究者的优化建议，进一步提升了系统的稳定性，使得系统能够应用于更多场景，并有效节约了能源。这种不断优化的过程，展示了如何在实践中完善AI系统，通过反馈和迭代，实现更高效的能源管理和资源利用。\r这个案例说明了AI系统设计的动态特性，反馈和迭代帮助我们持续改进AI工具，从而更好地满足用户需求并实现可持续发展。",
            "除了联合国教科文组织，其他机构，例如美国非盈利组织“数字承诺”（Digital Promise），也制定了一个人工智能素养框架。这一框架围绕“理解”、“评估”和“使用”三大核心步骤展开，通过这些步骤，帮助我们成为负责任的AI用户。\r感兴趣的同学们可以在课后查阅参考文献，自主学习。"
        ],
        "recommend_reason": "该候选内容片段详细讲述了人工智能能力框架的基础知识，这与学生需要获取AI基本概念的短期目标紧密相关。内容的理解层级与学生当前的认知投入水平匹配，同时也能为学生做好掌握人工智能通用性评估这一长期目标的基础。在逻辑上，该教学片段可帮助学生更好地理解AI如何与他们的生活和职业相关联，激发学生对课程内容自主控制的动机，以及对技术进步带来的影响力的关注。",
        "adaptation_result": {
            "start_speech": "同学，接下来我们从刚才谈到的通用人工智能发展出发，来学习如何通过人工智能能力框架来提升我们的AI素养。",
            "refined_scripts": [
                "第一小节我们将学习人工智能能力框架，帮助我们更好地理解AI如何与生活和职业相关。",
                "为什么我们应该了解和学习人工智能呢？第一，适应现代社会：AI已深入我们的日常中，如智能助手、推荐算法和自动驾驶。掌握AI的基本原理可以使同学们更好地适应这些技术。第二，职业发展：AI逐渐渗透各个领域，如医疗、教育、金融和物流。了解AI基础知识有助于提高同学们的职业竞争力。第三，避免误导：缺乏AI知识，容易受夸大宣传影响。基本了解AI能帮助辨别信息的真伪。第四，创新和协作：掌握AI能力可更好地与技术团队合作，共同解决实际问题。",
                "在2024年8月，联合国教科文组织发布了一项专门面向学生的人工智能能力框架，目的是帮助同学们理解人工智能的潜力和风险。该框架强调安全、道德和负责任地使用人工智能的重要性，帮助全球学生在教育和其他领域正确使用AI。通过批判性反思AI解决方案和公民责任的认知，同学们可以更好地理解终身学习中AI基础知识的作用及其对社会和环境的影响。",
                "人工智能能力框架可以从四个维度进行理解，其中每个维度都代表了一部分AI素养，帮助我们全面构建面向未来的AI能力：以人为本的思维：设计和使用AI工具时优先考虑人类需求和福祉，关注可持续发展。人工智能伦理：不仅是技术问题，它涉及社会道德，包括隐私、公平和责任，帮助我们做出更为合乎道德的技术决策。人工智能技术和应用：掌握AI工具使用技能，了解如何提高工作效率。人工智能系统设计：从零构建AI系统，对技术开发兴趣浓厚的同学尤为重要。这四个维度融合使我们能全方位提升AI素养，找到需重点发展的领域。希望同学们在学习中打下坚实基础。",
                "在人工智能能力框架中，除了四个内容维度，还有三层认知水平帮我们培养AI素养：理解、应用、创造。理解层次要求同学们清晰理解AI的基本概念、伦理问题及技术方法，比如AI的工作原理、社会影响及工具用途和限制。通过理解，全方位看待AI。应用层次转向实际操作，掌握在不同情境中使用AI技巧，让AI服务自己。创造层次则要求不仅掌握应用，更能创造新AI应用，推动技术进步。这三个层次构成了一条由浅入深的学习路径，从基础理解到熟练应用，最终达到创新，帮助同学们提升AI素养。",
                "在这张表格中，我们可以看到人工智能能力框架的四个内容维度如何分布于理解、应用和创造三个认知层次上。这种结构让我们清晰理解在每个维度上如何逐步提高AI素养。首先，在以人为本的思维上，理解阶段需认识到AI服务于人类需求。应用层次则要求承担人类责任，确保AI符合伦理。在创造中，应抱有AI时代公民意识，积极参与社会活动，推动AI发展。人工智能伦理上，需掌握伦理概念，理解使用AI的伦理挑战，并在实际中做到安全负责。在技术应用维度，需掌握AI的基本知识，应用技能解决问题，最终能独立开发工具。最后，系统设计维度上，要学会界定问题从理解开始，应用基本技能设计算法与程序，创造中则强调持续改进，确保系统完善。这种架构从初学到精通引导同学制定学习计划，实现突破。",
                "在“以人为本的思维”中，第一要务是理解人类主导性。AI由人类主导，理解这一点帮助我们保持对技术的控制，确保应用利于人类长远利益。比如，某智能选课系统辅助学生选课，但最终决策仍应由人做。AI提高效率，但人类决策是关键。技术是工具，人类是主体。",
                "在“以人为本的思维”维度的应用层次，我们特别关注人类责任。在高风险领域使用AI时，如招聘或金融，尽管效率提高，人类需监督并做最终把关。某公司用AI筛选求职者，但引入人工审核环节确保公平性。即便AI表现优异，责任仍在人类，特别涉及人类利益时尤为如此。AI是工具，但责任需人类承担。",
                "在“以人为本的思维”，我们不仅要承担责任，更需拥有人工智能时代的公民身份。这要求我们批判性理解AI的社会影响，促其负责任应用。某学校组织AI透明度活动，呼吁政府使用AI分配福利时提高透明度，保障公平。AI公民角色需主动推动技术符合社会价值，促进公平和包容。",
                "在人工智能伦理的维度中，理解具体问题很重要。AI可能引发人权、公平等争议，理解这些问题帮助我们做出负责任的选择。比如，在课上了解到AI预测气候变化中的数据偏见问题，认识到公平数据源的重要性。理解这些伦理问题帮助我们关注社会整体利益和公平性。",
                "在“人工智能伦理”维度的应用层次，确保使用安全且负责任。遵守伦理原则和法律是关键。学校推出健康管理App，小明注意到隐私政策并谨慎分享数据，重视隐私。享受AI便捷同时，保护数据隐私至关重要。",
                "在“人工智能伦理”维度的创造中，设计时融入伦理考量。在开发语音助手时，团队改善识别不同口音的能力，确保公平。伦理考量贯穿设计全过程，确保产品无偏见和包容性。",
                "在人工智能技术和应用中，理解基本知识帮助我们应用AI。通过新生讲座发现，生活中充满了AI的应用，如自动推荐和智能管理。掌握基础有助于我们理解AI多样性。",
                "在技术应用中，重点在于掌握应用技能。通过编程工作坊，物理系的小华学会了Python并处理数据集。跨学科学习技能对未来非常重要。",
                "在创造层次，强调创造AI工具。小李为新生开发智能导航App，解决他们在校园中迷路问题，让AI成为实用工具。",
                "在系统设计维度，明确问题范围是关键。学校用电管理系统的设计便是通过明确目标、评估条件，优化电力分配的成功案例。",
                "在系统架构设计时，构建可扩展的系统需跨学科知识。小李团队成功设计了用电管理系统，实现了数据收集到用户界面开发的全过程。",
                "在创造层次中，我们应关注迭代反馈，优化AI系统。小李团队在用电管理系统中积极反馈与调整，确保系统适应性与稳定性。",
                "除了联合国教科文组织，美国“数字承诺”等机构也制定了人工智能框架，帮助同学们成为负责任的AI用户。课后同学们可以查阅参考文献。"
            ],
            "end_speech": "同学，掌握了这些AI能力框架知识后，期待你们在学习中能更自信地驾驭AI，为未来的职业和生活打下坚实的基础。"
        }
    },
    {
        "title": "module_ai_plus_part3_周宛烨",
        "original_content": [
            "大语言模型虽然能回答“如何攀岩”这样的问题，却无法自己进行实际的攀岩。这是因为它们缺乏对现实物理世界的理解。要让大模型理解物理世界，其中一个方法是将物理信息转换为文本形式输入给它，但这会非常复杂且不精确。在自动驾驶的应用中，模型需要处理实时捕捉到的图像数据、雷达传感信息以及车辆的速度和方向等多种模态数据。通过融合这些不同类型的信息，多模态智能可以更全面准确地理解复杂的现实场景，从而在实际应用中进行更好的决策。",
            "那么，如何让一个大模型理解物理世界呢？一个可能的做法是将物理世界的信息完全转换为文本的形式，再输入给大语言模型进行理解和分析。但是，使用纯文本描述复杂的现实物理世界同样存在许多挑战。\n\n比如，在自动驾驶的场景中，我们需要将街道上的每一辆车的位置和运动状态输入给模型，以便它能够进行正确的决策。\n\n例如，屏幕上的这张街道图片中包含了非常丰富的信息：每辆车的位置、行人的移动、交通信号灯的状态等等。这些信息如果仅用文字来描述，会非常繁琐并且难以精确。比如，如果光靠文字来描述其中一辆车的位置及其运动状态，就需要大量的描述性语言，而对于整张图片来说，还包含了每辆车的颜色、位置、姿态、不同车辆之间的关系等等，这导致想要完整描述一张图片所需要的文字可能是无穷无尽的。\n\n因此，为了让大语言模型更好地理解和处理物理世界的信息，它们需要能够接收和处理更多模态类型的输入，不仅仅是文本，还包括图像、音频和各种实时传感数据。例如，在自动驾驶中，模型需要能够实时处理摄像头捕捉到的图像数据、雷达和激光雷达的感应数据，以及车辆的速度和方向等信息。\n\n通过这些多模态输入，大语言模型才能更准确地理解复杂的现实场景，从而在实际应用中做出更好的决策。这也说明了多模态人工智能的重要性，因为它能够将不同类型的信息融合在一起，提供更加全面和精确的分析和判断。",
            "实际上，多模态人工智能已经深深融入我们的生活，极大地提升了日常活动的智能化和便捷化。让我们来看几个具体的例子：\n\n首先是辅助驾驶系统，它通过处理视觉和雷达数据来增强道路安全和驾驶体验。这不仅能帮助我们更好地观察周围环境，还能预判潜在的危险，从而避免交通事故。\n\n再比如一键路人消除技术，这种图像编辑技术让我们在拍摄完美照片时变得更加容易。只需点击一下，就可以轻松去除不需要的背景人物，让照片更干净、更专业。\n\n智能家居系统则通过多模态理解和控制，例如视觉、听觉和温度感应，提供了高度定制化的家庭便利和控制。无论是调节室内温度、控制灯光，还是管理家用电器，智能家居系统都能让我们的生活更加舒适和高效。\n\n拍照购物结合了物体识别技术，使我们可以通过拍照来搜索和购买商品。只需用手机拍下物品的照片，系统就能识别出物品并提供购买链接，极大地简化了购物流程。\n\n最后是语音助手，它们通过解析语音命令来提供信息和执行任务。例如，我们可以通过语音助手设置提醒、播放音乐、查询天气等，极大地方便了我们的日常生活。\n\n这些例子展示了多模态人工智能如何在我们生活的各个方面发挥作用，赋能我们的日常活动，使生活更加智能化和便捷化。",
            "在这张幻灯片中，我们展示了一个强大的通用多模态模型——GPT-4V。这个模型在感知世界和细粒度理解方面具有显著的优势。GPT-4V结合了图像理解和文本推理，展现了图文交替输入与时序理解的能力。这些多模态能力使得GPT-4V在实际应用中表现出极大的灵活性和实用性，特别是在智能助手和机器人控制等领域。\n\n首先，我们来看GPT-4V的视觉能力。它能够识别并理解图像中的细节，比如识别出图片中自行车的特定组成部分的名称，或者在图片中找到并识别特定的文字。这种细粒度的理解能力使得GPT-4V能够处理复杂的视觉任务，如识别收据上的税费信息，并将其转换为有用的数据。\n\n接下来是图文交替输入与时序理解能力。GPT-4V不仅能理解单个图像，还能根据一系列图像进行时间上的预测。例如，通过观看一段视频片段，模型可以预测接下来可能发生的事件。这对于需要连续理解和决策的应用场景，如体育比赛分析或烹饪指导，都是非常有价值的。\n\n在实际应用方面，GPT-4V已经展现了不俗的潜力。例如，它可以作为智能助手，帮助用户搜索信息或完成任务。视频展示的是利用GPT-4V实现[网页浏览](https://cloud.tsinghua.edu.cn/f/a6d49b4143334e0b92d3/)的效果，用户仅需输入一个指令，这个智能助手就可以自动进行网页的理解和操作，达到用户的目标。此外，[在机器人控制领域](https://cloud.tsinghua.edu.cn/f/78dcbafa7ae14087b50a/)，也有工作利用GPT-4V的视觉理解能力让一个机械臂能够根据自然语言的指令执行拿取特定的物品的操作，展现了理解并执行复杂的指令。这种能力使得机器人在家庭和工业环境中都能发挥更大的作用。\n\n总之，GPT-4V展现出了强大的多模态理解能力，让人工智能在多模态交互和理解方面迈出了重要的一步。",
            "在理解物理世界之外，近期出现了可以进一步模拟物理世界的强大多模态生成模型——Sora。Sora模型的出现离不开我们刚刚所介绍的GPT-4V模型。Sora模型的产生借助了GPT-4V的强大理解能力，对大规模的视频数据进行了进一步的理解处理，从而训练得到了具有强大的视频生成能力的多模态模型，甚至涌现出了一定的模拟物理世界的能力。\n\n它有什么特别之处呢？首先在于Sora模型在生成视频内容时，能够保持时空和对象的一致性。这是什么意思呢？举个例子，在这个Sora生成的[狗狗视频](https://cloud.tsinghua.edu.cn/f/2e4a8365ad244e72b3cb/)中，斑点狗在被经过的行人遮挡之后再次出现的时，我们能够看出这只狗在遮挡前后是同一只狗，就像真实世界中一样。另一方面，它所生成的视频还能够模拟真实世界的复杂交互，比如视频中[老人吃汉堡](https://cloud.tsinghua.edu.cn/f/b4d7b124c12d47b49245/)的过程，老人的手与汉堡接触时形变，以及咬汉堡时产生的形变，都与真实世界中的情况非常相似。这两种特性让Sora生成的视频看起来非常自然、连贯。\n\n同时，从这个对比视频中我们可以看到，在输入给不同模型相同的生成指令时，Sora模型能够生成时间更长的视频，同时生成视频的自然度和连贯性上都明显更好。\n\n通过提供高度真实且动态的视频内容，Sora不仅可以推动视觉艺术的发展，还为很多实用应用开辟了新的前景。比如说，在影视制作、虚拟现实、教育培训等领域，Sora都可以发挥重要作用。可以说，Sora把AI技术在视觉艺术和实用应用中的前景推向了一个全新的高度。",
            "除了视觉上的突破，在声音模态，同样出现了强大的音频生成模型，它就是Suno。Suno 是一个革命性的音乐生成模型，将 AI 技术与创意艺术完美结合。它能够根据用户的文本提示，创作出具有广播质量的个性化音乐。不管用户喜欢什么样的音乐风格，或者使用中英文进行提示，Suno 都能理解并创作出与之相匹配的音乐作品。\n\n这段播放的音频展示了用户输入了周杰伦《夜曲》的歌词之后，Suno 基于这些输入，创作出的一首全新的[音乐作品](https://cloud.tsinghua.edu.cn/f/ce1f013ace1844e793cd/)。Suno 的技术进步，也使得音乐创作变得更加简便和个性化，为音乐爱好者提供了一个实现创意的新平台。\n\n通过访问 Suno 网站，用户可以亲自探索和体验这款工具的强大创作潜力。无论是想创作一首新的流行歌曲，还是创作一首轻音乐，Suno 都能满足你的需求。结合视觉理解大模型等其他的理解工具，用户甚至可以为一个视频创作与它的意境相一致的背景音乐。\n\n总之，Suno 不仅简化了音乐创作的过程，还极大地拓展了创作的可能性。它代表了 AI 技术在艺术领域的一大进步，为广大音乐爱好者带来了前所未有的创作自由和灵感。",
            "当我们将视觉、语音能力结合在一起，将会怎样？Figure 01 展现了一个可能的答案。可以说Figure 01 代表了一种多模态智能的终极形态，这款由 OpenAI 多模态大模型加持的机器人，具备了与人类及环境进行互动的卓越能力。在执行任务时，如[找到食物](https://cloud.tsinghua.edu.cn/f/a50cefd747ae4b79af90/)等工作，Figure 01 展现出快速且精确的操作能力。\n\n借助多模态模型作为它的“大脑”，这款机器人不仅能够理解复杂的语音指令，还能够根据当前的视觉信息进行策略规划，并通过机器人的控制模块进行灵巧的操作和物理交互，体现了具身智能实体在现实世界应用中的巨大潜力。\n\n通过高级的感知和执行功能，Figure 01 可以日常工作和特定任务提供创新的自动化解决方案。它不仅展现出在家庭环境中应用的可能，随着多模态智能的进一步发展，还可能在工业、医疗和服务等领域提供支持，展现出强大的应用潜力。",
            "在这张幻灯片上，我们将探究卷积神经网络（CNN）的原理以及它是如何受到生物视觉系统启发的。受到从视网膜到大脑初级视觉皮层的信息处理过程的启发，CNN网络通常包含卷积核、池化两种模块。首先，卷积核代表视觉皮层中简单细胞的功能，负责检测图像中的基础特征，如边缘。接着，池化层则模仿了复杂细胞的功能，通过合并多个简单细胞的信号来保持特征的空间不变性。我们的网络通过多层卷积结构逐步深化，从简单特征到复杂特征的集成，这样的分层结构描绘了从感知到认知的转变过程，正如幻灯片底部示例所展示的从简单数字8的轮廓，经过一系列的卷积和池化操作，最后抽象为数字8的高级特征表征。",
            "在这张幻灯片上，我们介绍了一种名为残差网络（ResNet）的深度学习架构。当卷积神经网络变得越来越深时，尽管网络能够提取更丰富和深层的特征，但同时伴随的是信息损失和训练难度的增加。为了解决这个问题，ResNet引入了残差连接，如幻灯片中残差连接结构图所示，它提供了一种“捷径”来直接传递浅层信息，使得网络即使在极深的层次上也能有效地学习。幻灯片的左侧显示了CNN网络在不同层次上提取的特征，从简单的边缘和纹理逐渐演变为复杂的对象部分和高级语义信息。残差连接让网络更容易优化，并且能够在不增加额外的参数和计算负担的情况下增深网络结构。右侧则展示了一个完整的ResNet网络结构，可见它通过堆叠多个带有残差连接的卷积块来构建深层的网络，这种结构设计有效地提升了深度学习在图像识别等任务上的性能。",
            "在这张幻灯片上，我们介绍视觉Transformer，它在图像识别领域引入了原本用于语言建模的Transformer架构。Transformer架构在自然语言处理（NLP）领域表现出色，并证明了其极佳的可扩展性。ViT通过将这一架构有效扩展到视觉任务上，实现了在图像识别方面的突破。\n\nViT架构的主体结构如图所示：首先，图像通过分块策略被切割成大小为16x16像素的补丁（patch），类似于语言模型中的单词（words）。然后，这些补丁被展平并通过位置编码增加空间信息，输入到Transformer编码器中。编码器通过多头自注意力机制处理这些图像补丁，允许模型动态地关注图像的不同区域，并提取出复杂的特征表示，正如幻灯片上的Transformer Encoder结构图所示。最后，ViT通过多层感知机（MLP）头部进行分类。\n\n当有充足的数据进行预训练时，ViT能够超越CNN模型的性能，并且在下游任务中显示出良好的迁移能力，表现出ViT大规模数据集上训练带来的优势，同时解决了Transformer在视觉任务上缺乏归纳偏置的问题。ViT的成功标志着Transformer在计算机视觉领域应用的一个重要里程碑，并激发了后续大量的研究工作。",
            "讨论完图像理解，我们我们会思考，人工智能可以生成图片吗？对于图像分类相对于图像生成的区别，就像婴儿在成长过程中学习辨认不同物体，图像分类器通过分析图片的特征来识别它代表的类别，相比之下，图像生成像是儿童学习如何画出一只猫那样更加困难，因为它需要理解猫的概念，并创造性地生成一只猫的图像。\n",
            "图像生成方法通常有三种流行的方法。\n第一种是生成对抗网络（GANs），类似于“骗子与侦探”的对抗，这种方法涉及两个模型：生成器（G，骗子）尝试生成看起来像真实图片的图像，而鉴别器（D，侦探）的任务是区分真实图片和生成器生成的假图片。通过这种对抗的训练过程，生成器学会产生越来越逼真的图像。\n\n第二种是自回归生成模型，这类似于文本生成，每次都基于前面生成的内容，生成一部分图像，比如一个区域或像素，逐渐构建整张图片。\n\n第三种是深度扩散模型，这些模型从一个随机的噪声分布开始，逐步转换成结构化的图像。在训练阶段，模型学习逆转加噪过程，让噪声数据逐步清晰，最终生成高质量的图像。\n",
            "我们具体介绍一下自回归图像生成模型，类似于大规模语言模型，通过“学习照抄”训练数据来掌握生成连贯文本的能力，每一个位置基于前文输入预测token。",
            "图像生成中自回归生成模型的训练流程与文本训练类似，我们将输入的图片分割成多个块。模型将尝试逐个块地重建整张图像，模型根据已知信息去预测下一个像素块的内容，根据真实的像素块来调整其参数，学习出真实像素块的分布。随着训练的持续进行，模型最终能够准确生成各个像素块，合成出与训练图像相似的新图像。",
            "在这张幻灯片中，我们深入探索了生成对抗网络(GANs)的基本概念。GANs的独特之处在于，它们模拟了一种对抗过程，其中生成器的目标是创造出骗过辨别器的合成数据，而辨别器则旨在区分真实数据和合成数据。这种方法的灵感来自于艺术品的仿制与鉴定过程，生成器和辨别器之间的对抗训练，可以创造出足以迷惑专家的伪作。\n\n幻灯片的左侧为我们展现了这一对抗过程的基本架构，包括从随机噪声到生成器，再到辨别器的数据流向。特别体现在这一点上的是，生成器和辨别器分别用绿色和红色框标出，展现了它们的对立性，反映了生成器要创造像真正数据一样的合成数据，而辨别器则试图识别出哪些是真实数据哪些是假的。\n\n幻灯片中间的文字进一步解释了每个组件的目标，其中生成器的训练目标是“骗过辨别器”，而辨别器的训练目标是“辨别真实的数据和生成的数据”，这两个目标构成了GANs的核心竞争机制。这样的学习过程最终可以产生高度逼真的图片或视频，如同艺术品仿制过程中的真品与赝品。\n\n右侧的图像展现了合成数据的一个示例，这可能是生成器在初期学习阶段的输出，看起来像是随机的噪声。随着生成器的学习和优化，这些图像将变得更加精细和逼真，最终足以达到以假乱真的效果。\n\n综上所述，GANs通过模拟这样的对抗过程，催生出强大的图像生成能力，并且在众多领域中展现了其潜力和应用价值。",
            "深度扩散网络的核心思想是在生成过程中，将噪声逐渐降低，把一个复杂的问题拆分为多个简单的步骤。模型首先通过创建多个噪声级别的图像版本，引导模型学会如何从随机噪声中逐步恢复回真实图像的数据分布。训练时我们进行逐步加噪，生成时从随机噪声图像一步一步恢复至原始的猫的图像。",
            "在本幻灯片中，我们看到深度扩散网络极大地提升了图像和视频生成的效果。关于深度扩散网络的表现力，举了两个例子：应用这种网络的著名模型Stable Diffusion用于图像生成，而Sora则用于视频生成。\n左侧的一系列图像表现了Stable Diffusion模型生成图像的多样性和精细度。\n[右侧](https://cloud.tsinghua.edu.cn/f/3b5bf8d4b41541c88fa0/)是Sora模型的视频生成效果，通过一系列的视频帧展示了模型如何产生连续性和动态效果的视频内容。\n",
            "在这张幻灯片中，我们将探讨声音的三个基本要素：音色、音量和音调。音色是指声音的质地和颜色，决定了我们如何辨别不同的声音源，例如人声与小提琴声的区别；音量，又称响度，决定了声音的强度或响亮程度；音调则与声音的频率有关，决定了声音的高低。\n\n幻灯片左侧有三个示例，分别对应音色、响度和音调。我们可以看到不同的图案表示了不同的声音属性，比如音色部分展示了不同乐器发出的声波形状；响度部分通过不同振幅的波形图来表示声音的大小；最后，音调部分通过不同频率的波形显示声音的高低。\n\n幻灯片右侧的图表向我们展示了如何通过傅里叶变换将声音信号从时域转换到频域，以便于分析声音的频率分量。通过这种变换，我们可以清晰地看到声音在频率上的分布，进而更好地理解和控制音色、音量与音调。\n\n总结来说，声音是可以通过其物理属性（频率和振幅）进行分析和生成的，而对这些属性的理解和操控正是制造和认识声音的基础。通过科学和技术，我们能够更加精确地表达和复制我们所需的声音特性。",
            "本幻灯片向我们介绍了OpenAI推出的一个领先技术——Whisper语音理解与识别系统。Whisper基于强大的Transformer模型，不仅能够执行高准确性的自动语音识别（ASR）任务，而且作为一个多任务模型，它还具备执行多语言语音识别、语音翻译以及语言识别的功能。\n\n首先，我们来看一下Whisper的核心特性。它的强大之处在于能够处理多语言语音输入，并且在各种嘈杂环境下仍能保持较高的识别准确率。此外，Whisper还能自动适应不同的说话风格和口音，提供更为精准的转录结果。这使得它在实际应用中非常灵活，例如在不同的语言之间进行转换或者在复杂的声音背景下进行识别。\n\n幻灯片右侧展示了Whisper的系统架构。我们可以看到，Whisper使用了多个编码器和解码器模块来处理语音信号。首先，信号处理模块将音频分割为小片段，并转化为频谱图像；接着，特征提取模块通过Transformer结构从这些频谱图像中提取重要特征；最后，文本生成模块利用这些特征生成对应的文本输出。\n\n通过这种结构，Whisper能够有效地将复杂的语音信号转化为文字，并且可以处理多个任务和语言。这种多任务的能力使得Whisper不仅在语音识别方面表现出色，还可以用于语音翻译和语言理解等其他应用。\n\n总的来说，Whisper是一个强大且灵活的语音识别系统，代表了语音技术的前沿发展。它的出现将极大地推动语音识别技术的进步，尤其是在多语言和复杂环境下的应用，带来更多的便利和可能性。",
            "在这张幻灯片中，我们深入了解了一项革新音乐创作的人工智能技术：Suno。Suno被誉为“音乐界的ChatGPT”，其独特之处在于，它能根据简单的提示，创作包含歌词、人声以及伴奏在内的完整歌曲。与其他音乐生成模型仅能创造片段不同，Suno拥有生成完整结构歌曲的能力。\n\n幻灯片[左侧](https://cloud.tsinghua.edu.cn/f/4d18a30f342a40f39796/)展示了Suno应用的用户界面，显示了用户如何自定义创作内容。用户可以选择音乐风格和是否使用乐器、生成歌词，这体现了Suno的多样性和用户友好性。[右侧](https://cloud.tsinghua.edu.cn/f/c5e7b92b84a04d98b020/)是一条社交媒体上的推文，推文认为Suno的丰富音乐风格就像在音乐AI创作的世界中找到了一座宝藏箱，暗示了Suno在多样化音乐创作中的潜力和价值。\n\nSuno不仅能够生成旋律和伴奏，还能够生成完整的歌词，这使得它在音乐创作领域独树一帜。对于那些没有音乐创作经验的人来说，Suno提供了一个直观且易于使用的平台，使他们能够轻松地生成高质量的音乐作品。对于专业音乐人，Suno则提供了新的创作工具和灵感来源，可以显著提高他们的创作效率。\n\n我们可以看到，Suno不仅是一个AI音乐生成工具，更是一个能够激发人们对音乐创作热情的平台。它代表了AI在艺术创作领域发挥越来越重要的作用，为作曲家和音乐爱好者提供了新的创作方式和灵感来源。未来，Suno有可能改变整个音乐产业，推动音乐创作进入一个新的时代。"
        ],
        "recommend_content": [
            "在前面，我们提到了一个非常核心的概念——“模态”。那么，模态究竟是什么？通俗来说，模态是指事物存在或发生的方式，可以以语言、声音、图片、视频等多种形式呈现。而我们所说的“多模态”，则是指多种模态的交互，比如一些常见的多模态组合包括图像+语言，声音+语言等等。\n\n举个例子，当图片与语言结合时，我们能够同时接收到视觉和听觉的信息。这种多模态的交互方式，不仅增强了信息的丰富性和表现力，还提升了我们的理解和记忆效果。\n\n幻灯片中的图像展示了我们日常生活中各种模态如何交织在一起，比如香气、偏好和记忆等，这些都共同作用于我们的注意力。多模态交互不仅仅是将多种感官信息结合起来，更是一种综合的体验方式，能够更全面地反映和影响我们的感知和行为。\n\n简而言之，多模态是一种跨越单一模态，将多种感官和信息形式结合起来的综合性交互方式。",
            "下面让我们来了解一下人通常能够接收并理解的模态。人类具有五种基本感官模态，每一种感官模态都为我们提供了与世界互动的独特方式，丰富了我们对环境的理解和感知。\n\n首先是视觉模态，它允许我们通过眼睛接收和理解图像、文字以及其他视觉信息。视觉是我们获取外界信息的主要途径之一，对于我们认知和分析周围环境至关重要。\n\n接着是听觉模态，它让我们通过耳朵接收声音和语言输入。听觉不仅帮助我们进行日常交流，还能让我们欣赏音乐、感知危险以及体验丰富的声景。\n\n嗅觉模态使我们能够探索和辨识周围环境的气味。嗅觉与记忆和情感有着紧密的联系，一些特定的气味常常能唤起我们深藏的回忆和感受。\n\n味觉模态让我们通过味蕾品尝到食物的不同味道。味觉不仅仅是饮食体验的一部分，还能帮助我们判断食物的安全性和质量。\n\n最后是触觉模态，它通过皮肤接触来感受环境的反馈。触觉使我们能够感知温度、压力、质地等，从而对物体进行更细致的辨识，并且在某些情况下提供警示功能。\n\n每种感官模态都在我们的日常生活中发挥着不可替代的作用，通过它们的综合作用，我们能够更全面、更立体地感知和理解这个世界。",
            "与人的感知模态类型相对应，产生出了不同的可数字化的信息模态。\n\n首先是语言模态。语言是人类沟通的主要方式，包含口头和书面形式。语言不仅是表达思想和情感的工具，也是文化传承的重要载体。\n\n图像模态包括静态的视觉内容，用于传递信息和创造美感。无论是艺术作品、照片还是图表，图像都能以直观的方式呈现复杂的信息。\n\n音频模态则涉及声音信息的传递。不仅限于音乐，还包含了语音和环境声音等元素。音频在丰富我们的听觉体验的同时，也在情感表达和信息传递中起到关键作用。\n\n除了三种基本的信息模态，还有一些更加复合、更加专业化的模态类型。例如视频模态涉及动态图像的视觉以及听觉信息。视频作为一种多感官结合的媒介，天然具有多模态的特性，它能够生动地讲述故事和传递复杂概念，是教学和娱乐的重要工具。\n\n医学影像模态专注于体内结构的可视化，常用于医疗诊断。通过X光、CT扫描和MRI等技术，医生能够准确地观察和分析患者的内部状况，做出科学的诊断和治疗方案。\n\n而行为模态则反映了个体的动作和反应，广泛应用于社交和心理学领域。通过分析人们的行为模式，我们可以理解个体的心理状态和社交互动。",
            "面对多种多样的模态信息，为了让模型能够顺利地进行理解，我们需要将不同的模态建模为新的形式。\n\n针对语言模态，我们利用前面的课程提到的自回归语言模型，可以同时实现文本的理解和生成。在图像模态中，我们则通常利用分类器进行图像识别，利用生成器来创造新的图像。对于音频模态则可以通过时间和频率等特征进行理解和生成。",
            "对人而言，不同模态具有不同的意义和编码方式。语言作为人类独有的交流形式，不仅是我们传递信息的工具，它更是我们文化和思想的载体。通过听、说、读、写这四种形式，语言为我们与世界、与他人之间架起了沟通的桥梁，使交流成为可能。\n\n爱德华·威尔逊曾把语言称为人类的一大进化成就，这凸显了语言在社会生物学和人类发展史上的核心地位。我们通过语言，可以共享知识，展开对话，甚至合作解决各种复杂的问题。这些都显示了语言在我们日常生活中的基础作用和重要价值。\n\n举个简单的例子，想象一下没有语言的世界，我们将如何传递复杂的想法和情感？如何在不同文化之间进行交流和理解？语言使这些成为可能，使我们能够超越时间和空间的限制，与他人建立深层次的联系。",
            "人的视觉是人分析理解世界的窗口，视觉感知是指通过视觉来获取、处理和理解信息的过程，帮助人类理解从基本的图形到图表、地图和文字等复杂图像解读。\n\n人类是如何处理视觉信息的？马尔的视觉理论对此进行了解释。马尔把视觉处理分为三个层次，让我们一步步来看。\n\n首先是原始图像的构建。这一步就像我们拍摄一张照片，大脑会处理光线的方向、强度和颜色这些最基本的视觉输入。这相当于我们获取到的视觉原材料。\n\n接下来是第二个层次，大脑开始对这些原材料进行加工。它会提取出物体的轮廓和形状，就像我们画一幅素描那样。这一步不仅仅是看见，还要认识到这些轮廓和形状所代表的物体，并形成立体的感知。\n\n最后是高级视觉处理层次，这是最复杂的部分。大脑会解读所看到的场景，识别出具体的物体，并理解它们的位置和如何与之互动。这一步就像我们在看一幅复杂的图表、地图或文字，不仅仅是看，还要理解其中的信息。\n\n通过这三个层次的处理，视觉感知使我们能够从简单的图形理解到复杂的图像。这种能力是我们与世界交流和认识的基础。想象一下，如果没有这些处理步骤，我们就无法识别面前的物体，更不要说理解图表或阅读文字了。",
            "首先，我们讨论人工智能是否可以识别图片。\n在这张幻灯片上，我们看到了一个探讨人工智能图像识别的例子。首先，我们将一张猫的图片输入给一个神经网络分类器，神经网络会提取猫的耳朵、鼻子、胡须和眼睛等特征作为识别猫的关键参考，最终确定这张图是猫。\n",
            "在这张幻灯片上，我们将探究卷积神经网络（CNN）的原理以及它是如何受到生物视觉系统启发的。受到从视网膜到大脑初级视觉皮层的信息处理过程的启发，CNN网络通常包含卷积核、池化两种模块。首先，卷积核代表视觉皮层中简单细胞的功能，负责检测图像中的基础特征，如边缘。接着，池化层则模仿了复杂细胞的功能，通过合并多个简单细胞的信号来保持特征的空间不变性。我们的网络通过多层卷积结构逐步深化，从简单特征到复杂特征的集成，这样的分层结构描绘了从感知到认知的转变过程，正如幻灯片底部示例所展示的从简单数字8的轮廓，经过一系列的卷积和池化操作，最后抽象为数字8的高级特征表征。",
            "在这张幻灯片上，我们介绍了一种名为残差网络（ResNet）的深度学习架构。当卷积神经网络变得越来越深时，尽管网络能够提取更丰富和深层的特征，但同时伴随的是信息损失和训练难度的增加。为了解决这个问题，ResNet引入了残差连接，如幻灯片中残差连接结构图所示，它提供了一种“捷径”来直接传递浅层信息，使得网络即使在极深的层次上也能有效地学习。幻灯片的左侧显示了CNN网络在不同层次上提取的特征，从简单的边缘和纹理逐渐演变为复杂的对象部分和高级语义信息。残差连接让网络更容易优化，并且能够在不增加额外的参数和计算负担的情况下增深网络结构。右侧则展示了一个完整的ResNet网络结构，可见它通过堆叠多个带有残差连接的卷积块来构建深层的网络，这种结构设计有效地提升了深度学习在图像识别等任务上的性能。",
            "在这张幻灯片上，我们介绍视觉Transformer，它在图像识别领域引入了原本用于语言建模的Transformer架构。Transformer架构在自然语言处理（NLP）领域表现出色，并证明了其极佳的可扩展性。ViT通过将这一架构有效扩展到视觉任务上，实现了在图像识别方面的突破。\n\nViT架构的主体结构如图所示：首先，图像通过分块策略被切割成大小为16x16像素的补丁（patch），类似于语言模型中的单词（words）。然后，这些补丁被展平并通过位置编码增加空间信息，输入到Transformer编码器中。编码器通过多头自注意力机制处理这些图像补丁，允许模型动态地关注图像的不同区域，并提取出复杂的特征表示，正如幻灯片上的Transformer Encoder结构图所示。最后，ViT通过多层感知机（MLP）头部进行分类。\n\n当有充足的数据进行预训练时，ViT能够超越CNN模型的性能，并且在下游任务中显示出良好的迁移能力，表现出ViT大规模数据集上训练带来的优势，同时解决了Transformer在视觉任务上缺乏归纳偏置的问题。ViT的成功标志着Transformer在计算机视觉领域应用的一个重要里程碑，并激发了后续大量的研究工作。",
            "讨论完图像理解，我们我们会思考，人工智能可以生成图片吗？对于图像分类相对于图像生成的区别，就像婴儿在成长过程中学习辨认不同物体，图像分类器通过分析图片的特征来识别它代表的类别，相比之下，图像生成像是儿童学习如何画出一只猫那样更加困难，因为它需要理解猫的概念，并创造性地生成一只猫的图像。\n",
            "图像生成方法通常有三种流行的方法。\n第一种是生成对抗网络（GANs），类似于“骗子与侦探”的对抗，这种方法涉及两个模型：生成器（G，骗子）尝试生成看起来像真实图片的图像，而鉴别器（D，侦探）的任务是区分真实图片和生成器生成的假图片。通过这种对抗的训练过程，生成器学会产生越来越逼真的图像。\n\n第二种是自回归生成模型，这类似于文本生成，每次都基于前面生成的内容，生成一部分图像，比如一个区域或像素，逐渐构建整张图片。\n\n第三种是深度扩散模型，这些模型从一个随机的噪声分布开始，逐步转换成结构化的图像。在训练阶段，模型学习逆转加噪过程，让噪声数据逐步清晰，最终生成高质量的图像。\n",
            "我们具体介绍一下自回归图像生成模型，类似于大规模语言模型，通过“学习照抄”训练数据来掌握生成连贯文本的能力，每一个位置基于前文输入预测token。",
            "图像生成中自回归生成模型的训练流程与文本训练类似，我们将输入的图片分割成多个块。模型将尝试逐个块地重建整张图像，模型根据已知信息去预测下一个像素块的内容，根据真实的像素块来调整其参数，学习出真实像素块的分布。随着训练的持续进行，模型最终能够准确生成各个像素块，合成出与训练图像相似的新图像。",
            "在这张幻灯片中，我们深入探索了生成对抗网络(GANs)的基本概念。GANs的独特之处在于，它们模拟了一种对抗过程，其中生成器的目标是创造出骗过辨别器的合成数据，而辨别器则旨在区分真实数据和合成数据。这种方法的灵感来自于艺术品的仿制与鉴定过程，生成器和辨别器之间的对抗训练，可以创造出足以迷惑专家的伪作。\n\n幻灯片的左侧为我们展现了这一对抗过程的基本架构，包括从随机噪声到生成器，再到辨别器的数据流向。特别体现在这一点上的是，生成器和辨别器分别用绿色和红色框标出，展现了它们的对立性，反映了生成器要创造像真正数据一样的合成数据，而辨别器则试图识别出哪些是真实数据哪些是假的。\n\n幻灯片中间的文字进一步解释了每个组件的目标，其中生成器的训练目标是“骗过辨别器”，而辨别器的训练目标是“辨别真实的数据和生成的数据”，这两个目标构成了GANs的核心竞争机制。这样的学习过程最终可以产生高度逼真的图片或视频，如同艺术品仿制过程中的真品与赝品。\n\n右侧的图像展现了合成数据的一个示例，这可能是生成器在初期学习阶段的输出，看起来像是随机的噪声。随着生成器的学习和优化，这些图像将变得更加精细和逼真，最终足以达到以假乱真的效果。\n\n综上所述，GANs通过模拟这样的对抗过程，催生出强大的图像生成能力，并且在众多领域中展现了其潜力和应用价值。",
            "深度扩散网络的核心思想是在生成过程中，将噪声逐渐降低，把一个复杂的问题拆分为多个简单的步骤。模型首先通过创建多个噪声级别的图像版本，引导模型学会如何从随机噪声中逐步恢复回真实图像的数据分布。训练时我们进行逐步加噪，生成时从随机噪声图像一步一步恢复至原始的猫的图像。",
            "在本幻灯片中，我们看到深度扩散网络极大地提升了图像和视频生成的效果。关于深度扩散网络的表现力，举了两个例子：应用这种网络的著名模型Stable Diffusion用于图像生成，而Sora则用于视频生成。\n左侧的一系列图像表现了Stable Diffusion模型生成图像的多样性和精细度。\n[右侧](https://cloud.tsinghua.edu.cn/f/3b5bf8d4b41541c88fa0/)是Sora模型的视频生成效果，通过一系列的视频帧展示了模型如何产生连续性和动态效果的视频内容。\n",
            "在这张幻灯片中，我们将探讨声音的三个基本要素：音色、音量和音调。音色是指声音的质地和颜色，决定了我们如何辨别不同的声音源，例如人声与小提琴声的区别；音量，又称响度，决定了声音的强度或响亮程度；音调则与声音的频率有关，决定了声音的高低。\n\n幻灯片左侧有三个示例，分别对应音色、响度和音调。我们可以看到不同的图案表示了不同的声音属性，比如音色部分展示了不同乐器发出的声波形状；响度部分通过不同振幅的波形图来表示声音的大小；最后，音调部分通过不同频率的波形显示声音的高低。\n\n幻灯片右侧的图表向我们展示了如何通过傅里叶变换将声音信号从时域转换到频域，以便于分析声音的频率分量。通过这种变换，我们可以清晰地看到声音在频率上的分布，进而更好地理解和控制音色、音量与音调。\n\n总结来说，声音是可以通过其物理属性（频率和振幅）进行分析和生成的，而对这些属性的理解和操控正是制造和认识声音的基础。通过科学和技术，我们能够更加精确地表达和复制我们所需的声音特性。",
            "本幻灯片向我们介绍了OpenAI推出的一个领先技术——Whisper语音理解与识别系统。Whisper基于强大的Transformer模型，不仅能够执行高准确性的自动语音识别（ASR）任务，而且作为一个多任务模型，它还具备执行多语言语音识别、语音翻译以及语言识别的功能。\n\n首先，我们来看一下Whisper的核心特性。它的强大之处在于能够处理多语言语音输入，并且在各种嘈杂环境下仍能保持较高的识别准确率。此外，Whisper还能自动适应不同的说话风格和口音，提供更为精准的转录结果。这使得它在实际应用中非常灵活，例如在不同的语言之间进行转换或者在复杂的声音背景下进行识别。\n\n幻灯片右侧展示了Whisper的系统架构。我们可以看到，Whisper使用了多个编码器和解码器模块来处理语音信号。首先，信号处理模块将音频分割为小片段，并转化为频谱图像；接着，特征提取模块通过Transformer结构从这些频谱图像中提取重要特征；最后，文本生成模块利用这些特征生成对应的文本输出。\n\n通过这种结构，Whisper能够有效地将复杂的语音信号转化为文字，并且可以处理多个任务和语言。这种多任务的能力使得Whisper不仅在语音识别方面表现出色，还可以用于语音翻译和语言理解等其他应用。\n\n总的来说，Whisper是一个强大且灵活的语音识别系统，代表了语音技术的前沿发展。它的出现将极大地推动语音识别技术的进步，尤其是在多语言和复杂环境下的应用，带来更多的便利和可能性。",
            "在这张幻灯片中，我们深入了解了一项革新音乐创作的人工智能技术：Suno。Suno被誉为“音乐界的ChatGPT”，其独特之处在于，它能根据简单的提示，创作包含歌词、人声以及伴奏在内的完整歌曲。与其他音乐生成模型仅能创造片段不同，Suno拥有生成完整结构歌曲的能力。\n\n幻灯片[左侧](https://cloud.tsinghua.edu.cn/f/4d18a30f342a40f39796/)展示了Suno应用的用户界面，显示了用户如何自定义创作内容。用户可以选择音乐风格和是否使用乐器、生成歌词，这体现了Suno的多样性和用户友好性。[右侧](https://cloud.tsinghua.edu.cn/f/c5e7b92b84a04d98b020/)是一条社交媒体上的推文，推文认为Suno的丰富音乐风格就像在音乐AI创作的世界中找到了一座宝藏箱，暗示了Suno在多样化音乐创作中的潜力和价值。\n\nSuno不仅能够生成旋律和伴奏，还能够生成完整的歌词，这使得它在音乐创作领域独树一帜。对于那些没有音乐创作经验的人来说，Suno提供了一个直观且易于使用的平台，使他们能够轻松地生成高质量的音乐作品。对于专业音乐人，Suno则提供了新的创作工具和灵感来源，可以显著提高他们的创作效率。\n\n我们可以看到，Suno不仅是一个AI音乐生成工具，更是一个能够激发人们对音乐创作热情的平台。它代表了AI在艺术创作领域发挥越来越重要的作用，为作曲家和音乐爱好者提供了新的创作方式和灵感来源。未来，Suno有可能改变整个音乐产业，推动音乐创作进入一个新的时代。",
            "本页重点介绍了多模态对齐的概念，其目的是发现并建立不同模态之间的关联性和对应关系，例如文本、图像、音频和视频。通过这种对齐，我们可以让机器更好地理解和处理复杂的信息场景，从而提升其在各类任务中的表现。\n\n幻灯片的上半部分展示了一个实际应用的例子：用户通过Siri虚拟助手下达“开始30分钟的户外跑步”的指令。这涉及到语音和文本的多模态对齐。Siri需要从用户的语音中识别出具体的文本信息，并执行相应的任务，如启动跑步计时器。这一过程展示了语音识别和自然语言处理技术的结合。\n\n下半部分的序列帧展示了一个视频分析的例子。视频中，一个小女孩从一个小男孩身边走过并继续吹树叶。这样的分析需要将视频中的视觉信息与动作的时序数据对齐，标注出特定动作的持续时间。这一过程展示了计算机视觉和时间序列分析的结合，能够精确地识别和标注视频中的复杂动作。\n\n通过这些例子，可以看出多模态对齐在创建更智能和更直观的交互方式中的重要性。它不仅能够提升人机交互的自然性，还在自动内容分析等领域发挥着关键作用。这一技术让机器能够更加全面地理解来自不同来源的信息，并提供更准确的解释和响应。\n\n多模态对齐技术正在推动人工智能向更高水平发展，使得机器能够像人类一样，整合和理解来自多个感官的信息，从而在实际应用中表现得更加智能和可靠。",
            "这张幻灯片介绍了视觉-文本对齐技术中的一个典型例子：CLIP模型。CLIP模型的核心思想是通过对比学习将图像和文本映射到同一个向量空间，在这个空间中，相关联的图像和文本彼此更接近，而不相关的则相隔较远。\n\n首先，我们来看CLIP的工作原理。CLIP模型通过对比预训练（contrastive pre-training），将图像和文本分别输入图像编码器和文本编码器，然后将它们映射到同一个向量空间。在这个空间中，模型学习到图像和文本之间的对应关系。例如，当我们输入一张小狗的图片和描述“小狗”的文本时，模型能够将它们映射到相邻的位置。\n\n最后，CLIP模型在零样本预测任务中展示了其强大的能力。即使模型从未见过某个特定类别的数据，它依然可以基于文本描述进行准确的识别。这在实际应用中非常有价值，例如，当遇到新的物体或场景时，模型可以通过已有的文本描述来进行识别和分类。",
            "这张幻灯片介绍了一种名为ImageBind的多模态对齐技术。ImageBind的核心方法是使用视觉作为中心模态，来对齐包括文本、音频、深度、热力以及内部运动单元（IMU）数据在内的多个模态表示。这种方法的优势在于，它减少了对直接对齐多模态数据的需求，扩大了可以对齐的模态范围。\n\n幻灯片左侧的图例展示了几种不同模态的数据示例，如包含图像和文本的网页数据、深度传感器数据、网络视频、热力数据和第一人称视频。这些示例展示了ImageBind如何自然对齐不同的模态数据。通过将这些数据映射到一个共同的嵌入空间，ImageBind可以实现跨模态的信息融合和理解。\n\n右侧的示意图描绘了各种模态数据在ImageBind中是如何融合到一个统一的嵌入空间的。图中的各种符号表示不同的模态，而线条则代表了模态之间的对齐关系，其中实线代表自然对齐，虚线代表通过ImageBind实现的对齐。这个过程不仅简化了多模态数据的处理，还增强了系统在处理复杂和多样化数据时的灵活性和效率。\n\n总的来说，ImageBind代表了在多个不同类型数据间建立联系的尖端技术，具有巨大潜力，特别是在创建综合感知系统和改进跨模态理解方面。这种技术可能对增强现实、机器人视觉以及跨模态搜索引擎等领域产生深远影响。通过这种多模态对齐技术，我们能够更好地整合和理解来自不同传感器和数据源的信息，推动智能系统的进一步发展。"
        ],
        "recommend_reason": "周宛烨具备高水平的认知投入，对技术概念的学习兴趣显著，此候选片段介绍了模态和多模态的应用，相关理论与视觉、语言模态相连，紧密贴合周宛烨的长期目标。这内容与她之前的知识点有良好延续，并且处于理解的Bloom等级，确保她能够消化和探讨这些信息，从而增强自我导向学习和复杂问题理解能力。",
        "adaptation_result": {
            "start_speech": "同学，接下来我们从刚才谈到的多模态智能出发，深入探讨模态的基本概念及其应用。",
            "refined_scripts": [
                "我们刚才提到了一个核心概念——“模态”，那么模态究竟是什么呢？简单来说，模态指的是事物存在或发生的方式，可以通过语言、声音、图片、视频等形式呈现。而所谓的“多模态”，就是多种模态之间的交互，比如图像加语言、声音加语言等组合。当图片与语言结合时，我们能同时获取视觉和听觉的信息，这种交互不仅增强了信息的丰富性和表现力，更提高了我们的理解和记忆效果。幻灯片中展示的图像例证了日常生活中各种模态的相互作用，像是香气、偏好和记忆共同作用于我们的注意力。多模态交互不仅是感官信息的结合，更是一种综合体验，能够完整反映并影响我们的感知和行为。因此，多模态是一种整合不同感官和信息形式的交互方式。",
                "接下来我们看看人类通常能够接收并理解的模态。人类具有五种基本感官模态，每一种模态都提供了与世界互动的独特路径，丰富了我们的环境理解和感知。首先是视觉，通过眼睛接收并理解图像、文字等视觉信息，是我们获取外界信息的主要途径之一，对于认知和分析环境至关重要。其次是听觉，它让我们通过耳朵感知声音，包括语言输入。听觉不仅帮助交流，还让我们欣赏音乐、感知危险及体验声景。嗅觉使我们分辨气味，与记忆情感紧密相关，特定气味常常唤起深藏的回忆和感受。味觉通过味蕾让我们品尝食物，除了饮食体验的一部分，还帮助判断食物的安全性和质量。最后是触觉，通过皮肤接触感受环境反馈，帮助辨识温度、压力、质地等，有时有警示功能。这些感官模态在日常生活中发挥不可替代的作用，通过它们综合运作，我们能够更立体地理解世界。",
                "和人的感知模态相对应，我们有可被数字化的信息模态。首先是语言模态，人类沟通的主要方式，包括口头和书面形式，是思想和情感的表达工具和文化传承的载体。图片模态则是静态视觉内容，用于信息传递和美感创造，从艺术作品到照片、图表，以直观方式呈现复杂信息。音频模态则涵盖声音信息的传递，丰富我们的听觉体验，音乐、语音及环境声等元素在情感表达和信息传递中扮演重要角色。在这之上，还有更加专业化的模态类型，例如视频模态，融合动态图像的视觉和听觉信息，具有多模态特性，是教学和娱乐的重要工具。医学影像专注于体内结构的可视化，用于诊断，通过技术手段准确了解患者内部状况，为诊断和治疗提供依据。而行为模态反映个体的动作和反应，应用于社交和心理学，通过行为模式分析理解心理状态和社交互动。",
                "面对多样的模态信息，我们需要让模型顺利地理解不同的模态，将它们建模为新形式。我们刚才讨论的自回归语言模型用于语言模态，实现文本理解和生成。图像模态中，我们通常使用分类器进行识别，用生成器创造新的图像。音频模态，则通过时间和频率特征进行理解和生成。",
                "对于人类而言，不同模态意义和编码不同。语言不仅是交流工具，还承载文化思想。听、说、读、写形成沟通桥梁，使信息传递与人之间的交流成为可能。爱德华·威尔逊称语言是人类进化的成就，显示它在社会生物学和人类历史上的核心地位。通过语言，我们共享知识、展开对话，甚至合作解决复杂问题。想象没有语言的世界，复杂想法和情感如何传递？不同文化之间又如何交流和理解？语言使这些交流超越时间和空间限制，与他人建立深层联系。",
                "人的视觉是分析理解世界的窗口，视觉感知通过视觉获取、处理和理解信息。马尔的视觉理论解释了视觉层次处理。首先是原始图像构建，像拍照，处理光线方向、强度、颜色，为感知原材料。然后是加工轮廓和形状，形成立体感知。最后是高级视觉处理，解读场景识别物体，理解位置和相互互动，类似看复杂图表、地图或文字。通过这些步骤，视觉感知使我们从简单图形到复杂图像都能理解，是与世界交流基础。",
                "同学，我们看到了人工智能图像识别的可能性。以猫的图片为例，通过神经网络分类器提取猫的耳朵、鼻子、胡须、眼睛等特征，最终确定图像是猫。",
                "接着我们探讨卷积神经网络(CNN)原理，受到生物视觉系统启发。CNN网络有卷积核、池化模块，靠卷积核代表视觉皮层简单细胞功能，检测基础特征如边缘；池化层模仿复杂细胞，合并信号保持空间特征不变。网络多层卷积结构逐步深化，从简单特征到复杂特征集成，描绘从感知到认知转变过程。正如幻灯片示例所展示，从数字8轮廓经过卷积、池化操作，到抽象为高级特征表征。",
                "我们介绍名为残差网络（ResNet）的深度学习架构。CNN变得很深时，能提取深层特征但会损失信息和增加训练难度。为解决此问题，ResNet引入残差连接，提供“捷径”直传浅层信息，使深层网络有效学习。左侧展示CNN提取特征演变：从简单边缘到复杂对象和高级语义。残差连接让网络更易于优化，在不加负担情况下增深结构，提升性能。右侧展示完整ResNet结构，通过堆叠多个带残差连接的卷积块构建深层网络。",
                "我们介绍视觉Transformer，它引入用于语言建模的Transformer架构到图像识别领域。Transformer在自然语言处理表现良好，ViT将其扩展到视觉任务，实现识别突破。ViT架构如图，图像经分块切为16x16像素补丁类似语言模型中的单词，展平并结合位置编码，输入Transformer编码器。编码器用多头自注意力机制处理补丁，提取复杂特征。最后通过多层感知机（MLP）进行分类。预训练时，ViT能超越CNN，显示良好迁移能力，标志在计算机视觉应用里程碑。",
                "人工智能能生成图片吗？图像分类与生成就像认知物体和画图，分类器分析特征识别类别，生成需要理解概念创作性地产图。",
                "图像生成方法三种流行方式，第一是生成对抗网络（GANs），“骗子与侦探”模型：生成器尝试创造逼真图像，鉴别器区分真实与生成。第二是自回归模型，基于前生成内容逐步构建图片。第三是深度扩散，从随机噪声变结构化图像。",
                "自回归图像生成模型，类似大规模语言模型，通过学习照抄训练数据来掌握生成连贯文本，每个位置基于前文预测token。",
                "说明自回归生成模型训练像文本训练，输入图片分割块，模型逐块重建整张图片，根据已知信息预测下一个像素块的内容并调整参数，学习像素块分布。训练持续模型最终准确生成各个像素块合成类似训练图像的新图像。",
                "生成对抗网络(GANs)独特在于模拟对抗过程，生成器目标创造骗过辨别器的数据，而辨别器旨在区分真实数据和合成数据。灵感来自艺术品仿制与鉴定过程。幻灯片展示这一对抗架构，从随机噪声到生成器再到辨别器。中间文字解释每组件目标：生成器目标“骗过辨别器”，辨别器目标“辨别真实与生成数据”，核心竞争机制创造高度逼真图片或视频。右侧图像展现合成数据示例，初期输出像随机噪声，优化后逼真以假乱真。GANs通过对抗过程生成强大图像能力，展现众多领域潜力。",
                "深度扩散网络核心思想是生成过程中逐步降低噪声，把复杂问题拆分多简单步骤。模型创建多个噪声级别图像，引导模型学会从随机噪声逐步恢复真实图像数据分布。训练逐步加噪，生成从随机噪声一步步恢复至原始图像。",
                "深度扩散网络极大提升图像和视频生成效果，模型示范Stable Diffusion用于图像生成，Sora用于视频生成。左侧图像表现Stable Diffusion生成图像的多样性与精细度。右侧是Sora模型视频生成效果，视频帧展示模型如何产生连续动态效果内容。",
                "声音的三个基本要素：音色、音量、音调。音色是声音质地颜色，决定辨别声音源；音量指响亮程度；音调与频率有关，决定高低。左侧示例对应音色、响度、音调，比如音色部分展示乐器声波形状，响度部分振幅波形图表示声音大小，音调频率波形显示声音高低。右侧图表示傅里叶变换声音信号时域到频域分析，看到声音频率分布，更好理解音色、音量、音调。总结来说声音通过物理属性分析生成，对这些属性理解操控是制造认识声音基础。",
                "Whisper语音理解与识别系统介绍。其基于强大Transformer模型，执行高准确性自动语音识别及多任务，如多语言语音识别、翻译、识别。展示Whisper强大之处，在多语言语音输入、嘈杂环境下保持高识别率。适应不同说话风格口音，精准转录结果。右侧展示Whisper架构，音频分割频谱图像，特征提取模块通过Transformer从图像中提取特征，最后文本生成模块利用特征生成文本输出。结构有效处理复杂语音信号，为多个任务语言应用。",
                "Suno革新音乐创作的AI技术，能根据提示创作完整歌曲。左侧展示Suno应用界面，用户自定义创作内容。提供选择音乐风格及工具平台，生成旋律、伴奏、歌词。用户友好，适合没有音乐创作经验的人生成高质量音乐作品。右侧推文认为Suno丰富音乐风格为AI创作世界带来宝藏。Suno能生成旋律、伴奏、完整歌词，在创作领域独树一帜，为音乐爱好者提供新的方式灵感来源。",
                "介绍多模态对齐，目的是建立模态间关联。例如文本、图像、音频、视频，如通过Siri助手执行任务，与视频分析结合，展现人机交互提高自然性与自动内容分析。对智能系统促进理解与应用。",
                "CLIP模型通过对比学习图像文本同向量空间映射，相关联更近。工作原理：图像文本分别输入编码器，然后映射同向量空间，学习对应关系。零样本预测强大能力，实际应用中通过已有描述识别分类新物体。",
                "ImageBind多模态对齐使用视觉为中心模态对齐其他模态。简化过程扩展模态范围，示例展示网页、传感器数据、视频等对齐到统一空间。增强理解、多样化数据处理灵活性。推动综合感知系统及跨模态理解。"
            ],
            "end_speech": "同学，希望这次探讨能激发你对多模态应用的深刻理解，鼓励你在技术领域进一步探索。"
        }
    },
    {
        "title": "module_ai_plus_part1_夏熠",
        "original_content": [
            "首先，为什么通用人工智能会在近两年受到如此大的关注，是什么让我们看到了实现通用人工智能的曙光呢？\n我想，随着计算量的增加而不断提升性能的大语言模型功不可没。让我们看到左下角这张图，该图的横轴是时间，而纵轴是困惑度（perplexity），它常用于反映大语言模型的能力，其值越低模型性能越好，而图中的圆圈大小则表示模型的训练计算量。不难发现，随着时间轴不断向右移动，圆圈越来越大，即AI模型的计算量不断增加，而与此同时，困惑度不断下降，表明模型的性能也在随之变好，这一趋势揭示了增大模型规模和计算量的潜在价值。\n\n现在，大家看到右下这张条形图，它展示了GPT-4在各种专业考试中的表现，不仅仅是与人类比较，更是和它的前代模型GPT-3.5相比较。可以看到，GPT-4在很多领域的表现已经超过了大部分的人类考生。这真是令人惊叹！除了专业考试以外，以ChatGPT、GPT-4为代表的超大规模语言模型已经被证明可以在众多类目丰富的任务中取得优越的成绩，让人们看到了实现通用人工智能的希望。这种成绩的背后，是模型设计的不断创新和计算资源的巨大投入。这种进步不仅是量的积累，更是质的飞跃。",
            "超大规模的预训练模型同样展现出了令人惊叹的能力和智慧，让我们来看两个例子。\n\n正如左侧的图片中，GPT-4能够理解并描述出这一场景的滑稽之处：一个庞大、过时的VGA连接器竟然被插进了一个现代智能手机的细小充电口。这个描述不仅准确，而且还透露出了它对人类幽默感的理解。\n\n同时，看向右侧的[视频](https://cloud.tsinghua.edu.cn/f/ee6f862bec9c4f099ef6/)，我们见证了Sora这样的视频大模型在视觉内容创作方面取得的深刻进步。无人机航拍视频的制作，通常需要专业的技能和创意，更需要对空间、方向、角度等概念的充分理解，而现在AI能够自主完成这样的任务，这标志着我们在迈向融合多感官的通用智能的路上迈出了一大步。",
            "说到此处，相信有不少同学会关心一个问题，当下的人工智能技术发展如此迅猛，迈向通用人工智能也是必然趋势，那么它究竟什么时候能够实现呢？\n\n为了回答这个问题，我们可以看一下来自这些知名AI企业、企业家和顶尖学者们的观点。为了得到更强大的人工智能，OpenAI组建了Superalignment（超级对齐）团队，目标是四年内能够实现“引导和控制比我们聪明得多的AI系统”。这是一个雄心勃勃的愿景，意味着在短短几年的时间内，人工智能将有可能在大量的任务上真正地超越人类。\n而Elon Musk则预测，AI在三年内就能写出像《哈利波特》那样好的小说，或者是发现新的物理学理论和新技术。这也体现出他对于AI发展出艺术创作、科学研究、新技术开发等比肩人类的高级能力抱有深切期待。\n图灵奖得主Yoshua Bengio、Geoffrey Hinton、姚期智等人在一篇合著论文中也指出，AI技术的进步速度令人震惊，在当前十年或下一个十年内，人工智能系统就有可能在许多关键领域超越人类，对此，我们必须认真对待这种可能性，并积极预防AI的发展所带来的风险与挑战。\n\n综合以上观点，我们不难发现，与人类比肩甚至超越人类能力的通用人工智能，已经不再是存在于科幻小说中的天方夜谭，而是很有可能在不久的将来被真正实现的。",
            "正如我们之前讨论“人工智能”的界定一样，通用人工智能的定义同样值得琢磨。\n\n通用人工智能的英语表述为Artificial General Intelligence，简称AGI，该词最早于1997年为物理学家Mark Gubrud所提出。他认为高级的通用人工智能，是那些在复杂度和处理速度上能够匹敌甚至超过人脑的AI系统。随着时间的推移，AGI 的概念已经扩展，不再局限于特定的实现机制或应用，而是指一种类似人类乃至超越人类的能力，包括学习、适应和解决问题的能力。正如OpenAI在其一篇博客中所阐述的那样，通用人工智能需要在绝大多数有经济价值的工作中，具备超越人类的能力，同时必须能够高度自主地运作。\n\n可以看到，AGI 的发展焦点已经转移到其普遍的应用和效用上，而不仅仅是技术本身。这种理念预示着我们正在朝着创造出真正能够在各种环境和情境中，以人类般的智能和适应性执行任务的机器迈进。这不仅对于技术领域是一个巨大的挑战，同时也为人类的工作方式、生活方式带来了前所未有的变革潜力。",
            "不过，要如何界定通用人工智能的实现与否，AI的能力强大到什么程度才可以算作通用人工智能，这些问题确实难以给出一个共识性的解答。为了更好地理解已有AGI的发展，Google DeepMind提出了一个系统化的分级方法，它旨在量化AGI进步的不同阶段。这个分级包括能力级别和自动化程度两个维度，有助于我们评估AGI的成熟度和应用范围。\n\n在能力级别上，起点是“无智能”，然后是“涌现”阶段，其能力相当于或略高于非专业人士。随着技术的发展，“能干”的AI至少能胜过一半的专业人员。再进一步，“专家”阶段的AI超过90%的专业人员，而“大师”级别的AI能力则超越了99%的人类专家。最终，“超人”级别的AGI将会超越所有人类的智能水平。我们现在所处的阶段大致处于“涌现”与“能干”之间。\n\n从自动化程度来看，起点是“无智能”。然后AGI从“工具”级开始，这是人类完全控制AI的阶段，然后是“顾问”级，AI在决策中发挥重要作用但仍需要人类主导。接下来的“合作者”级别，AI能与人类平等合作；“专家”级则是AI主导，人类仅提供必要的支持；最后，达到“智能体”级别，AGI可以完全自主运作。目前所处的阶段，大致在“工具”与“顾问”之间。\n\n这一分级体系的思想非常有用，它提供了一种框架来观察和评估AGI的技术进展，同时也为研究人员和工程师提供了明确的目标。",
            "看了之前那些问题呀，相信同学们已经有了不少想法，那就让我们先从最简单的问题开始看起吧，在我们的生活或者是专业学习中，人工智能有哪些应用，又有着怎样的地位。这些身边的例子会帮助我们理解人工智能技术的普及程度和它们所带来的便利。\n\n例如，在清华校园中，人脸识别技术帮助我们快速通过门禁，无需翻找校园卡；自动驾驶技术让图书馆的书籍能够自动送达，节省了我们的时间和精力；而在家庭环境中，智能家居助手能够理解我们的命令，控制家中的设备，提供方便快捷的服务。外卖和电商平台使用个性化推荐算法，让我们在海量商品中快速找到自己喜欢或需要的商品；搜索引擎则利用复杂的信息检索算法，帮助我们精准地找到所需信息。这些都是人工智能技术融入我们生活的具体例子。\n\n这些智能系统的背后，是AI领域学者和工程师的辛勤研究和创新，在他们的努力下，人工智能已经成为我们生活中不可或缺的部分，大大提高了人类社会运作的效率。当我们谈论人工智能的应用时，我们不仅是在讨论技术本身，更是在讨论这项技术如何与我们的生活、工作、学习相互融合，以及它们如何提高我们处理日常任务和复杂问题的能力。",
            "了解了人工智能在我们日常生活中的应用后，现在让我们来看看AI在更广阔领域的作用。在科学研究的前沿，人工智能同样变得至关重要，它不仅加速了既有知识的获取，还拓展了我们探索潜在新知的能力。\n我们不妨来聆听一下那些AI业界领军人物的看法，感受到他们对人工智能的期待。比如，创造ChatGPT的企业，OpenAI，其CEO Sam Altman认为，AI将极大提升每个人的生产力，包括顶尖科学家们，从而加速科学的进步，帮助我们掌握更多知识，发掘新的创意。DeepMind的CEO，Demis Hassabis，他认为AI最终的用途在于将科学加速到极致。Google的CEO，Sundar Pichai则认为，人工智能是人类进行的最为深刻的研究方向之一，其重要性甚至可能超过火和电的发现。\n\n这些观点描绘出了一个令人激动的前景：一个由AI驱动的世界，在这个世界中，信息获取和知识探索更为高效和深入。AI带来的技术革命不仅能提升我们社会运作的效率，更有潜力拓展人类的知识边界。\n作为人类智慧结晶的AI，将会在不远的将来帮助我们实现跨越性的进步。这个技术革命，就像火和电一样，将会成为推动人类社会发展的新引擎。所以，我们不仅要学习人工智能，还要思考如何利用它来推动人类文明的进步。",
            "当我们尝试理解人工智能时，就会发现它不仅仅是技术层面的概念。AI研究领域的学者们从多个角度探讨了这个概念，提出了不同的认识和理解。\n\n有的学者，比如Marvin Minsky，他是人工智能领域的先驱之一，他从“理性”的角度出发，将AI视为一种能够理性行动、解决复杂问题的系统。在Minsky看来，AI的本质在于执行那些需要智能才能完成的任务，而智能正是解决这些复杂问题的关键。另一种观点则是从“类人”的角度出发，如深度学习先驱之一、图灵奖得主Yoshua Bengio认为，人工智能就像是一种“聪明”的机器，可以进行学习、理解世界，并将所学知识应用到实际任务中，与人类行动非常相似。\n\n这些观点展现了学者们对AI的深层次认知，也指向了AI未来发展的重要方向：实现理性行动并解决复杂问题，以及发展出类似于人类的思维和认知能力。随着研究的不断进展，我们可以预见到人工智能在这些方向上会有更多的突破，进而在各个领域中发挥更重大的作用。",
            "正如你们可能已经意识到的，对于人工智能的定义确实存在一些差异。然而，尽管学术界对人工智能的精确定义尚未达成共识，我们还是有一个广泛接受的基本概念。\n\n人工智能（Artificial Intelligence），主要指的是由机器，特别是计算机系统所实现的智能系统。AI的核心追求是让机器能够模拟人类智能的行为，这包括了感知环境和在环境中采取行动以高效完成任务的能力。这些任务往往相对复杂，需要一定的人类智能和工作量才能精准完成。简单来说，AI旨在创造能够独立思考、学习知识和解决问题的机器，它们不仅仅按照预定的规则行动，而是可以通过学习和适应来增强其性能，不断进步以适应新的环境。这是一条既充满挑战也令人激动的探索之路。",
            "虽然人工智能作为一门学科被研究和重视，是在现代计算机技术出现并成熟以后。但事实上，对于这类能够自主思考和行动的机械的想象，在中西方的人类文明早期便已经悄然开始。接下来，让我们投身时光的洪流，从人类对人工智能的早期畅想开始，回溯AI的起源，以及其漫长坎坷的发展道路。\n\n早在古希腊时期的多部神话中，就记载着一位青铜巨人，其名为Talos，它全身由青铜铸就，所向无敌，一日之内能绕克里特岛三周，保护克里特岛免受入侵者的侵害。这也是西方典籍中已知最早的“机器人”。而在咱们中国古代的西周时期，也记载有一位“机器人”。《列子·汤问》中描述了这样一个故事，一位叫偃师的人给周穆王造了一个“偶人”（也就是人偶、机械人），它既会唱歌又会跳舞。在给周穆王表演的时候，它偷偷向周穆王左右侍妾抛媚眼。周穆王大怒，要杀偃师。偃师慌忙解释说，这是假人，不信拆开看看。拆开之后，周穆王发现，“偶人”是由革、木、胶、漆、白、黑、丹、青制成的，肝胆、心肺、脾肾、肠胃，筋骨、肢节、皮毛、齿发等都是假的。当周穆王把它的心拿出来，它就不能说话了，把肝拿出来，它就看不见东西了，把肾拿出来，它就不能走路了。如此看来，这个偶人极为高级，五脏与身体活动能力的对应关系，也体现了古人对人体的认识。偃师所打造的这个“偶人”，也是中国典籍中已知最早的“机器人”。\n\n尽管古时的技术与今日的人工智能相去甚远，但这些故事显露出人类对于创造可以自主执行任务、拥有智能的非生物实体的早期追求。无论是在东方还是西方，人们对于能够模仿人类行为的机械始终抱有深厚的兴趣和无限的想象。这些宏大而美好的梦想和理念，今日也化作了人工智能领域学者不断前进的动力与目标。",
            "说到人工智能的起源，我们就不能不提到艾伦·麦席森·图灵——他不仅是计算机科学的巨擘，也是人工智能领域的奠基人之一。1950年，图灵在他的开创性论文《计算机器与智能》中提出了一个著名的问题：“机器能思考吗？”他设想了一台会思考的机器，即所谓的“Thinking Machine”。图灵认为，这样的机器需要具备感知能力，它不仅要能够接收指令，还应能感知周围环境，包括视觉和听觉等感官信息，从而在没有人类干预的情况下，独立地做出决策。机器的“看”和“听”不仅限于复制人类感知，更关键的是要理解和处理收到的信息，从而实现真正的自主的智能。\n\n图灵的这些观点对我们今天所理解的人工智能有着深远的影响。他提出的思考机器的概念，实际上预见了当代智能系统所拥有的许多特性——包括学习、适应和处理复杂问题的能力。",
            "当然，图灵对于人工智能的贡献远不止于此。除了提出AI的早期概念以外，关于如何界定智能，他也同样有着自己的思考，著名的“图灵测试”便是他在《计算机器与智能》一文中所提出的，人工智能领域最具代表性的思想实验之一。它提出了一个标准，以判断机器是否具备人类智能。\n\n具体而言，测试者与被试者（被试者包括一个人和一台机器）隔开，测试者向被试者随机提出问题，并需要判定提供回答的是人还是机器。如果测试者无法以较高的准确率分辨出来对方的身份，那么被试机器便被认为具有人类智能。这一测试深度考验了机器理解和响应人类语言的能力，长期以来一直是人工智能研究中一个重要的理论基石和目标。\n\n然而，随着人工智能技术，特别是大语言模型如GPT-4的快速进展，一些学者开始质疑图灵测试是否还是一个充分的智能判定标准。顶尖的模型因为其惊人的语言生成和理解能力，让图灵测试的标准显得不够挑战性。这导致了对智能的定义和测试标准的进一步讨论，学界正在寻求更高标准，以更全面地评估AI的智能水平。但我们仍需要意识到，图灵测试的重要性不仅仅在于它为AI的智能评估提供了一个参照点，更在于它启发了关于智能本质的广泛讨论和思考。图灵对智能的深刻见解提醒我们，评估AI智能时，我们应考虑到智能的多个维度，包括逻辑推理、学习、适应、创造性和理解复杂概念等，正如今天我们在面对越来越高级的AI模型时所进行的讨论一样。",
            "“人工智能”作为一门真正意义上的学科诞生，是在达特茅斯会议上。这场会议在1956年举行，召集了一群有远见的科学家们，他们一同讨论了关于机器模仿人类学习和其他智能行为的可能性。这场会议定义了人工智能研究的基本议题，并预见了未来的研究方向。在会议上提出的议题，如使计算机使用语言、神经网络等，现在仍然是人工智能研究中最为活跃和关键的领域。例如，自然语言处理（NLP）技术正是从“让计算机使用语言”的议题中逐渐发展起来的，而今天的大型语言模型，则是NLP技术的最新成就。同样，神经网络作为当前大多数AI模型的基础架构，也在达特茅斯会议上被提出并讨论。那些参加会议的科学家，都为人工智能的发展做出了巨大贡献，其中，John McCarthy、Marvin Minsky、Allen Newell、Herbert Simon最终获得了计算机科学界的最高荣誉——图灵奖。\n\n这场会议不仅仅是学科发展的起点，更是一系列重大创新和突破的催化剂。它为人工智能科学家提供了一个集思广益、互相启发的平台。这一群科学家的远见和集体智慧，奠定了现代人工智能发展的基石，影响至深，使得原本只存在于科幻中的想法，转化为改变世界的现实技术。",
            "人工智能的发展历史就像一部跌宕起伏的史诗。AI首先作为一门学科在达特茅斯会议上诞生，使得1956年成为AI元年。紧接着，1957年，作为神经网络鼻祖的感知器算法被发明，它也曾一度被看作是人工智能向前迈进的关键技术。然而，历史的发展并不是一帆风顺，1970至1980年间，因为早期的翻译机和感知器的局限性，人工智能遭到了来自各界的批评，由此进入了AI发展史上的第一个“寒冬”，这是一个资金和研究兴趣都急剧减少的时期，大部分政界和学界人士不相信人工智能的潜力，而不愿投入资源进行研究。但如同凛冬将尽，春暖花开。1980年代，许多新的AI技术开始成熟，如多层神经网络和专家系统，它们重燃了人工智能的火花。到了1986年，BP、PDP等算法的提出为AI的发展注入了强大的生命力，时至今日，BP算法仍是我们高效训练深度神经网络的基础算法之一。不过，AI面临的挑战并未完全消失，1990至2000年间，随着日本五代机项目失败，人们对AI的热情满满退去，人工智能再次面临着资金和期望值的低谷。\n\n进入21世纪，随着深度学习的突破，人工智能开始在许多领域表现出它强大的潜力，这一次并没有陷入低谷，而是在2010年以后开始爆发。诸如AlphaGo、人脸识别等成功案例，都展示了人工智能技术的长足进步，人们对AI研究转化为实用价值的期望空前提高。\n\n这张时间线不仅仅是对过去的回顾，更是对未来的展望。每一次的低谷都为下一个高潮做准备，每一次的挑战都孕育着新的飞跃。如今，我们也正站在新的起点、新的高度上。AI大模型取得的突破，正在引领着AI技术快速地向更高处迈进。",
            "符号智能，也就是使用预定义的符号和规则表示知识，并基于此进行信息分析和推理的人工智能。符号智能曾一度主导AI领域，作为AI的早期范式，该技术在20世纪60到80年代左右取得了长足发展。在这个时期，像Noam Chomsky和Edward Feigenbaum这样的学者，分别在语言学和专家系统领域做出了重大的理论和实践贡献。Chomsky的语言学理论对于理解语言的结构和语言处理有着深远影响，而Feigenbaum在专家系统方面的工作则展示了如何将复杂的知识进行形式化的编码，使得计算机能够利用专家知识，在特定领域进行专家级的判断和决策。\n1997年，IBM的“深蓝”国际象棋程序击败世界冠军Garry Kasparov，这更是证明了符号智能能够在特定领域超越人类智能。这一里程碑事件不仅展示了计算机的巨大潜能，也引发了公众对AI能力和未来的广泛讨论。",
            "然而，随着时间的发展，符号智能的局限性也逐渐暴露出来，让我们来看一个专家系统的例子。如图所示，一个典型的专家系统由知识库和推理机构成。其中，知识库中涵盖了大量由专家手工总结的知识和规则，而推理机在接受用户的指令后，会从知识库中查询相关的知识，并经过推理算法生成最后的答案。例如，当询问“青蒿素抑制什么？”，专家系统会查找其知识库，找到与青蒿素相关的信息，表示“青蒿素”与“疟原虫”之间有“抑制”关系，因此经过简单推理，即可得到正确答案“疟原虫”。对于已经预编程和预设好的领域知识，这样的系统能够迅速而准确地给出答案。\n\n然而，专家系统，乃至整个符号智能的局限性就在于，它依赖的是事先定义好的知识和规则。但当遇到知识库没有的信息时，例如关于一个具体而未知的生物信息问题，它就无法提供答案。这种系统不能自行获取新知识，也不能处理未知类型的问题。此外，简单地扩充知识库并不能解决这一问题，一方面，知识难以被穷尽式枚举，另一方面，也并非所有知识都可以被形式化为知识库中的规则，知识的总结更需要耗费大量的人力，因此，我们亟需探索更加成熟、不依赖于预定义知识库的方法。",
            "在符号智能之后，我们迎来了针对特定任务的经典范式——专用智能。这一阶段的AI更加注重于在特定的任务上达到或超越人类的水平，通常依赖于数据驱动的机器学习方法，而非预先定义的规则。\n\n在这个时期，有几位学者的工作极具影响力。Judea Pearl，因其在因果推断领域的工作而知名，提出了概率图模型和贝叶斯网络，极大地推动了我们对机器如何模拟人类推理的理解，促进了数据驱动的机器学习的发展；Yann LeCun则是在深度学习领域做出了巨大贡献，尤其是通过卷积神经网络在多个计算机视觉任务上取得了性能的突破性进步，从而推动深度学习和数据驱动的范式走向新高位，成为当下通用人工智能的主流范式。\n\n在这一阶段，我们也同样看到了很多振奋人心的成果。例如，DeepMind团队将深度学习与蒙特卡洛树搜索相结合，创建了一个能够在复杂的围棋游戏中胜过世界冠军的程序AlphaGo。AlphaGo在2016年和2017年的比赛中分别战胜李世石和柯洁。这些成就显现了数据驱动的专用AI在复杂任务上的巨大潜力，并且对公众的认知产生了深远的影响，再次激发了对人工智能未来可能性的想象，提高了人们的预期。",
            "当然，专用智能也并非完美无缺，同样有着一定的局限性。具体来说，专用智能的方法往往需要高度特化的训练数据，这意味着模型通常在它们被训练执行的特定任务上表现出色，但却很难处理训练数据未覆盖的问题。\n举例来说，一个被训练用于中文、英语、法语翻译的专用模型，在翻译任务的数据上训练后，可能在被问及“计算机”的英文和法文对应词时回答得很准确，但当它面对一个数学问题如“1+2=？”时，则可能束手无策，因为他的训练数据根本没有覆盖任何的数学问题。这显示出专用智能的模型对训练数据的依赖性，无法泛化到数据分布外的问题。",
            "最后，我们来看看通用智能——这是一个致力于实现通用认知能力的范式，也是人工智能未来发展的一个重要方向，旨在创建能在广泛任务和环境中表现出色的AI模型。\n\n在这一方面，OpenAI的GPT，Google的BERT是前期具有代表性的工作。这些模型在大规模的文本语料上对模型做自监督的预训练后，只需要在专用数据上做少量的微调，即可于多种语言理解或生成任务上取得优异的表现，而无需再为每个任务都从头训练一个专用模型。\n2020年，OpenAI 发布的 GPT-3 则又是一个里程碑式的例子，这个模型拥有惊人的1750亿参数，展示了大语言模型能带来前所未有的能力，如语言理解、生成和任务适应性，初步揭示了增大模型的规模和数据量所能带来的能力飞跃。ChatGPT，作为 GPT-3 的后续版本，更是通过人类交互，可以处理多种复杂的问题。\n\n可以看到，自2018年起，我们见证了预训练语言模型的快速发展。这些模型不仅统一了文本任务的处理框架，而且在多项任务上取得了显著的性能提升。今天的通用智能模型正在快速进步，随着全球的团队投身到这一领域，AI的应用范围和能力势必会不断扩展。而在这些模型所体现出的丰富知识和通用能力背后，起到关键作用的，正是在海量通用域无标注数据上进行的自监督训练，而模型的巨大参数量则使得他们可以存储更多的知识。在不远的未来，我们可以期待更加强大、多功能和高度泛化的智能系统。这些系统不仅会在特定任务上表现出色，还能够跨任务和环境学习和适应，为我们的日常生活和工作带来革命性的变化。",
            "通用智能的范式之所以可以取得如此亮眼的成功，其核心优势在于可以利用大规模廉价可得的无标注训练数据，以及模型的大规模参数所带来的更加强大的知识学习和存储能力。以大语言模型为例，书籍、新闻、论文、报告，几乎任何的文本语料，在经过适当的筛选和清洗后，都可以拿来作为训练材料。在自监督预训练的过程中，大模型能够充分提取和利用海量文本数据中的模式，这些模式不仅包括语言的表面特征，而且包括文本中隐含的更深层次的结构和知识，使得模型能够在各个不同的领域中解决多种类型的问题。从基本的事实性问题（如“计算机的英文是什么？”），到具体的操作性问题（如“如何治疗疟疾？”），甚至数学计算（如“1+2=？”），都可以进行相应的回答，展现出了它们处理信息的强大能力。\n我们相信，未来的AI系统将更加强大，它们将不仅限于单一任务，而是能够跨领域进行学习和应用知识，向真正的通用人工智能迈进。"
        ],
        "recommend_content": [
            "接下来，我们来讨论人工智能在艺术创作这一领域中的应用和挑战。\n\n首先，我们来回顾一下扼要回顾一下艺术创作的发展。我们来看中世纪的艺术作品。在这一时期，艺术主要服务于宗教目的，表现圣母子像和宗教故事，人物形象失真，以强调其神圣性而非现实性。幻灯片中展示的是拜占庭镶嵌画的例子，这些作品充满了宗教色彩和象征意义。\n\n接下来是文艺复兴时期，这一时期的艺术强调人本位和解放思想，艺术作品追求写实和人体美。幻灯片中展示了米开朗基罗的《圣母怜子图》和达芬奇的《蒙娜丽莎》。文艺复兴时期的艺术反映了经济发展和世俗享乐的追求，同时也是对天主教会权威的反叛。\n\n最后，我们看到现代主义的艺术，这一时期的作品标新立异，解构传统思维，反映了工业革命和城市化背景下的社会变化。幻灯片中展示的是毕加索的《亚维农的少女》和梵高的《星夜》。现代主义艺术家们通过这些作品表达出对传统的挑战和自我的探索。\n\n通过这张幻灯片，我们看到艺术风格随着社会、经济和技术背景的变化而演进。每一个时期的艺术风格都对未来的创造者产生了深远的影响。与前两个领域（科学研究和历史文献）相比，文艺创作对人工智能的“创造”能力提出了更直接的考验。人工智能在文艺创作中需要更深层次的理解和创新，不仅仅是模仿和再现。\n\n这既是一个巨大的机遇，也是一个严峻的挑战。人类社会的文艺创作是理性与感性交融的体现，AI在这一领域中的应用仍需不断探索和突破，以实现真正的创意表达和文化价值的体现。 ​",
            "文艺创作中存在着感性与理性的两种不同的角色。艺术创作不仅涉及个人的情感表达，当这些个人情感成为群体的共鸣时，就形成了特定时期的风格。同时，文艺创作也受到长期共通审美特征的制约，这些规范和制式成为艺术家必须遵守或选择打破的约束。\n\n首先，幻灯片指出了文艺创作的感性面。当个人感受成为群体特征时，便形成了某一时段的艺术风格。举例来说，达达主义代表马塞尔·杜尚的作品《泉》，这是一个普通的小便池，但通过艺术家的重新命名和展示，挑战了传统艺术的定义和界限，体现了对现有艺术体系的反叛和感性表达。\n\n其次，幻灯片展示了先锋派作曲家约翰·凯奇的无声音乐作品《4'33\"》。这个作品在演奏时，演奏者不发出任何声音，只是静静地坐在乐器前。这个作品挑战了音乐的本质，质疑了传统音乐的定义，体现了对艺术规范的突破和重新定义。\n\n最后，文艺创作的理性面涉及长期共通的审美特征凝结成的制式约束。这在中国古代诗词中表现得尤为明显。例如，唐诗中的《忆江南》展示了严格的格律要求，包括平仄、对仗等，体现了理性在文艺创作中的作用。这些规范约束了创作的形式，但也造就了独特的美感和文化价值。\n\n通过这些例子，我们可以看到，艺术家在创作过程中不断在感性与理性之间寻找平衡，或者选择挑战和突破传统规范。这种辩证关系推动了艺术的发展和创新，也为未来的创作者提供了新的灵感和路径。",
            "文艺创作的实质是什么？基本元素的模仿组合是否可以称为文艺创作？新的表达要素又是如何演生的？这些问题引导我们思考文艺作品中的“创造力”定义和评价标准。\n\n柏拉图认为，现实世界是理想世界的影子，而文艺作品则是现实世界的影子。如果艺术家仅仅为了迎合大众口味而放弃了艺术的神圣性，艺术与真理之间就会渐行渐远。因此，文艺创作应该努力反映世界的本质，追求更高的真理和深层次的意义。\n\n幻灯片中引用了拉斐尔的《雅典学院》，这幅画作象征着理性思辨和艺术表现之间的紧密联系。它描绘了古典哲学的集会，寓意了哲学家们对理想世界的探索和对现实世界的反思。\n\n通过这些讨论，我们可以总结出文艺创作的实质在于创新和深度。真正的文艺作品不仅仅是对现实的简单模仿，更是对理想和真理的追求。评价一件文艺作品的创造力，需要考虑其在表现形式和内容上的新颖性和深度，以及是否能够启发人们深思、感受和领悟到生活的本质。\n",
            "在讨论完什么是艺术创作之后，我们来看看现如今AI是如何被应用在AI创作中的。\n序列的可控生成技术是文艺创作中的被应用最为广泛的技术。让我们详细了解这一领域及其应用。\n\n首先，整体而言，文艺创作具有很大的自由度，相关工作主要以生成式的模型系统为主。例如，在计算机视觉（CV）领域，图像风格迁移能够将一种艺术风格应用到另一张图片上；在自然语言处理（NLP）领域，我们可以看到故事续写等任务，它们本质上都是一种可控生成。\n\n幻灯片下方展示了几种应用场景：\n\n* 序列生成用于文艺创作：展示了自动生成诗词的例子。通过输入关键词，系统可以自动生成相关的诗句，这展示了序列生成技术在文学创作中的潜力。\n* 可控文本生成任务研究：展示了两个具体的研究例子。一个是故事生成，生成的故事能够按照某种逻辑线索推进；另一个是AI聊天机器人的对话生成，展示了聊天机器人是如何生成符合特定语境和风格的文本。\n\n这些例子表明，序列生成技术在文艺创作方面具有巨大的潜力。例如，自动编曲和根据关键词生成诗词等应用，不仅丰富了创作手段，还为探索新的艺术形式提供了可能性。特别引用了Zhang等人的研究论文，该研究深入探讨了如何使用基于Transformer的预训练语言模型进行可控文本生成的各种方式。\n\n通过这些技术，文艺创作可以实现更加丰富和多样化的表达形式，同时也为艺术创作者提供了强有力的工具。这种技术的发展不仅能够提高创作效率，还能激发出更多创新和独特的艺术作品。",
            "语言模型的本质是在生成可能性最大的文本序列。大型语言模型在预训练阶段会见过大量的人类语言文本，学习了在任何时候接话，使得文段合理且完整。通过这种方式，模型能够生成连贯且具有意义的文本。\n\n幻灯片展示了几个重要的应用：\n\n提示工程：通过提示工程，我们可以给AI模型“洗脑”，植入不同的人格。这种方法是引导大型模型风格化生成的最简单方式。幻灯片中展示了一些不同的人格设定，例如自信的、随和的等，通过这些设定，模型可以生成不同风格的文本。\n\n智能体相互辩论：幻灯片中还展示了不同人格的智能体之间的互动和辩论，这种方式可以用于研究AI在复杂对话和争论中的表现。通过模拟不同观点和态度的智能体互动，研究人员可以探索AI在处理辩论和逻辑推理方面的能力。\n\n总体而言，序列生成技术为文艺创作带来了丰富的可能性和多样化的表达方式。通过对大规模语言模型的训练和提示工程，我们可以引导模型生成具有特定风格和情感的文本，进一步推动文艺创作的发展和创新。",
            "图像生成技术在文艺创作中同样得到了广泛的应用。\n\n由OpenAI开发的DALLE·2是一个接受文本描述作为输入，利用多模态技术生成图像的先进工具。这种技术能够基于文本描述创造出丰富多样的视觉内容，极大地拓展了文艺创作的可能性。幻灯片展示了DALLE·2的结构和在特定文本提示下生成的图像示例。例如，“a corgi playing a flame-throwing trumpet”这样的描述可以生成一张柯基犬吹火焰喇叭的图片，展示了DALLE·2在将文字转化为图像方面的强大能力。\n\n图像生成技术的应用不仅为艺术创作提供了新的工具和手段，还拓宽了我们的视觉艺术表现形式。通过这些技术，艺术家和设计师可以更加自由地表达创意，创作出更加丰富和多样化的作品。这些工具不仅提高了创作效率，还让更多人能够参与到艺术创作中来，推动了艺术的普及和发展。",
            "首先，幻灯片展示了杰森·艾伦使用AI绘画工具Midjourney生成的作品《太空歌剧院》，这件作品在2022年末的一个艺术比赛中获得了第一名。这个例子表明，AI在图像生成和艺术创作方面已经达到了可以与人类艺术家竞争的水平。AI能够根据文本提示生成复杂且富有美感的艺术作品，展示了其强大的创意和技术能力。\n\n另一方面，幻灯片还展示了一个由网友参与的创意活动：“完成这幅画，用想象力证明你不会被AI取代”。这些简笔画和漫画作品展示了人类艺术家的独特创意和幽默感，突显了人类在艺术创作中的情感和个人风格，这些是AI难以完全复制的。\n\n讨论中提到的“灵魂画手”这一称号，让我们思考AI与人类艺术家的区别和联系。尽管AI可以生成令人惊叹的艺术作品，但人类艺术家的情感、经验和个性在艺术创作中仍然扮演着不可替代的角色。人类艺术家的每一次创作都带有他们独特的视角和感受，而这些是机器难以完全模仿的。\n\n通过这张幻灯片，我们看到了AI在艺术创作中的潜力和局限性。AI可以作为一种强有力的工具，辅助艺术创作，但真正的艺术灵魂依然属于人类艺术家。这种讨论鼓励我们继续探索AI在艺术中的应用，同时也提醒我们珍惜和发扬人类艺术家独特的创作能力和精神。",
            "AI文艺创作者是否需要人格？\n\n历史上的文艺创作常常源自创作者的深刻生命体验。从《易经》到《春秋》，从《离骚》到《国语》，还有《孙子兵法》等，每一部伟大的文学作品都与其作者的个人经历密切相关。这些作品捕捉了作者的情感、遭遇和独特视角，它们的深度和力量正来源于这种个人体验的真实性和主体性。\n\nAI文艺创作者的情感和主体性的讨论带来了有关人工智能是否需要有人格的问题。尽管AI可以模仿和再创作人类的艺术作风，但是它们是否能够体验到与生命体验相连的那种深层情感，依然是一个开放性的问题。\n\n幻灯片中展示的两首诗词，流露着浓厚的情感，背后隐含着个人经历和时代背景，它们凸显了人类创作中的深度和复杂性。真实的情感体验，以及情绪的细腻表达，是机器尚难以完全复制的。\n\n综上所述，虽然AI能在某种程度上模仿艺术创作过程中的技术层面，但在主体性和情感性方面，它们与以丰富个人经历为基础的人类艺术创作仍有很大的差距。这引发了对人工智能将如何继续融入人文艺术领域并可能改变它的更深层次讨论。而人类艺术家的不可取代之处，在于能够通过艺术表达自身独有的感受和人生体验。",
            "进一步地，我们来探讨AI在文艺创作中的角色及其可能引发的伦理问题。\n\n首先，关于伦理问题，AI用于文艺创作可能存在风险。由于AI能够生成高仿真图像和文本，可能会引发原创性、版权归属以及创作者身份等方面的争议。例如，AI生成的照片可能会被误认为是真实照片，从而在法律和社会层面引发信任危机。\n\n其次，关于AI参与文艺创作比赛的讨论，AI是否可以作为参赛者或辅助角色，取决于比赛的规则和具体的应用场景。通常，文艺创作比赛旨在展示和鼓励人类的创造力，因此，若允许AI参与，可能需要明确规定其角色和贡献，以避免对人类创作者的不公平竞争。\n\n关于作者权归属问题，目前大多数情况下，提出创意并指导AI生成作品的人通常被视为第一作者，版权也归属他们。训练和开发AI模型的人则被视为提供工具的角色。然而，随着AI生成作品的复杂度和独立性增加，版权归属问题可能变得更加复杂，可能需要进一步的法律解释和规范。\n\n最后，AI生成的照片已经可以达到以假乱真的程度，这对照片作为法律证据的可信度提出了挑战。未来，鉴别照片真伪的技术和法律规定需要进一步发展，以确保照片作为证据的可靠性。\n\n这张幻灯片中展示的新闻例子说明了当前AI生成的数字图像已经在商业和社交媒体中广泛应用，引发了对用户隐私和数据安全的关注。例如，使用AI生成的“数字分身”照片在社交媒体上广泛传播，可能带来隐私泄露和虚假信息传播的问题。\n\n总体而言，AI在文艺创作中的应用带来了许多新的机遇和挑战。我们需要在技术、法律和伦理层面进行深入讨论，以合理定位AI的角色，确保人类与AI的合作能够促进文艺创作的健康发展。 ",
            "首先，面对未来，AI在文艺创作领域的角色需要清晰界定。AI的引入带来了几个挑战：\n\n岗位替代：AI可能会取代一些低端设计工作岗位，这对于从事这些工作的艺术家来说是一个威胁。\n创意闭锁：过于依赖AI生成的内容可能导致人类创意的闭锁，阻碍原创性的发挥。\n伦理道德风险：AI生成的作品涉及版权归属和创作者身份等伦理问题，这需要进一步的法律和道德规范来解决。\n然而，AI也带来了显著的机遇：\n\n解放低端设计工作生产力：AI可以承担大量重复性和低端的设计工作，解放人类艺术家的创造力，使他们可以专注于更具创新性和艺术价值的创作。\n反哺文艺创作：AI可以作为一种工具，为艺术家提供新的创作手段和灵感，推动文艺创作的发展。\n回顾历史，我们看到技术的进步一直在推动艺术的变革。例如，15世纪以来，部分画家使用透镜等设备进行描摹，以追求写实效果。相机的出现对自然主义画派造成了冲击，但也促进了西方绘画史的进步，引发了新的艺术运动。幻灯片右侧的图像展示了艺术家使用投影设备辅助创作的例子，证明了技术工具对艺术创作的启发性和变革性影响。\n\nAI的引入有望激发艺术领域的进一步进化和丰富，尽管我们需要不断审视和适应其带来的挑战。通过合理定位AI在文艺创作中的角色，我们可以确保技术进步与人类创造力的良性互动，共同推动艺术的发展。",
            "我们来探讨AI在不同领域的应用难度和正确性的限制，并思考AI最先可能在哪个领域实现突破。\n\n首先，同样的任务对于人和人工智能而言，难易不同。AI在不同领域的表现和潜力各不相同：\n\n* 秩序维护：AI在这一领域的表现相对较好，因为它涉及现有规则的判断与执行。AI系统能够快速准确地执行大量基于规则的任务，比如交通监控和自动化的工业控制。因此，秩序维护是AI较容易实现突破的领域。\n\n* 科学研究：AI在科学研究中展现了巨大的潜力，尤其是在数据收集、归纳和总结方面。通过学习大量的科学数据和文献，AI能够帮助科学家发现新的模式和内在规律，加快科学研究的进展。然而，科学研究中的创新性和复杂性依然对AI提出了很高的要求。\n\n* 文艺创作：虽然AI已经能够生成令人印象深刻的艺术作品和文本，但创造新兴思潮并真正表达情感和深层次的人类体验，对于AI来说是一个更为复杂和挑战性的任务。文艺创作需要高度的创造力和情感共鸣，这是AI目前难以完全掌握的。\n\n从难度和“正确性”限制来看，AI在秩序维护方面最先取得显著成就，其次是科学研究，而文艺创作则是一个更长期的探索领域。\n\n思考：对于AI来说，这三个领域的难度相对递进，正如上述分析，秩序维护的任务比较明确且规则性强，因此AI在这一领域最容易实现突破。科学研究虽然复杂但具有明确的规律可循，也是AI可以发挥其强大数据处理能力的领域。而文艺创作则涉及更多的主观性和情感表达，是AI最难攻克的领域。\n\n总的来说，AI在各个领域的应用都面临着不同的挑战和机遇。随着技术的进步和发展，我们需要不断探索和评估AI在这些领域中的角色和影响，以实现技术与人类创造力的良性互动，共同推动社会的发展。",
            "尽管当前AI未必能做到顶尖，但它可以有效地辅助人类，以更高的效率和质量完成任务。AI在许多方面展示了强大的处理能力，特别是在数据分析和重复性工作中。\n\n然而，很多社会环节的智能化水平依然不足，例如：\n\n* 工作人员的路径依赖：许多工作仍依赖于人类的经验和习惯，难以完全被AI替代。\n* 特殊群体的学习困难：一些群体在适应和学习新技术方面面临困难，这限制了AI的广泛应用。\n* 算力设备的高昂成本：高性能计算设备和维护成本高，限制了AI在某些领域的普及和应用。\n\n在“人+AI+X”模型中，人类和AI应各自扮演不同的角色，以充分发挥各自的优势：\n* 人类的角色：人类擅长创意思考、情感交流和道德判断。在战略决策、创新设计和个性化服务方面，人类拥有不可替代的优势。\n* AI的角色：AI擅长处理大量数据、执行重复任务和进行快速计算。在数据分析、信息处理和自动化工作中，AI能够极大地提高效率和准确性。\n* 结合X：X代表不同领域的专业知识和具体场景。在这个模型中，人类和AI可以互相配合，将各自的优势结合起来，共同推动各行各业向智能化和高效率发展。\n* \n幻灯片中的插图展示了人类与AI在工作环境中的合作场景。合理配置时，AI可以帮助人类专注于需要人类特质的任务，例如创意和情感表达，而将数据处理和分析等可以自动化的工作交给AI。\n\n通过这样的分工合作，我们可以最大化利用AI技术的潜在价值，同时确保人类在创造和控制过程中发挥核心作用。这种协同模型不仅能够提高生产力，还可以推动各领域的创新和进步，构建更加智能化和高效的未来。",
            "AI+X的发展应当绝对以人为本，服务于人类社会的具体场景需求，并受到人类道德与利益的限制。这意味着AI技术的应用必须始终考虑到对人类社会的积极影响，同时遵循伦理和法律规范。\n\n其次，我们提出了一个前瞻性的问题：随着AI自主性的增加，在秩序维护、科学研究、艺术创作等多个领域已经有了很强自主性之后，AI是否会拥有并被允许拥有自己的小社会？\n\n幻灯片中引用了斯坦福大学的一项研究，该研究利用大模型智能体模拟人类的性格和职业角色，并让这些智能体在虚拟社区中生活和交流。这种模拟展示了AI在受控环境下的“社会化”能力，并为研究AI行为模式及其对人类行为的模仿程度提供了宝贵的数据。\n\n通过这种模拟，研究人员可以观察AI在复杂社交场景中的行为和决策过程，尽管这些行为和决策是根据设计者设定的规则和目标进行的。这表明，尽管AI可以模拟人类社会中的互动，但它们仍然缺乏人类的意识、情感和自主的道德决策能力。\n\n总结来说，尽管AI在模拟人类行为和社交互动方面展示了巨大潜力，但要实现AI自主建立和管理自己的社会，还存在许多技术和伦理上的挑战。当前的重点应当是确保AI技术在发展过程中以人为本，服务于人类的利益和需求。未来，随着技术的进步和对AI理解的加深，我们可能会看到更多AI在不同社会和文化情境下的应用和探索。"
        ],
        "recommend_reason": "夏熠对AI的兴趣不仅在技术方面，也在于其伦理和文化影响，这与选中片段中的内容息息相关。该片段深入探讨AI在艺术创作中的应用和挑战，不仅符合夏熠的兴趣，同时涉及到伦理问题，这与推荐策略中的AI伦理问题关注高度一致。此外，该片段为分析层次，适合夏熠对高阶思维的需求，有助于他进一步发展批判性思维和探索精神。",
        "adaptation_result": {
            "error": "ParseError",
            "response": "{\n  \"start_speech\": \"同学，接下来我们从刚才谈到的人工智能技术应用于多个领域，特别是其在艺术创作中的挑战和机遇出发，探索AI如何在这一领域体现其独特价值。\",\n  \"refined_scripts\": [\n    \"接下来，我们来讨论人工智能在艺术创作这一领域中的应用和挑战。我们刚刚提到，AI在多个领域都有着突破，而在艺术方面，它不仅需要模仿，还必须创新。首先，让我们简单回顾一下艺术创作的发展历程。在中世纪，艺术主要服务于宗教目的，表现宗教故事和神圣性。幻灯片展示了拜占庭镶嵌画，充满宗教色彩和象征意义。随后，文艺复兴则强调写实与解放思想，《蒙娜丽莎》和《圣母怜子图》是经典例子。现代主义则挑战传统，反映工业革命和城市化的社会变化。毕加索的《亚维农的少女》和梵高的《星夜》就是典型代表。从历史看，艺术风格随社会、经济、技术背景变化而演进，对未来创作者产生深远影响。AI若能在此领域创新，则不仅是巨大的机会，也是严峻的挑战。\",\n    \"在文艺创作中，我们看到感性与理性的两种不同角色。艺术作品不仅是个人情感的表达，当这种情感引发群体共鸣时，就形成特定的艺术风格。幻灯片中的《泉》和《4'33\\\"》便是挑战传统艺术定义的例子，前者通过重新命名改变艺术界限，后者则通过无声音乐质疑音乐本质。这些作品体现了文艺创作中的感性表达和理性制约。譬如，中国古代诗词中，唐诗的严格格律要求使其成为致美之作。这种不断在感性与理性之间探索的辩证关系，推动了艺术的发展，提供了未来创作者创新的灵感。\",\n    \"我们继续探讨，文艺创作的实质是什么？是否简单的模仿或组合基本元素可以算作艺术创作？柏拉图曾认为，艺术应反映世界的本质，追求真理和意义。幻灯片中拉斐尔的《雅典学院》象征着理性与艺术的结合，它展示了哲学家们对理想世界的探索和现实思辨。总结来说，真正的艺术作品不仅要展示创新，更需追求深度，启发思考和感悟生活本质。\",\n    \"讨论完艺术创作，我们看看AI目前在艺术中的应用。文艺创作通常具有很大自由度，生成模型在这方面有广泛应用。例如，图像风格迁移和故事续写它们本质上属于序列生成技术。幻灯片展示了自动生成诗词及故事生成的例子，通过关键词输入，系统能自动生成文本和对话，其背后是基于Transformer的预训练语言模型。这些技术不仅提高了艺术创作效率，还激发了更多的创意可能。\",\n    \"语言模型的核心在于生成最可能的文本序列。在预训练阶段，模型学习到如何在话语中生成连贯的文本。幻灯片展示了提示工程的应用，能够为AI植入人格，从而风格化文本生成。不同人格的AI互动展示出AI在复杂对话中的能力。总之，这种技术推动了艺术创作的多样化和创新发展。\",\n    \"图像生成技术在艺术中得到了广泛应用，特别是OpenAI的DALLE·2，这个工具通过文本描述生成丰富的视觉内容。幻灯片示例中的柯基犬吹火焰喇叭便体现了这种技术的强大。这些工具不仅提高了效率，还让更多人能参与艺术创作，推动了视觉艺术的普及和发展。\",\n    \"继续来看，幻灯片展示了AI与人类艺术家的创作对比。尽管AI能够生成复杂且具美感的作品，如《太空歌剧院》，但人类艺术家的创意和情感是AI难以复制的。这提醒我们人类在创作中的独特角色。AI可以辅助创作，而真正蕴含灵魂的艺术依然是人类的成就。\",\n    \"AI文艺创作者是否需要情感与主体性？历史上的伟大作品多源于作者深刻的生命体验与独特视角。AI虽然能再现人类艺术风格，但是否能体验到生命的真正情感仍是未知。幻灯片中展示的诗词就体现了复杂的情感和时代背景，这种体验是AI尚无法复制的。\",\n    \"进一步地，我们探讨AI在文艺创作中的伦理问题以及其应用风险。AI生成的高仿真图像可能引发原创性和版权归属的争议。而在比赛中，AI的角色需要明确规定，确保公平竞争。版权归属随着AI独立性增加可能需法律解释。AI生成的照片也对法律证据可靠性提出挑战。研究表明数字图像广泛应用需关注隐私和数据安全。\",\n    \"AI在文艺创作中的角色需要清晰定位。它带来了岗位替代、创意闭锁和伦理问题的挑战。但AI也解放了低端设计工作，提高生产力，提供新的创作手段。透镜和相机的历史例子展示了技术对艺术的启发和变革。AI可能进一步激发艺术进化，需要合理定位其角色。\",\n    \"AI在不同领域表现各异，秩序维护较易突破，因为它涉及规则判断与执行。科学研究中，AI在数据分析方面潜力巨大，但创新要求仍高。文艺创作需高度创造力，目前仍是长期探索领域。秩序维护最可能先取得成效，科学研究次之，文艺创作最具挑战。\",\n    \"尽管当前AI未必能成为顶尖，但能有效辅助人类高效完成任务。"
        }
    },
    {
        "title": "module_ai_plus_part2_夏熠",
        "original_content": [
            "1956年达特茅斯会议标志着人工智能学科的诞生。在会议上，神经网络是七个主要议题之一。在第一次人工智能浪潮中，研究人员提出了单隐藏层感知机。这是一种简单的单层神经网络，可以用来进行图像识别。在第二次人工智能浪潮中，图灵奖得主Hinton提出了反向传播算法，解决了多层神经网络难以训练的问题。2010年后的今天，随着数据的积累和算力的持续发展，我们已经可以训练层数更多的深度神经网络模型。\n\n从历史趋势来看，神经网络一直都是人工智能研究的重要方向。随着算法、数据和算力的发展，神经网络模型呈现深度不断增加的趋势。",
            "\n1943年，心理学家McCulloch和数理逻辑学家Pitts提出了神经元模型，启发了后续对人工智能学科中神经网络设计的研究，开启了神经网络研究的第一次浪潮。\n\n生物神经元通过众多树突接受其他神经元的信号，将刺激传导到轴突并通过轴突向其他神经元传递信号。根据生物神经元的工作机理，以上两位科学家提出了数学上的神经元模型，对多个输入x1到xn进行加权求和的操作，经过一个非线性的激活函数之后输出数值。它可以接受多个输入并产生输出信号。\n\n这个模型模拟了生物神经元的基本功能，为理解大脑如何通过神经元网络处理信息打开了一扇窗。\n",
            "继我们刚刚讨论的McCulloch和Pitts模型之后，1957年心理学家Frank Rosenblatt带来了Mark I Perceptron，这是首个以硬件实现的单隐藏层感知机，主要应用于图像识别。\n\n在1989年，通用近似定理被证明，定理指出具有具有足够多神经元的单隐藏层感知机具有拟合任何连续函数的能力。\n\n然而，1969年Minsky和Papert的研究揭示了其局限性，指出单层感知机无法解决诸如异或（XOR）这样的复杂逻辑问题。这导致了神经网络研究的走向第一次低潮。",
            "在经历了一段低谷期后，神经网络的研究于八十年代迎来了第二次浪潮。1986年，图灵奖得主Geoffrey Hinton验证了反向传播算法，使多层神经网络的训练存在一种高效路径。紧接着，1989年Yann LeCun发展了早期的卷积神经网络原型，极大地推动了计算机视觉领域的发展。2000年，Yoshua Bengio提出了神经概率语言模型，为自然语言处理技术的进步做出了重要贡献。这些进展标志着神经网络技术开始步入成熟阶段，为未来的人工智能应用打下坚实的基础。\n\n在2018年，Geoffrey Hinton、Yann LeCun与Yoshua Bengio也因他们在神经网络发展中做出的重要贡献获得计算机领域最高奖项——图灵奖。",
            "进入21世纪，神经网络的研究和应用迎来了第三次浪潮。2006年，Geoffrey Hinton等人提出了结合无监督预训练和有监督微调的深度学习策略，显著提升了深度网络的学习效率。此后，深度学习领域的研究如雨后春笋，特别是在2010年之后，ImageNet挑战赛催生了一系列神经网络领域的技术突破。尤其是2012年AlexNet的获胜，显著推动了深度卷积神经网络在图像识别领域的应用，彰显了深度学习在处理大规模数据方面的巨大潜力。同时，这一时期的重大进展不仅局限于图像领域，微软和谷歌在语音识别和自然语言处理上的进展也为人工智能的实际应用和未来发展铺平了道路。",
            "如今，我们正生活在人工智能的黄金时代。2018年，OpenAI和Google带来了GPT和BERT这样的预训练模型，它们利用大量数据的预训练加上任务特定的微调，显著提升了模型在各种自然语言处理任务中的性能。随着OpenAI发布GPT-3、ChatGPT等模型，我们迈入了大模型时代，这些模型的应用范围更广泛，性能更加强大，正在改变我们与技术的互动方式。在这张从OpenAI到ChatGPT的演化树上，我们可以看到人工智能技术快速发展的壮观历程，这并不仅仅是技术的进步，更代表着人类对知识的积累和潜力的解放。",
            "下面，我们将讨论为什么虽然具有单个隐藏层的感知机具有拟合任何连续函数的能力，我们仍然追求拓展神经网络的深度。\n\n第一，神经网络之所以越深越好，是因为它们具有层级特征学习能力。以图像分类这一任务为例。深层神经网络可以从简单的视觉边缘开始，逐层捕捉并学习到更复杂的结构，最终实现对复杂对象的识别。\n\n第二，这些网络的深度还赋予了它们强大的非线性建模能力，通过多层的叠加，网络能够捕捉输入与输出之间更为复杂的模式和关系。\n\n第三，更深的网络还增强了数据的可分性，这是通过非线性变换将数据映射到新的特征空间实现的，在这个空间中不同的类别更容易被区分开来。这些优势共同作用，使得深度学习模型可以自动地从数据中发现规律，从而成为了解决许多复杂问题的强有力工具。\n",
            "深度神经网络的训练和发展离不开数据的积累。正如这张幻灯片展示的那样，从医疗的fMRI/DTI图像到金融市场的股票数据，从媒体娱乐到零售巨头沃尔玛每小时产生的2.5PB数据，再到工业、生物和商业领域的各类数据，所有这些都是深度学习的潜在知识来源。而随着人类活动的不断扩大，在大数据时代背景下，到2025年全球数据总量预计将达到惊人的181ZB，这些海量数据的积累不仅反映了我们生活的方方面面，还为深度学习模型提供了丰富的训练素材，使得模型能够不断进化，更好地服务于社会的各个层面。",
            "同时，深度学习的进步还得益于计算能力的显著提升。\n\n大家也许听过摩尔定律，也就是算力会在每18-24个月增加一倍。\n最新的NVIDIA DGX B200计算平台就是一个典型例子。这个平台在训练性能上达到了72 petaFLOPS，即每秒进行7.2亿亿次运算，在推理性能上更是达到了144 petaFLOPS，显著加速了深度学习任务的处理速度。这里的FLOPS指的是每秒钟的浮点计算次数。\n\n过去几十年中，随着GPU等计算资源的飞速发展，我们在处理语言、视觉和其他类型任务时的计算能力呈指数级增长。这种算力的增长为大型模型的训练提供了可能，使得我们能够解锁深度学习在多个领域的潜力，从而推动智能计算技术向前发展。",
            "让我们从神经元模型开始，了解深度学习背后的生物学基础。生物神经元，也就是神经细胞，是构成我们神经系统的基本单元，能够接收和传递电信号。正如这张幻灯片上展示的图片，神经元由树突（接收信息）、轴突（传递信息）和细胞体组成。我们的大脑大约有860亿个这样的神经元相互连接，形成一个复杂的网络。在人工智能领域，这种生物神经元的结构被抽象成了人工神经元模型，它是深度学习中神经网络的基础构件。通过模拟这样的网络，我们可以实现能够执行各种任务的算法，从简单的分类到复杂的决策制定。这种由生物灵感而来的建模，架起了自然界与人工智能之间的桥梁。",
            "如图所示，人工神经元正是由生物神经元的原理演化而来的数学模型，它是构成人工神经网络的基础单元。\n\n在这个模型中，我们可以看到一个神经元可以接收多个输入信号 $\\( x_1, x_2, ..., x_n \\)$，在这里每一个输入信号都是一个具体的小数。每个输入都通过一个权重\\( w_1, w_2, ..., w_n \\)进行加权，然后这些加权的信号会被汇总，再加上一个偏置项\\( b \\)。\n\n之后，总输入值将通过一个激活函数进行转换，如果超过了一定的阈值，那么神经元就会产生输出信号。\n\n这个简化模型抓住了生物神经元的核心特性，在此基础上，人们构建出各种复杂的深度学习网络架构，应用于语音识别、图像处理和许多其他领域。\n",
            "形式化而言，如这个幻灯片所示，每个输入信号\\( x_i \\)都会乘以一个相应的权重\\( w_i \\)，然后所有加权的输入会相加，并加上一个偏置项\\( b \\)。得到的总和会通过函数\\( \\sigma \\)进行转换，也就是我们提到的激活函数，从而得出输出结果\\( y \\)。数学表达式为 \\( y = \\sigma(w_1x_1 + w_2x_2 + ... + w_nx_n + b) \\)，也可以写作 \\( y = \\sigma(b + \\sum_{i=1}^{n} w_ix_i) \\)。通过这个公式，我们能够计算出单个神经元对于给定输入的响应输出。\n",
            "激活函数在人工神经网络的作用是增加非线性性，即使神经元的最终输出并非单纯的是所有输入信号的线性加权。它们决定了一个神经元是否应该被激活，从而影响信号是否传递。\n\n激活函数的设置受启发于生物神经元，在生物神经元中，只有输入信号强度超过一定阈值，神经元才会被激活并向下传递信号。\n\n常见的激活函数如ReLU、Sigmoid和Tanh。ReLU函数是一种简单的非线性函数，当输入值为正时直接传递，否则输出为零；Sigmoid函数将输入值映射到0和1之间，经常用于二分类问题；而Tanh函数则将输入值映射到-1和1之间，形状类似Sigmoid但输出范围更广。这幅图直观地展示了这三种函数的形状和它们的输出范围。感兴趣的同学可以自行搜索三个激活函数的具体公式，在本节课中我们并不展开叙述。\n\n选择合适的激活函数对于神经网络的学习能力和性能有着直接影响。",
            "我们来看一个神经元的实际例子。\n在这个实际例子中，我们用一个神经元模型来决定今晚应该外出吃饭还是在家做饭。这里神经元的输入包括饥饿程度、天气状况和财务状况，每个因素都被赋予了一个权重和0到1之间的分值。\n\n我们将这些输入进行加权求和，然后通过Sigmoid激活函数处理。具体计算为 \\( y = \\sigma(0.9 \\times 0.6 + 0.5 \\times 0.5 + 0.2 \\times 0.1 + 0) = \\sigma(0.69) \\)，由于0.69大于Sigmoid函数的阈值0.5，所以应该选择外出吃饭。通过这个例子，我们可以看到神经元是如何处理不同因素并作出决策的。\n\n接着，我们将了解神经网络是如何通过连接多个这样的神经元来处理更复杂的问题。",
            "将多个神经元组合可以形成单层的神经网络。单层神经网络包含一个输入层和一个输出层，中间没有隐藏层。在这里，我们可以看到多个输入\\( x_1, x_2, ..., x_n \\)通过权重矩阵\\( W \\)连接到多个输出\\( y_1, y_2, ..., y_m \\)。\n\n也就是说，对于每一个橙色的神经元，每个神经元有自己的一套权重作用于输入\\( x_1, x_2, ..., x_n \\)，并进行加权求和。这实际上就是对\\( x_1, x_2, ..., x_n \\)组成的x向量进行线性矩阵乘Wx + b。\n\n整个过程可以用数学公式表达为：\\( y = \\sigma(Wx + b) \\)，其中，\\( \\sigma \\)是激活函数，\\( W \\)是权重矩阵，\\( x \\)是输入向量，\\( b \\)是偏置向量。\n\n这种网络结构虽然简单，但对于某些问题已经足够有效。接下来，我们将探索多层神经网络，以及它们如何通过增加层次来增强网络的复杂性和表现力。",
            "现在，我们转向多层神经网络的结构，这是一种更为强大的神经网络架构。\n\n与单层网络不同，多层网络通过添加一个或多个隐藏层来学习数据中复杂的抽象特征。在这个示意图中，我们可以看到输入层\\( x \\)通过连接权重\\( W_1 \\)和偏置\\( b_1 \\)与隐藏层相连，隐藏层\\( h \\)再通过另一组权重\\( W_2 \\)和偏置\\( b_2 \\)与输出层\\( y \\)相连。\n\n隐藏层允许网络学到从简单到复杂的数据表示，使得网络能够解决比单层网络更复杂的问题。我们可以继续叠加层数或者增加隐藏层神经元数量，使得模型规模进一步增大。下一步，我们会探讨如何训练这些多层网络，以及如何通过调整权重和偏置来优化它们的性能。",
            "通过使用多层神经网络，我们可以捕捉到更加复杂的决策模式。比如在晚餐场景中，当我们思考天气对决定的影响时，在单层神经网络中，我们使用一个抽象的数值来表示天气的好坏。在实际场景中，我们往往需要结合温度和风速等具体的气象因素，来最终判断天气是好还是坏。我们可以将这些具体的特征输入给多层神经网络，这些因素经过隐藏层的处理，最终合成为一个抽象的\"天气\"影响因素。在单层神经网络中，我们需要自行定义天气好坏程度的计算方法。与之对比，多层神经网络可以自行从具体的特征中，总结、学习出抽象的特征，提升了多层神经网络的通用性。\n\n同样的，其他如饥饿程度、上一次吃饭间隔的时间等因素也可以经过相似的处理。这些特征的提取并非有研究人员手动进行，而是在模型训练过程中由模型自行学习提取，因此它们也被称为隐状态（hidden states）。这个加深的理解能力是多层神经网络带给我们的优势。",
            "我们已经走过了从单个人工神经元的基本理解，到单层和多层神经网络的构建过程。\n\n人工神经元作为生物神经元的数学模型，包含输入信号、连接权重、阈值和激活函数等部分。单个神经元具有综合一系列输入特征决定一个输出的功能。多个神经元可以组成单层神经网络，实现多个输入特征的处理，并产生多个输出。多层神经网络通过添加隐藏层进一步增强了模型捕捉数据中抽象特征的能力。\n\n这些层级结构的网络可以处理复杂问题，通过训练和调整，它们能够学习并预测我们希望它们了解的模式。至此，我们对神经网络的基础框架有了一个清晰的认识。接下来，我们将进入神经网络的学习过程，即如何使用数据来训练这些网络，使它们能够完成特定的任务。",
            "现在，我们进入神经网络的核心部分——训练算法。\n\n神经网络的训练本质上是一个优化问题，目的是找到最优的权重\\(W_1, W_2\\)和偏置\\(b_1, b_2\\)，以便网络能够准确预测或分类数据。\n\n如图所示，在收集了一个用户关于“是否外出吃饭”这一事件的数据之后，我们需要使用这批数据训练我们的神经网络模型，使得他可以准确地根据输入特征进行预测。",
            "梯度下降法是一种在神经网络训练中被广泛应用的优化算法。梯度下降法的核心思想是利用损失函数的梯度来指导参数的更新，目的是最小化损失函数的值，即减少预测误差。\n\n损失函数，或者说误差函数，是用来衡量模型预测值（给定输入后，模型产生的输出）与真实值（训练数据中，对应的真实标签）之间差异的一个函数。我们的目标是调整模型参数，使得这个损失函数的值尽可能小。\n\n梯度下降的操作可以比喻为在山上寻找最低点。想象你在山顶，目标是到达山脚。每一步移动都需要选择让你的海拔下降最快的方向。在神经网络中，每一步的“移动”实际上就是对权重和偏置的小幅调整，这些调整是基于损失函数梯度的方向和大小来确定的。\n\n在我们的“是否外出吃饭”预测模型中，这意味着我们希望减少模型预测用户是否会看外出与实际情况之间的误差。下面，我们将看到损失函数是如何在实践中应用的，以及我们如何具体实施梯度下降来优化我们的神经网络。"
        ],
        "recommend_content": [
            "让我们从神经元模型开始，了解深度学习背后的生物学基础。生物神经元，也就是神经细胞，是构成我们神经系统的基本单元，能够接收和传递电信号。正如这张幻灯片上展示的图片，神经元由树突（接收信息）、轴突（传递信息）和细胞体组成。我们的大脑大约有860亿个这样的神经元相互连接，形成一个复杂的网络。在人工智能领域，这种生物神经元的结构被抽象成了人工神经元模型，它是深度学习中神经网络的基础构件。通过模拟这样的网络，我们可以实现能够执行各种任务的算法，从简单的分类到复杂的决策制定。这种由生物灵感而来的建模，架起了自然界与人工智能之间的桥梁。",
            "如图所示，人工神经元正是由生物神经元的原理演化而来的数学模型，它是构成人工神经网络的基础单元。\n\n在这个模型中，我们可以看到一个神经元可以接收多个输入信号 $\\( x_1, x_2, ..., x_n \\)$，在这里每一个输入信号都是一个具体的小数。每个输入都通过一个权重\\( w_1, w_2, ..., w_n \\)进行加权，然后这些加权的信号会被汇总，再加上一个偏置项\\( b \\)。\n\n之后，总输入值将通过一个激活函数进行转换，如果超过了一定的阈值，那么神经元就会产生输出信号。\n\n这个简化模型抓住了生物神经元的核心特性，在此基础上，人们构建出各种复杂的深度学习网络架构，应用于语音识别、图像处理和许多其他领域。\n",
            "形式化而言，如这个幻灯片所示，每个输入信号\\( x_i \\)都会乘以一个相应的权重\\( w_i \\)，然后所有加权的输入会相加，并加上一个偏置项\\( b \\)。得到的总和会通过函数\\( \\sigma \\)进行转换，也就是我们提到的激活函数，从而得出输出结果\\( y \\)。数学表达式为 \\( y = \\sigma(w_1x_1 + w_2x_2 + ... + w_nx_n + b) \\)，也可以写作 \\( y = \\sigma(b + \\sum_{i=1}^{n} w_ix_i) \\)。通过这个公式，我们能够计算出单个神经元对于给定输入的响应输出。\n",
            "激活函数在人工神经网络的作用是增加非线性性，即使神经元的最终输出并非单纯的是所有输入信号的线性加权。它们决定了一个神经元是否应该被激活，从而影响信号是否传递。\n\n激活函数的设置受启发于生物神经元，在生物神经元中，只有输入信号强度超过一定阈值，神经元才会被激活并向下传递信号。\n\n常见的激活函数如ReLU、Sigmoid和Tanh。ReLU函数是一种简单的非线性函数，当输入值为正时直接传递，否则输出为零；Sigmoid函数将输入值映射到0和1之间，经常用于二分类问题；而Tanh函数则将输入值映射到-1和1之间，形状类似Sigmoid但输出范围更广。这幅图直观地展示了这三种函数的形状和它们的输出范围。感兴趣的同学可以自行搜索三个激活函数的具体公式，在本节课中我们并不展开叙述。\n\n选择合适的激活函数对于神经网络的学习能力和性能有着直接影响。",
            "我们来看一个神经元的实际例子。\n在这个实际例子中，我们用一个神经元模型来决定今晚应该外出吃饭还是在家做饭。这里神经元的输入包括饥饿程度、天气状况和财务状况，每个因素都被赋予了一个权重和0到1之间的分值。\n\n我们将这些输入进行加权求和，然后通过Sigmoid激活函数处理。具体计算为 \\( y = \\sigma(0.9 \\times 0.6 + 0.5 \\times 0.5 + 0.2 \\times 0.1 + 0) = \\sigma(0.69) \\)，由于0.69大于Sigmoid函数的阈值0.5，所以应该选择外出吃饭。通过这个例子，我们可以看到神经元是如何处理不同因素并作出决策的。\n\n接着，我们将了解神经网络是如何通过连接多个这样的神经元来处理更复杂的问题。",
            "将多个神经元组合可以形成单层的神经网络。单层神经网络包含一个输入层和一个输出层，中间没有隐藏层。在这里，我们可以看到多个输入\\( x_1, x_2, ..., x_n \\)通过权重矩阵\\( W \\)连接到多个输出\\( y_1, y_2, ..., y_m \\)。\n\n也就是说，对于每一个橙色的神经元，每个神经元有自己的一套权重作用于输入\\( x_1, x_2, ..., x_n \\)，并进行加权求和。这实际上就是对\\( x_1, x_2, ..., x_n \\)组成的x向量进行线性矩阵乘Wx + b。\n\n整个过程可以用数学公式表达为：\\( y = \\sigma(Wx + b) \\)，其中，\\( \\sigma \\)是激活函数，\\( W \\)是权重矩阵，\\( x \\)是输入向量，\\( b \\)是偏置向量。\n\n这种网络结构虽然简单，但对于某些问题已经足够有效。接下来，我们将探索多层神经网络，以及它们如何通过增加层次来增强网络的复杂性和表现力。",
            "现在，我们转向多层神经网络的结构，这是一种更为强大的神经网络架构。\n\n与单层网络不同，多层网络通过添加一个或多个隐藏层来学习数据中复杂的抽象特征。在这个示意图中，我们可以看到输入层\\( x \\)通过连接权重\\( W_1 \\)和偏置\\( b_1 \\)与隐藏层相连，隐藏层\\( h \\)再通过另一组权重\\( W_2 \\)和偏置\\( b_2 \\)与输出层\\( y \\)相连。\n\n隐藏层允许网络学到从简单到复杂的数据表示，使得网络能够解决比单层网络更复杂的问题。我们可以继续叠加层数或者增加隐藏层神经元数量，使得模型规模进一步增大。下一步，我们会探讨如何训练这些多层网络，以及如何通过调整权重和偏置来优化它们的性能。",
            "通过使用多层神经网络，我们可以捕捉到更加复杂的决策模式。比如在晚餐场景中，当我们思考天气对决定的影响时，在单层神经网络中，我们使用一个抽象的数值来表示天气的好坏。在实际场景中，我们往往需要结合温度和风速等具体的气象因素，来最终判断天气是好还是坏。我们可以将这些具体的特征输入给多层神经网络，这些因素经过隐藏层的处理，最终合成为一个抽象的\"天气\"影响因素。在单层神经网络中，我们需要自行定义天气好坏程度的计算方法。与之对比，多层神经网络可以自行从具体的特征中，总结、学习出抽象的特征，提升了多层神经网络的通用性。\n\n同样的，其他如饥饿程度、上一次吃饭间隔的时间等因素也可以经过相似的处理。这些特征的提取并非有研究人员手动进行，而是在模型训练过程中由模型自行学习提取，因此它们也被称为隐状态（hidden states）。这个加深的理解能力是多层神经网络带给我们的优势。",
            "我们已经走过了从单个人工神经元的基本理解，到单层和多层神经网络的构建过程。\n\n人工神经元作为生物神经元的数学模型，包含输入信号、连接权重、阈值和激活函数等部分。单个神经元具有综合一系列输入特征决定一个输出的功能。多个神经元可以组成单层神经网络，实现多个输入特征的处理，并产生多个输出。多层神经网络通过添加隐藏层进一步增强了模型捕捉数据中抽象特征的能力。\n\n这些层级结构的网络可以处理复杂问题，通过训练和调整，它们能够学习并预测我们希望它们了解的模式。至此，我们对神经网络的基础框架有了一个清晰的认识。接下来，我们将进入神经网络的学习过程，即如何使用数据来训练这些网络，使它们能够完成特定的任务。",
            "现在，我们进入神经网络的核心部分——训练算法。\n\n神经网络的训练本质上是一个优化问题，目的是找到最优的权重\\(W_1, W_2\\)和偏置\\(b_1, b_2\\)，以便网络能够准确预测或分类数据。\n\n如图所示，在收集了一个用户关于“是否外出吃饭”这一事件的数据之后，我们需要使用这批数据训练我们的神经网络模型，使得他可以准确地根据输入特征进行预测。",
            "梯度下降法是一种在神经网络训练中被广泛应用的优化算法。梯度下降法的核心思想是利用损失函数的梯度来指导参数的更新，目的是最小化损失函数的值，即减少预测误差。\n\n损失函数，或者说误差函数，是用来衡量模型预测值（给定输入后，模型产生的输出）与真实值（训练数据中，对应的真实标签）之间差异的一个函数。我们的目标是调整模型参数，使得这个损失函数的值尽可能小。\n\n梯度下降的操作可以比喻为在山上寻找最低点。想象你在山顶，目标是到达山脚。每一步移动都需要选择让你的海拔下降最快的方向。在神经网络中，每一步的“移动”实际上就是对权重和偏置的小幅调整，这些调整是基于损失函数梯度的方向和大小来确定的。\n\n在我们的“是否外出吃饭”预测模型中，这意味着我们希望减少模型预测用户是否会看外出与实际情况之间的误差。下面，我们将看到损失函数是如何在实践中应用的，以及我们如何具体实施梯度下降来优化我们的神经网络。",
            "在这一页中，我们会进一步深入理解梯度下降法的具体操作步骤。首先，我们有一个误差函数\\(L\\)，它衡量的是网络预测的输出与真实标签之间的误差。我们的目标是调整权重\\(w\\)，最小化这个误差函数。具体来说：\n步骤如下：\n\n1. 选择初始权重：这一步非常重要，因为它定义了我们开始搜索最小误差的位置。\n2. 计算梯度：在当前权重下，计算误差函数的梯度 \\(\\nabla_w L\\)。这一步是找出误差函数下降最快的方向。\n3. 更新权重：根据计算出的梯度更新权重，公式为 \\(w \\leftarrow w - \\eta \\nabla_w L\\)，其中 \\(\\eta\\) 是学习率，它决定了每一步向梯度相反方向迈出的大小。\n4. 重复迭代：持续这个过程，直到误差函数的值不再显著降低，或者达到预设的迭代次数。\n\n其中学习率 \\(\\eta\\) 的选择至关重要，因为它影响优化的速度和质量。如果学习率太大，可能会导致在最小值附近震荡甚至偏离最优解；如果太小，则可能导致收敛速度过慢，增加训练时间。\n\n在这里，梯度就是误差函数下降最快的方向，当模型参数只有一个数时，梯度也就是我们高中数学中学习到的“导数”。\n\n通过这种方法，我们可以有效地调整神经网络的权重，使其输出尽可能接近我们希望的结果，从而最小化预测误差。下一页，我们将讨论如何处理优化过程中可能遇到的一些挑战。",
            "这张幻灯片展示了一个基于梯度下降法的简单神经网络训练例子。我们有一个单一神经元，使用ReLU激活函数，这是一个非线性函数，允许模型捕获更复杂的数据模式。在这个例子中，ReLU函数的输出是输入x乘以权重w加上偏置b的结果。输入信号通过ReLU激活函数处理，输出预测结果。这个简单的模型设置为一个分类问题，当激活函数的输出大于0.5时，模型预测结果为\"外出\"。我们可以从这个例子中看到，训练数据包括输入和对应的真实输出，模型通过调整权重w和偏置b来尽量减少预测输出与真实输出之间的差异，即通过最小化损失函数来进行学习。我们接下来会讨论模型如何通过更新这些参数，采用梯度下降法迭代地减少预测误差，从而有效地学习给定的训练数据。",
            "这张幻灯片向我们展示了采用ReLU激活函数的单神经元在经过70个梯度下降步骤后的参数变化和预测性能。\n\n在本例中，我们从 \\( w = 0.1 \\) 和 \\( b = 0.1 \\) 开始，并观察到通过多次迭代后，权重和偏置发生了显著变化，分别调整至 \\( w = 10.95 \\) 和 \\( b = -7.02 \\)。这些调整是基于损失函数的梯度，并通过梯度下降算法逐步进行的。\n\n我们可以看到，每次更新都是为了减少预测输出和真实标签之间的误差，通过这种方式，模型逐渐学习如何准确预测结果。例如，经过调整后，神经元对不同输入的响应发生了变化，从而更接近实际的标签。例如，当 \\( y'_2 \\) 的值从较小的数值增加至1.735，表明模型对某些特定输入的预测更加自信地接近于“外出”。\n\n这个过程说明了神经网络训练中梯度下降法的效果，以及如何通过多次迭代优化权重和偏置以改善模型性能。在实际应用中，调整这些参数需要仔细选择学习率和迭代次数，以确保模型具有良好的预测准确率。\n\n这个例子细节地展示了神经网络的训练过程，其中涉及了不少数学运算。如果你对该过程感兴趣，不妨动手算一算吧！当然，如果你对数学计算不甚了解，这也不影响后续课程内容的学习！",
            "刚才我们展示了一个简单神经元的训练过程。进一步地，对于多层神经网络的优化，反向传播算法是其中关键技术。它允许我们根据损失函数——即模型输出与实际数据之间的误差——来自动地计算每个参数的梯度，从而调整神经网络网络中各层的权重。\n\n反向传播算法通过以下几个步骤展开：\n\n1. 前向传播：数据通过网络前向传递，每层的输出依赖于其权重、偏置和前一层的输出。这个过程一直持续到输出层，最终产生一个预测结果。\n\n2. 损失计算：在网络的最后，计算预测结果与真实标签之间的误差。这个误差就是我们所说的损失。\n\n3. 反向传播：为了减少损失，我们需要调整网络的权重和偏置。反向传播算法从输出层开始，逆向通过网络传递误差信息。这一过程使用链式法则来计算每个权重对损失的贡献。\n\n4. 梯度下降：知道了每个权重如何影响损失后，我们可以使用梯度下降法更新权重，以减少总体误差。具体来说，每个权重更新为原权重减去其梯度乘以学习率。\n\n这张幻灯片中的图解清晰地展示了这一过程。通过自动微分技术，即计算图和链式法则，每个权重的梯度都能被准确计算出来，从而有效地指导网络学习。这种方法确保了神经网络能够根据实际表现逐步优化，最终达到较高的预测准确性。",
            "这张幻灯片详细介绍了均方误差（MSE）损失函数，这是深度学习特别是在回归任务中常用的一种损失函数。均方误差通过计算模型预测值与实际值之间差值的平方然后取平均来衡量预测的准确性。\n\n例如，如果一个模型对某个事件发生的预测概率是 75%，而实际发生了（真实值为 1），则该预测的误差为 \\( (1 - 0.75)^2 = 0.0625 \\)。这个计算反映了预测值与实际值之间的偏差程度，损失越小，说明模型的预测准确性越高。\n\n在实际应用中，我们通常使用这种损失函数来训练模型，目标是最小化整体的 MSE，从而优化模型的预测性能。通过不断地调整网络参数，比如权重和偏置，模型能够逐渐学习到如何减少预测误差，最终达到较高的准确度。这个过程是机器学习和深度学习训练中不可或缺的，它直接关系到模型能否有效地解决具体的问题。",
            "这张幻灯片介绍了交叉熵损失函数，它是处理分类问题时非常关键的一个工具。交叉熵损失衡量的是模型输出的概率分布与目标真实分布之间的差异。在分类任务中，这种损失函数尤为有用，因为它可以有效地处理那些分类正确与否非常重要的场景。\n\n公式为：\n\\[ CE(y, t) = -\\sum_{i=1}^{N} t_i \\log y_i \\]\n其中，\\( y_i \\) 是模型对每个类别预测的概率，而 \\( t_i \\) 是真实的目标分布，通常用 one-hot 编码表示，即正确类别的位置为1，其余为0。\n\n例如，如果一个模型对某个类别的预测概率是75%，即 \\( y_i = 0.75 \\)，并且这是正确的分类，那么交叉熵损失为:\n\\[ -\\log(0.75) \\approx 0.287 \\]\n这意味着，如果模型的预测完全正确（概率为100%），交叉熵损失则为0，这是最佳情况。损失为0表示预测分布与真实分布完全一致，这是所有机器学习模型的目标。\n\n理解并有效使用交叉熵损失函数可以帮助我们更好地训练分类模型，通过最小化这个损失值，我们的模型可以学习到如何提高预测的准确性。\n\n\n总结一下，神经网络的训练过程常采用梯度下降法，该方法的目标是逐步优化神经网络参数，使得模型预测值与真实值之间的误差逐步减小。反向传播算法是一种自动计算多层神经网络梯度的算法，能够使神经网络计算高度自动化。刚才的学习涉及非常多数学运算，大家千万不要被难倒啦，感兴趣的同学可以翻阅更多课外资料！"
        ],
        "recommend_reason": "选择该片段是因为它直接涉及和详述了梯度下降法及其在神经网络训练中的应用，正契合学生当前短期目标之一，即理解反向传播算法。这部分内容通过实际例子阐述权重和偏置的更新过程，与推荐策略中的学习兴趣和短期目标对齐，并且处于 Bloom 分类的理解阶段，适合夏熠的当前能力水平。",
        "adaptation_result": {
            "start_speech": "同学们，接下来我们从刚才谈到的神经元模型出发，深入探索深度学习的生物学基础。",
            "refined_scripts": [
                "我们刚刚提到了生物神经元的基础，现在让我们看看这些神经元是如何构成我们大脑的基本单元的。它们能够接收和传递电信号，而完整的神经系统则依赖数十亿个这样的神经细胞。在人工智能领域，我们把生物神经元抽象成了人工神经元模型，通过这种模拟构建的网络，我们能够实现灵活多样的算法，从简单的分类到复杂的决策制定。这样一来，自然界与人工智能之间的桥梁也逐渐建立。",
                "接着，我们观察人工神经元是如何从生物神经元的原理演化而来的。这些数学模型构成了人工神经网络的基础，在这里一个神经元能够接收多个输入信号，通过权重加权和偏置项进行处理。之后总输入值经过激活函数转换，符合条件时就会产生输出。这一模型简洁地抓住了生物神经元的核心特性，为应用于诸如语音识别或图像处理等领域的复杂网络架构奠定了基础。",
                "从形式化表达来看，每个输入信号乘以权重后相加，然后加上偏置项，经由激活函数处理来得到输出结果。这个公式可以帮助我们精准地计算神经元对特定输入的响应，这也是深度学习模型背后的基本运算方式。",
                "刚才我们提到了激活函数，现在来看它在神经网络中如何帮助增加非线性性。它决定了一个神经元是否会被激活并传递信号，这种机制在生物神经元中是类似的。选择合适的激活函数如ReLU、Sigmoid和Tanh，不仅影响神经网络的学习能力，还能显著提升模型性能。",
                "接下来我们用一个生动的例子说明神经元模型的运作。我们想知道是外出吃饭还是宅家做饭，通过输入饥饿程度、天气状况和财务状况等因素，进行加权求和，再通过Sigmoid激活函数做出决定。这个例子帮助我们理解神经元怎样综合各因素并做出决策。",
                "我们已经从个体神经元讨论过，来看看如何将多神经元组合成单层神经网络。在这种简单的网络结构里，几个简单计算就能处理一些特定问题。但想解决更复杂的任务，就需要我们引入多层结构，接下来我们就来探索这些结构的奥秘。",
                "现在我们转向更强大的多层神经网络，它的复杂性体现在隐藏层的使用上。隐藏层能帮助网络学习数据的抽象特征，从而解决那些单层网络无法处理的复杂问题。随着我们继续增加隐藏层的数量，模型变得庞大复杂。接下来，我们要看如何训练这些网络，让它们实现高效的任务执行。",
                "使用多层神经网络允许我们捕捉更复杂的决策模式。在外出就餐的例子中，多层网络能自主从具体因素中提炼抽象特征，从而提高模型的通用性。这样的隐状态是对具体数据表征的一种深层次理解。",
                "我们已经走过从人工神经元的基本理解到复杂神经网络的构建过程。接下来，是时候进入神经网络的学习过程，看看如何通过数据训练这些网络使它们完成特定任务。",
                "同学，现在我们进入神经网络的训练核心，即如何找出最优的权重和偏置来尽可能精确预测结果。结合真实用户数据，我们通过这个过程在实际应用场景中实现数据驱动的预测。",
                "梯度下降法是我们训练神经网络时使用的利器，它通过损失函数的梯度来不断优化模型参数。目的就是减少模型预测误差，让我们的预测结果尽量贴近真实情况。过程就像穿越崎岖山路来寻找最深的谷底。",
                "现在我们进一步研究梯度下降的操作。首先选择初始权重，再通过计算梯度来调整权重。学习率对训练速度和质量至关重要。经过不断迭代和反复调试，模型逐渐提高预测准确性。尽管这个过程涉及到不少数学运算，但当你逐步跟随其中逻辑时，一定会豁然开朗。",
                "接下来，我们通过一个简单例子感受如何利用梯度下降法强化神经网络的学习能力。在这个示例中，神经网络通过训练迭代来调整参数，从而增强其实用性和预测性能。",
                "本例中，我们给出在经过70次梯度下降步骤后的参数变化，权重从起初的小数不断优化，给出更接近实际输出的预测。这样的训练过程需要细致的学习率选择和迭代须知，以确保高质量的预测效果。",
                "最后，我们用一个简单神经元的训练过程引入一个重要概念——反向传播算法，让我们能自动调整多层神经网络的权重，提升模型性能。我们看看其中的步骤如何帮助网络逐步实现更高的预测准确率。",
                "当然在处理具体任务时，我们有选择损失函数的自由，均方误差和交叉熵损失函数都是其中非常有效的工具，它们让我们的模型预测越来越精确。",
                "交叉熵损失在训练分类模型时尤为重要，这是我们实现分类任务时提升模型准确性的工具之一。通过不断最小化误差，我们赋予模型更大的预测能力。",
                "总结一下，神经网络训练中常采用的是梯度下降法，通过优化参数来减小预测误差。反向传播则让复杂网络的训练更高效。刚才经过许多数学式子的学习，不要被这些精妙的计算打败哦！"
            ],
            "end_speech": "同学，继续努力提升你对反向传播算法的理解，将为你运用神经网络技术奠定坚实基础！"
        }
    },
    {
        "title": "module_ai_plus_part3_夏熠",
        "original_content": [
            "大语言模型虽然能回答“如何攀岩”这样的问题，却无法自己进行实际的攀岩。这是因为它们缺乏对现实物理世界的理解。要让大模型理解物理世界，其中一个方法是将物理信息转换为文本形式输入给它，但这会非常复杂且不精确。在自动驾驶的应用中，模型需要处理实时捕捉到的图像数据、雷达传感信息以及车辆的速度和方向等多种模态数据。通过融合这些不同类型的信息，多模态智能可以更全面准确地理解复杂的现实场景，从而在实际应用中进行更好的决策。",
            "那么，如何让一个大模型理解物理世界呢？一个可能的做法是将物理世界的信息完全转换为文本的形式，再输入给大语言模型进行理解和分析。但是，使用纯文本描述复杂的现实物理世界同样存在许多挑战。\n\n比如，在自动驾驶的场景中，我们需要将街道上的每一辆车的位置和运动状态输入给模型，以便它能够进行正确的决策。\n\n例如，屏幕上的这张街道图片中包含了非常丰富的信息：每辆车的位置、行人的移动、交通信号灯的状态等等。这些信息如果仅用文字来描述，会非常繁琐并且难以精确。比如，如果光靠文字来描述其中一辆车的位置及其运动状态，就需要大量的描述性语言，而对于整张图片来说，还包含了每辆车的颜色、位置、姿态、不同车辆之间的关系等等，这导致想要完整描述一张图片所需要的文字可能是无穷无尽的。\n\n因此，为了让大语言模型更好地理解和处理物理世界的信息，它们需要能够接收和处理更多模态类型的输入，不仅仅是文本，还包括图像、音频和各种实时传感数据。例如，在自动驾驶中，模型需要能够实时处理摄像头捕捉到的图像数据、雷达和激光雷达的感应数据，以及车辆的速度和方向等信息。\n\n通过这些多模态输入，大语言模型才能更准确地理解复杂的现实场景，从而在实际应用中做出更好的决策。这也说明了多模态人工智能的重要性，因为它能够将不同类型的信息融合在一起，提供更加全面和精确的分析和判断。",
            "实际上，多模态人工智能已经深深融入我们的生活，极大地提升了日常活动的智能化和便捷化。让我们来看几个具体的例子：\n\n首先是辅助驾驶系统，它通过处理视觉和雷达数据来增强道路安全和驾驶体验。这不仅能帮助我们更好地观察周围环境，还能预判潜在的危险，从而避免交通事故。\n\n再比如一键路人消除技术，这种图像编辑技术让我们在拍摄完美照片时变得更加容易。只需点击一下，就可以轻松去除不需要的背景人物，让照片更干净、更专业。\n\n智能家居系统则通过多模态理解和控制，例如视觉、听觉和温度感应，提供了高度定制化的家庭便利和控制。无论是调节室内温度、控制灯光，还是管理家用电器，智能家居系统都能让我们的生活更加舒适和高效。\n\n拍照购物结合了物体识别技术，使我们可以通过拍照来搜索和购买商品。只需用手机拍下物品的照片，系统就能识别出物品并提供购买链接，极大地简化了购物流程。\n\n最后是语音助手，它们通过解析语音命令来提供信息和执行任务。例如，我们可以通过语音助手设置提醒、播放音乐、查询天气等，极大地方便了我们的日常生活。\n\n这些例子展示了多模态人工智能如何在我们生活的各个方面发挥作用，赋能我们的日常活动，使生活更加智能化和便捷化。",
            "在这张幻灯片中，我们展示了一个强大的通用多模态模型——GPT-4V。这个模型在感知世界和细粒度理解方面具有显著的优势。GPT-4V结合了图像理解和文本推理，展现了图文交替输入与时序理解的能力。这些多模态能力使得GPT-4V在实际应用中表现出极大的灵活性和实用性，特别是在智能助手和机器人控制等领域。\n\n首先，我们来看GPT-4V的视觉能力。它能够识别并理解图像中的细节，比如识别出图片中自行车的特定组成部分的名称，或者在图片中找到并识别特定的文字。这种细粒度的理解能力使得GPT-4V能够处理复杂的视觉任务，如识别收据上的税费信息，并将其转换为有用的数据。\n\n接下来是图文交替输入与时序理解能力。GPT-4V不仅能理解单个图像，还能根据一系列图像进行时间上的预测。例如，通过观看一段视频片段，模型可以预测接下来可能发生的事件。这对于需要连续理解和决策的应用场景，如体育比赛分析或烹饪指导，都是非常有价值的。\n\n在实际应用方面，GPT-4V已经展现了不俗的潜力。例如，它可以作为智能助手，帮助用户搜索信息或完成任务。视频展示的是利用GPT-4V实现[网页浏览](https://cloud.tsinghua.edu.cn/f/a6d49b4143334e0b92d3/)的效果，用户仅需输入一个指令，这个智能助手就可以自动进行网页的理解和操作，达到用户的目标。此外，[在机器人控制领域](https://cloud.tsinghua.edu.cn/f/78dcbafa7ae14087b50a/)，也有工作利用GPT-4V的视觉理解能力让一个机械臂能够根据自然语言的指令执行拿取特定的物品的操作，展现了理解并执行复杂的指令。这种能力使得机器人在家庭和工业环境中都能发挥更大的作用。\n\n总之，GPT-4V展现出了强大的多模态理解能力，让人工智能在多模态交互和理解方面迈出了重要的一步。",
            "在理解物理世界之外，近期出现了可以进一步模拟物理世界的强大多模态生成模型——Sora。Sora模型的出现离不开我们刚刚所介绍的GPT-4V模型。Sora模型的产生借助了GPT-4V的强大理解能力，对大规模的视频数据进行了进一步的理解处理，从而训练得到了具有强大的视频生成能力的多模态模型，甚至涌现出了一定的模拟物理世界的能力。\n\n它有什么特别之处呢？首先在于Sora模型在生成视频内容时，能够保持时空和对象的一致性。这是什么意思呢？举个例子，在这个Sora生成的[狗狗视频](https://cloud.tsinghua.edu.cn/f/2e4a8365ad244e72b3cb/)中，斑点狗在被经过的行人遮挡之后再次出现的时，我们能够看出这只狗在遮挡前后是同一只狗，就像真实世界中一样。另一方面，它所生成的视频还能够模拟真实世界的复杂交互，比如视频中[老人吃汉堡](https://cloud.tsinghua.edu.cn/f/b4d7b124c12d47b49245/)的过程，老人的手与汉堡接触时形变，以及咬汉堡时产生的形变，都与真实世界中的情况非常相似。这两种特性让Sora生成的视频看起来非常自然、连贯。\n\n同时，从这个对比视频中我们可以看到，在输入给不同模型相同的生成指令时，Sora模型能够生成时间更长的视频，同时生成视频的自然度和连贯性上都明显更好。\n\n通过提供高度真实且动态的视频内容，Sora不仅可以推动视觉艺术的发展，还为很多实用应用开辟了新的前景。比如说，在影视制作、虚拟现实、教育培训等领域，Sora都可以发挥重要作用。可以说，Sora把AI技术在视觉艺术和实用应用中的前景推向了一个全新的高度。",
            "除了视觉上的突破，在声音模态，同样出现了强大的音频生成模型，它就是Suno。Suno 是一个革命性的音乐生成模型，将 AI 技术与创意艺术完美结合。它能够根据用户的文本提示，创作出具有广播质量的个性化音乐。不管用户喜欢什么样的音乐风格，或者使用中英文进行提示，Suno 都能理解并创作出与之相匹配的音乐作品。\n\n这段播放的音频展示了用户输入了周杰伦《夜曲》的歌词之后，Suno 基于这些输入，创作出的一首全新的[音乐作品](https://cloud.tsinghua.edu.cn/f/ce1f013ace1844e793cd/)。Suno 的技术进步，也使得音乐创作变得更加简便和个性化，为音乐爱好者提供了一个实现创意的新平台。\n\n通过访问 Suno 网站，用户可以亲自探索和体验这款工具的强大创作潜力。无论是想创作一首新的流行歌曲，还是创作一首轻音乐，Suno 都能满足你的需求。结合视觉理解大模型等其他的理解工具，用户甚至可以为一个视频创作与它的意境相一致的背景音乐。\n\n总之，Suno 不仅简化了音乐创作的过程，还极大地拓展了创作的可能性。它代表了 AI 技术在艺术领域的一大进步，为广大音乐爱好者带来了前所未有的创作自由和灵感。",
            "当我们将视觉、语音能力结合在一起，将会怎样？Figure 01 展现了一个可能的答案。可以说Figure 01 代表了一种多模态智能的终极形态，这款由 OpenAI 多模态大模型加持的机器人，具备了与人类及环境进行互动的卓越能力。在执行任务时，如[找到食物](https://cloud.tsinghua.edu.cn/f/a50cefd747ae4b79af90/)等工作，Figure 01 展现出快速且精确的操作能力。\n\n借助多模态模型作为它的“大脑”，这款机器人不仅能够理解复杂的语音指令，还能够根据当前的视觉信息进行策略规划，并通过机器人的控制模块进行灵巧的操作和物理交互，体现了具身智能实体在现实世界应用中的巨大潜力。\n\n通过高级的感知和执行功能，Figure 01 可以日常工作和特定任务提供创新的自动化解决方案。它不仅展现出在家庭环境中应用的可能，随着多模态智能的进一步发展，还可能在工业、医疗和服务等领域提供支持，展现出强大的应用潜力。",
            "在这张幻灯片上，我们将探究卷积神经网络（CNN）的原理以及它是如何受到生物视觉系统启发的。受到从视网膜到大脑初级视觉皮层的信息处理过程的启发，CNN网络通常包含卷积核、池化两种模块。首先，卷积核代表视觉皮层中简单细胞的功能，负责检测图像中的基础特征，如边缘。接着，池化层则模仿了复杂细胞的功能，通过合并多个简单细胞的信号来保持特征的空间不变性。我们的网络通过多层卷积结构逐步深化，从简单特征到复杂特征的集成，这样的分层结构描绘了从感知到认知的转变过程，正如幻灯片底部示例所展示的从简单数字8的轮廓，经过一系列的卷积和池化操作，最后抽象为数字8的高级特征表征。",
            "在这张幻灯片上，我们介绍了一种名为残差网络（ResNet）的深度学习架构。当卷积神经网络变得越来越深时，尽管网络能够提取更丰富和深层的特征，但同时伴随的是信息损失和训练难度的增加。为了解决这个问题，ResNet引入了残差连接，如幻灯片中残差连接结构图所示，它提供了一种“捷径”来直接传递浅层信息，使得网络即使在极深的层次上也能有效地学习。幻灯片的左侧显示了CNN网络在不同层次上提取的特征，从简单的边缘和纹理逐渐演变为复杂的对象部分和高级语义信息。残差连接让网络更容易优化，并且能够在不增加额外的参数和计算负担的情况下增深网络结构。右侧则展示了一个完整的ResNet网络结构，可见它通过堆叠多个带有残差连接的卷积块来构建深层的网络，这种结构设计有效地提升了深度学习在图像识别等任务上的性能。",
            "在这张幻灯片上，我们介绍视觉Transformer，它在图像识别领域引入了原本用于语言建模的Transformer架构。Transformer架构在自然语言处理（NLP）领域表现出色，并证明了其极佳的可扩展性。ViT通过将这一架构有效扩展到视觉任务上，实现了在图像识别方面的突破。\n\nViT架构的主体结构如图所示：首先，图像通过分块策略被切割成大小为16x16像素的补丁（patch），类似于语言模型中的单词（words）。然后，这些补丁被展平并通过位置编码增加空间信息，输入到Transformer编码器中。编码器通过多头自注意力机制处理这些图像补丁，允许模型动态地关注图像的不同区域，并提取出复杂的特征表示，正如幻灯片上的Transformer Encoder结构图所示。最后，ViT通过多层感知机（MLP）头部进行分类。\n\n当有充足的数据进行预训练时，ViT能够超越CNN模型的性能，并且在下游任务中显示出良好的迁移能力，表现出ViT大规模数据集上训练带来的优势，同时解决了Transformer在视觉任务上缺乏归纳偏置的问题。ViT的成功标志着Transformer在计算机视觉领域应用的一个重要里程碑，并激发了后续大量的研究工作。",
            "讨论完图像理解，我们我们会思考，人工智能可以生成图片吗？对于图像分类相对于图像生成的区别，就像婴儿在成长过程中学习辨认不同物体，图像分类器通过分析图片的特征来识别它代表的类别，相比之下，图像生成像是儿童学习如何画出一只猫那样更加困难，因为它需要理解猫的概念，并创造性地生成一只猫的图像。\n",
            "图像生成方法通常有三种流行的方法。\n第一种是生成对抗网络（GANs），类似于“骗子与侦探”的对抗，这种方法涉及两个模型：生成器（G，骗子）尝试生成看起来像真实图片的图像，而鉴别器（D，侦探）的任务是区分真实图片和生成器生成的假图片。通过这种对抗的训练过程，生成器学会产生越来越逼真的图像。\n\n第二种是自回归生成模型，这类似于文本生成，每次都基于前面生成的内容，生成一部分图像，比如一个区域或像素，逐渐构建整张图片。\n\n第三种是深度扩散模型，这些模型从一个随机的噪声分布开始，逐步转换成结构化的图像。在训练阶段，模型学习逆转加噪过程，让噪声数据逐步清晰，最终生成高质量的图像。\n",
            "我们具体介绍一下自回归图像生成模型，类似于大规模语言模型，通过“学习照抄”训练数据来掌握生成连贯文本的能力，每一个位置基于前文输入预测token。",
            "图像生成中自回归生成模型的训练流程与文本训练类似，我们将输入的图片分割成多个块。模型将尝试逐个块地重建整张图像，模型根据已知信息去预测下一个像素块的内容，根据真实的像素块来调整其参数，学习出真实像素块的分布。随着训练的持续进行，模型最终能够准确生成各个像素块，合成出与训练图像相似的新图像。",
            "在这张幻灯片中，我们深入探索了生成对抗网络(GANs)的基本概念。GANs的独特之处在于，它们模拟了一种对抗过程，其中生成器的目标是创造出骗过辨别器的合成数据，而辨别器则旨在区分真实数据和合成数据。这种方法的灵感来自于艺术品的仿制与鉴定过程，生成器和辨别器之间的对抗训练，可以创造出足以迷惑专家的伪作。\n\n幻灯片的左侧为我们展现了这一对抗过程的基本架构，包括从随机噪声到生成器，再到辨别器的数据流向。特别体现在这一点上的是，生成器和辨别器分别用绿色和红色框标出，展现了它们的对立性，反映了生成器要创造像真正数据一样的合成数据，而辨别器则试图识别出哪些是真实数据哪些是假的。\n\n幻灯片中间的文字进一步解释了每个组件的目标，其中生成器的训练目标是“骗过辨别器”，而辨别器的训练目标是“辨别真实的数据和生成的数据”，这两个目标构成了GANs的核心竞争机制。这样的学习过程最终可以产生高度逼真的图片或视频，如同艺术品仿制过程中的真品与赝品。\n\n右侧的图像展现了合成数据的一个示例，这可能是生成器在初期学习阶段的输出，看起来像是随机的噪声。随着生成器的学习和优化，这些图像将变得更加精细和逼真，最终足以达到以假乱真的效果。\n\n综上所述，GANs通过模拟这样的对抗过程，催生出强大的图像生成能力，并且在众多领域中展现了其潜力和应用价值。",
            "深度扩散网络的核心思想是在生成过程中，将噪声逐渐降低，把一个复杂的问题拆分为多个简单的步骤。模型首先通过创建多个噪声级别的图像版本，引导模型学会如何从随机噪声中逐步恢复回真实图像的数据分布。训练时我们进行逐步加噪，生成时从随机噪声图像一步一步恢复至原始的猫的图像。",
            "在本幻灯片中，我们看到深度扩散网络极大地提升了图像和视频生成的效果。关于深度扩散网络的表现力，举了两个例子：应用这种网络的著名模型Stable Diffusion用于图像生成，而Sora则用于视频生成。\n左侧的一系列图像表现了Stable Diffusion模型生成图像的多样性和精细度。\n[右侧](https://cloud.tsinghua.edu.cn/f/3b5bf8d4b41541c88fa0/)是Sora模型的视频生成效果，通过一系列的视频帧展示了模型如何产生连续性和动态效果的视频内容。\n",
            "在这张幻灯片中，我们将探讨声音的三个基本要素：音色、音量和音调。音色是指声音的质地和颜色，决定了我们如何辨别不同的声音源，例如人声与小提琴声的区别；音量，又称响度，决定了声音的强度或响亮程度；音调则与声音的频率有关，决定了声音的高低。\n\n幻灯片左侧有三个示例，分别对应音色、响度和音调。我们可以看到不同的图案表示了不同的声音属性，比如音色部分展示了不同乐器发出的声波形状；响度部分通过不同振幅的波形图来表示声音的大小；最后，音调部分通过不同频率的波形显示声音的高低。\n\n幻灯片右侧的图表向我们展示了如何通过傅里叶变换将声音信号从时域转换到频域，以便于分析声音的频率分量。通过这种变换，我们可以清晰地看到声音在频率上的分布，进而更好地理解和控制音色、音量与音调。\n\n总结来说，声音是可以通过其物理属性（频率和振幅）进行分析和生成的，而对这些属性的理解和操控正是制造和认识声音的基础。通过科学和技术，我们能够更加精确地表达和复制我们所需的声音特性。",
            "本幻灯片向我们介绍了OpenAI推出的一个领先技术——Whisper语音理解与识别系统。Whisper基于强大的Transformer模型，不仅能够执行高准确性的自动语音识别（ASR）任务，而且作为一个多任务模型，它还具备执行多语言语音识别、语音翻译以及语言识别的功能。\n\n首先，我们来看一下Whisper的核心特性。它的强大之处在于能够处理多语言语音输入，并且在各种嘈杂环境下仍能保持较高的识别准确率。此外，Whisper还能自动适应不同的说话风格和口音，提供更为精准的转录结果。这使得它在实际应用中非常灵活，例如在不同的语言之间进行转换或者在复杂的声音背景下进行识别。\n\n幻灯片右侧展示了Whisper的系统架构。我们可以看到，Whisper使用了多个编码器和解码器模块来处理语音信号。首先，信号处理模块将音频分割为小片段，并转化为频谱图像；接着，特征提取模块通过Transformer结构从这些频谱图像中提取重要特征；最后，文本生成模块利用这些特征生成对应的文本输出。\n\n通过这种结构，Whisper能够有效地将复杂的语音信号转化为文字，并且可以处理多个任务和语言。这种多任务的能力使得Whisper不仅在语音识别方面表现出色，还可以用于语音翻译和语言理解等其他应用。\n\n总的来说，Whisper是一个强大且灵活的语音识别系统，代表了语音技术的前沿发展。它的出现将极大地推动语音识别技术的进步，尤其是在多语言和复杂环境下的应用，带来更多的便利和可能性。",
            "在这张幻灯片中，我们深入了解了一项革新音乐创作的人工智能技术：Suno。Suno被誉为“音乐界的ChatGPT”，其独特之处在于，它能根据简单的提示，创作包含歌词、人声以及伴奏在内的完整歌曲。与其他音乐生成模型仅能创造片段不同，Suno拥有生成完整结构歌曲的能力。\n\n幻灯片[左侧](https://cloud.tsinghua.edu.cn/f/4d18a30f342a40f39796/)展示了Suno应用的用户界面，显示了用户如何自定义创作内容。用户可以选择音乐风格和是否使用乐器、生成歌词，这体现了Suno的多样性和用户友好性。[右侧](https://cloud.tsinghua.edu.cn/f/c5e7b92b84a04d98b020/)是一条社交媒体上的推文，推文认为Suno的丰富音乐风格就像在音乐AI创作的世界中找到了一座宝藏箱，暗示了Suno在多样化音乐创作中的潜力和价值。\n\nSuno不仅能够生成旋律和伴奏，还能够生成完整的歌词，这使得它在音乐创作领域独树一帜。对于那些没有音乐创作经验的人来说，Suno提供了一个直观且易于使用的平台，使他们能够轻松地生成高质量的音乐作品。对于专业音乐人，Suno则提供了新的创作工具和灵感来源，可以显著提高他们的创作效率。\n\n我们可以看到，Suno不仅是一个AI音乐生成工具，更是一个能够激发人们对音乐创作热情的平台。它代表了AI在艺术创作领域发挥越来越重要的作用，为作曲家和音乐爱好者提供了新的创作方式和灵感来源。未来，Suno有可能改变整个音乐产业，推动音乐创作进入一个新的时代。"
        ],
        "recommend_content": [
            "通过将不同类型的数据序列化并由大型模型来学习和处理来实现，我们可以实现多个模态的统一建模。\n\n我们展示了几种不同类型的数据如何被序列化：\n\n对于语言来说，无论是自然语言文本（如公司简介）还是编程代码段，这些都可以被分解为单词或符号的序列。例如，“Founded in 1988, Huawei is...”可以被分解为单词的序列。\n对于图像来说，它也可以通过某种编码方法转换为序列，这种编码方法可能基于像素表示或特征提取技术。例如，一组连续的图像帧可以被序列化为一系列图像特征。\n对于DNA来说，作为生物信息的原始数据形式，DNA序列天然是一个字符序列，例如“5' ATGACGTGGGAA 3'”。\n对于工具使用而言，工具的使用行为可以被描述为一系列动作的序列，例如“搜索”、“翻页”、“摘取”、“翻译”等。\n而电磁波例如声音信号，同样可以被转换为一系列的振幅或频率数据点。\n\n这种统一的序列化方式使得不同领域的数据和知识能够被整合进单一的多模态模型中，这大大提高了AI的适用性和灵活性。无论是文本、图像还是其他类型的数据，统一的序列化方法都能让模型在不同模态之间进行无缝整合。\n\n在后续的讲解中，我们将进一步探讨序列化如何实现跨模态数据的整合，并了解这种技术对于实际应用的潜在影响。通过这种方式，AI不仅能够在特定领域内进行深度学习，还能够跨领域地综合利用各种类型的信息，为解决复杂问题提供更强大的支持。",
            "这张幻灯片呈现了一个模块化多模态大模型的概念框架，该框架将语言模型作为核心，可以处理涉及多种模态的复杂任务。幻灯片上的图表清晰地描绘了模型的输入和输出流程，包括各种不同模态的数据如文本、图像、音频、视频等。\n\n在输入端，不同模态的数据通过特定的编码器被转换成统一格式的表示，例如图像编码器、音频编码器和视频编码器。这些编码器的输出随后被投影到一个共享的输入投影空间。这个过程确保了不同模态的数据能够在统一的语义空间中进行处理和理解。\n\n模型的核心是语言模型，它将不同模态的输入投影转换为统一的语义空间，进而实现跨模态的信息整合和任务执行。通过这种方法，模型能够理解和关联来自不同模态的信息，实现更加全面和准确的认知。\n\n在输出端，包含转换后信息的语义表征被进一步转换，通过相应模态的输出投影和扩散模块生成特定模态的输出，比如图像扩散模块、音频扩散模块以及视频扩散模块。这些模块负责将语义信息重新转化为对应模态的实际输出，完成从输入到输出的全流程处理。\n\n整个框架突出了模块化设计的优势，允许灵活组合和交换不同模态的处理组件，实现了一个真正多功能的、跨模态的大型人工智能模型。通过这个模块化的设计，这种大模型能够在一个单一的结构中处理多种任务，显著提升了AI在处理复杂世界信息时的效率和灵活性，并有可能在诸如自动内容创建、实时交互式通信和高级分析等诸多应用领域产生重大影响。\n\n这个设计不仅展示了多模态对齐技术的应用前景，还为未来的人工智能发展提供了新的思路和方向。通过这种模块化和多模态的整合方法，AI系统将能够更好地理解和处理复杂、多样化的信息，实现更高层次的智能和应用。",
            "在本页，我们将了解符号化多模态大模型的概念，讨论它的特点以及面临的潜在挑战。这种模型通过将多种模态的信息转换成Token，再应用基于语言模型的框架来学习这些Token化的信息，从而从无标注数据中提取通用知识。\n\n这种方法让我们能够从不同类型的无标注数据中提取出有价值的信息，大大扩展了模型的应用范围。然而，这种方法也存在一些挑战，特别是在符号化（Tokenization）过程中可能会遇到瓶颈，这可能会影响模型学习的效率和质量。\n\n我们以 Google 提出的 Gemini 模型为例来介绍，在幻灯片的右侧，我们看到了该模型结构的图解：各种模态的输入序列（如文本、音频、图像、视频）首先被符号化为Token，然后通过 Transformer 结构进行处理。处理后的结果被分配到不同的解码器，以便进行图像和文本的解码。 符号化方法使得模型框架和学习方式更加一致，能够有效处理不同模态的数据。此外，这种方法在处理没有明确标签的大规模多模态数据集时展现了巨大的潜力，能够提高模型的泛化能力。\n\n同时，我们也要关注符号化过程中可能遇到的瓶颈。例如，不同模态的数据在被符号化时可能会丢失一些关键的信息细节，影响模型的表现。为了克服这些挑战，我们需要进一步优化符号化方法，使其能够更好地保留和传递多模态数据中的关键信息。",
            "在这张幻灯片中，我们探讨了内置化多模态大模型的理念，它的目的在于通过消除专为某一模态设计的特化模块，将不同模态的原始表示映射至统一的模型空间内。\n\n幻灯片上的文本强调了这种模型架构的高度统一化特点。示意图展示了一个输入图像被分割成一个个图像块，然后通过线性投影转换为Token，这些Token与其他模态的数据（如文本）统一处理于一个具有Transformer结构的解码器内。解码器的输出对应于文本中的Token，这些输出与输入的图像块进行了映射，以此构建了图像和文本间的关联。\n\n不过这一方法也存在学习过程的难度较大的问题，需要较高的计算成本和数据资源。这是因为模型需要直接处理模态的原始数据，而不是通过特化模块来预处理，增加了任务的复杂程度。\n\n在未来，我们可能需要思考如何平衡这种高度统一的结构所带来的好处与其学习难度和成本之间的关系，以及如何利用和改进这种模型来更好地应用于实际问题。",
            "在这张幻灯片中，我们概述了多模态大模型如何学习人类知识的几个关键步骤。首先是多模态预训练，这一步骤中模型通过摄入各种模态的数据—例如视觉、听觉、嗅觉、触觉和味觉—来理解世界。预训练阶段通常涉及海量数据，帮助模型捕获跨模态间的丰富关系和模式。\n\n接下来是有监督微调，这一阶段是通过标注数据的指引，优化模型的表现以适应特定任务或领域。在这个过程中，模型细化了它对特定任务所需知识的理解。\n\n模型的学习还涉及从人类的反馈中学习。人类可以通过评估模型的输出，并提供指导性的反馈，来指导模型改进其预测和决策。\n\n综上所述，多模态大模型采用一系列的方法来学习人类知识，结合了预训练、有监督学习和从反馈中学习的过程，通过模拟和实践不断增强其对真实世界的理解。这种学习方法确保了多模态大模型能够为各种复杂任务提供有效和准确的输出。",
            "这张幻灯片展现了多模态大模型的“多模态预训练”学习方法的第一阶段，即海量感知的预训练阶段。\n\n多模态预训练阶段使用大量的图文对等模态对齐数据进行训练，比如一张图片及其对应的文本描述。这种训练方法要求模型根据给定一模态的输入（例如一张图片）预测该模态的后续内容以及其他模态相应的表示（例如对图片内容的文本描述）。\n\n这一预测过程一般以“单字接龙”的形式来完成，我们在幻灯片下方给出了一个例子。\n当我们输入一个柿子的图片是，我们要求模型逐字给出相应的描述，当模型生成了错误的预测时，需要进行调整。例如，模型预测出“一个”后，接下来预测出了错误的Token，”鸡“，这需要通过模型调整来纠正，最终达到正确输出“一个柿子”。\n\n通过这种多模态预训练，模型能够学习理解和生成从视觉模态信息（图片）到文本模态信息（文字）的转换，这对于提升人工智能在多模态理解和生成方面的能力至关重要。",
            "这张幻灯片向我们介绍了多模态大模型学习方法的第二阶段，即有监督微调，这一阶段可以比喻为模型通过“反复刷题”来做出更为精准的响应和决策。\n\n有监督微调是一种模型训练方法，通过使用人工标注的数据（例如用户的指令和模型的回答）来优化模型性能。目标是使模型能够更好地理解用户的意图，并且能够根据各种模态的输入和具体的用户指令生成恰当的回复。\n\n在幻灯片的示例中，用户提出了三种不同的请求。在第一个示例中，用户要求以清华大学校徽为主题生成一首诗，模型成功地生成了一篇诗作，体现出其理解和创造力。在第二个示例中，用户播放一首歌曲并询问模型这首歌的专辑名，模型成功地回答了专辑名称。\n\n在第三个示例中，用户询问如何制备某种化合物，模型据此作出伦理判断，提示用户关于该化合物可能有害的社会影响，并拒绝提供帮助。\n\n通过这种方法，模型不仅学习了如何处理多模态的数据，也在有监督微调过程中加强了理解指令和提供适当响应的能力。这使我们能够期待模型在更复杂的实际应用场景中，如何准确理解和回应人类提问，充分展现其适应性和判断力。",
            "这张幻灯片揭示了多模态大模型学习方法的第三阶段：从人类反馈中学习，可以视为模型通过“模拟演练”来提高表现。\n\n这个阶段的目标是让模型通过人工给出的质量打分来学习和进步，以便调整模型使其产生的回答得分不断提高。就像学生参加模拟考试，每次考试后能获得分数反馈，模型依据这些反馈进行自我调整以提升表现。\n\n幻灯片底部的示例展示了一个简单的互动场景，一个猫的图片被输入到模型中，随后模型生成文字描述。如果描述不准确，将得到负面反馈；如果描述准确，将得到正面反馈。这些反馈会被用来引导模型的未来回答，优化其生成结果。\n\n通过这一过程，模型学会如何根据人类的评价标准来调节自己的输出，这样的学习环节对于模型能够理解和适应用户期望至关重要。下一步，我们可能会探讨如何优化人类反馈的有效性，以及如何确保模型能够在多变的真实世界情境中稳定和高效地学习。",
            "下面我们对多模态大模型的应用与未来进行讨论",
            "多模态大模型可以通过学习领域数据，在不同领域的下游应用场景进行应用，包括艺术与设计、商业、科学、健康与医学、人文与社会以及技术与工程。\n在艺术与设计领域，多模态大模型可以帮助分析和辨识音乐谱号的结构，识别构建是否正确\n在商业分析中，模型运用在数据解读，帮助理解市场调查数据与图表，求解与概率相关的问题\n针对科学问题，如数学题目的解答，多模态大模型可以处理和解读数学公式，计算区域的面积，这要求模型有能力理解复杂的算术问题和数学表示。\n在健康与医学方面，模型通过分析医疗图像，例如MRI和CT扫描，协助诊断疾病的成因。\n人文与社会学科的应用体现在对历史事件和社会现象的理解。\n在科技与工程应用上，多模态大模型能够解释和分析电子电路图，帮助求解特定电路组件的电压。\n随着技术的完善，多模态大模型预计将进一步推动更多领域的创新和效率。",
            "除此之外，我们讨论多模态大模型在三个具体的下游应用场景中的实例：自动驾驶、医疗诊断和数字孪生。\n\n首先是自动驾驶领域，多模态大模型结合了图像、声音、雷达等多种模态的信号来实现智能驾驶。图中的汽车示意图代表了这一过程，强调了传感器数据融合在提高驾驶安全与智能水平上的重要性。\n\n接下来是医疗诊断，模型利用包括影像、文本等在内的多模态医疗数据来实现对医学图像的精确理解和解读。幻灯片中的医疗图展示了模型如何参与医疗诊断流程，对疾病进行更精准的识别和分析。\n\n最后提到了数字孪生技术，通过实时采集和分析多种模态的信息，这项技术可以实现对城市基础设施的综合管理和优化。这个部分的图表和图像展现了数字孪生技术如何对城市运作的各个方面进行模拟和分析，以促进更高效的资源配置和决策制定。\n\n随着模型能力的不断增强，我们可以期待在更多的行业和领域内看到其发挥更加关键的作用。",
            "这张幻灯片展示了多模态人工智能在自动驾驶应用中的具体例子。自动驾驶技术需要集成多种传感器的数据，包括RGB图像、激光雷达点云、雷达点和地图等。这些数据的融合使得车辆能够对周围环境有更全面的理解，从而实现安全导航。\n\n左侧的图展示了不同传感器的数据，包括车辆、行人、道路标志和交通灯的视觉图像，以及激光雷达和雷达点数据。这些传感器数据通过融合，形成了对车辆周围环境的全面理解，为决策系统提供了必要的信息。\n\n右侧提供了两个场景的样例，展示了GPT-4V在理解复杂场景和进行因果推理方面的能力。文本提示详细描述了车辆当前的行驶情景，包括周围的车辆、行人、交通状况以及环境动态。这些示例表明不仅能够理解现有场景，还可以预测未来可能的变化，展现出了为自动驾驶系统提供及时、准确的决策支持的希望。\n\n通过多模态传感器数据和高级AI模型的结合，自动驾驶技术正不断取得新突破，使车辆能够在复杂、多变的交通环境中更安全、更高效地导航。这一技术的进步不仅提升了驾驶安全性，还为实现完全自动驾驶奠定了坚实的基础。",
            "在这张幻灯片中，我们讨论了多模态人工智能在医疗自动诊断领域的应用，尤其是在X光图像分析上的利用。幻灯片展示了医疗图像作为一种模态，是通过特定的算法进行处理，以自动识别和解读疾病标志。\n\n左侧部分显示了一个X光图像示例，并配有一个文本框，解释了这个图像中可能见到的特征，如肺炎的迹象。此外，还有一个循环展示了图像处理的步骤，强调图像分析软件具备识别和标记图像中关键特征的能力。\n\n右侧部分提供了一个多模态数据和机会的彩色连接图，表明除了医疗成像之外，还可以整合多种模态的数据如基因组数据、代谢物、生物标志物、微生物组、电子健康档案、可穿戴生物传感器、环境感应器等数据，以及它们如何与诸如精准健康、数字化试验、健康监测、大流行监控、数字双胞胎、虚拟健康教练等具体健康应用之间的关系。\n\n综合整张幻灯片，我们可以看出多模态人工智能在健康领域的应用前景非常广泛，不仅仅限于提高自动诊断的准确性，还可以在处理和整合来自多个源的健康数据方面发挥作用，从而在预防、诊断和治疗过程中为医生和患者提供不断改进和个性化的医疗解决方案。这样的系统可能对未来医疗保健产生革命性的影响。",
            "在这张幻灯片中，我们介绍了多模态人工智能在数字孪生技术—特别是应用于智慧城市中的重要作用。\n\n数字孪生系统通过整合来自交通、环境、能源等多个领域的数据，不仅处理图像、声音、视频等多种模态的信息，而且能够实时采集与分析这些数据。幻灯片上的图像展示了一个数字孪生城市的灵活框架，其中包含了城市建筑的3D模型、交通流量、能耗数据等关键指标。\n\n通过这样的系统，城市能够实现更加精确和自动化的综合管理与优化。数字孪生技术的应用不仅帮助城市管理者更好地理解和响应城市发展的需求，也为居民带来更高的生活质量。这说明多模态人工智能不仅在技术上具有革命性的潜力，而且它带给社会运行的效率和质量也具有深远的影响。",
            "在这张幻灯片中，我们探讨了多模态智能模型的未来展望，特别是世界模型的概念。\n\n在理解语言时，我们通过预测下一个Token\n当我们理解世界时，我们要通过预测下一个State来实现。这包括场景变化和物理变化的考量，需要模型能够理解空间的变化和跨时间的轨迹变化，从而建模交互过程的复杂性。\n",
            "多模态大模型发展的另一个前沿方向是具身智能，这是一种在与环境交互时涌现出的智能。具身智能的一个挑战是需要实体通过从第三人称视角转变到第一人称视角，并解决现实世界中的复杂任务。\n\n左侧的图表展示了一个agent在环境中的操作模型。代理有一个目标（Goal）,通过对环境的观察（Observation），执行动作（Action），并从环境中获得相应的回报（Reward），以此来判断在未来的状态中应如何行动。\n\n右侧的图片系列辅助说明了目前利用大语言模型已经可以辅助机器人任务，包括倒薯片、拿铅笔罐、拿空盘子等多样化的操作。这些任务都需要具身智能体认知空间和物体，并对其进行有效的操控，体现了具身智能在现实世界动作执行和问题解决中的能力。\n未来的智能系统将更加深入和广泛地了解他们所处的环境，并能够进行日益复杂的与环境的交互。具身智能有望解决现实世界的多种挑战，为未来的智能交互和自动化开启新的可能性。",
            "总结来看，我们将使用Transformer模型作为一个统一的框架处理各种模态，从图像智能、语音智能到理解生成能力，再到模态对齐，Transformer在单模态和多模态领域内的应用成为了整个领域的关键节点，并期望在自动驾驶、智能医疗和智慧城市等下游应用提供了强大的支持，同时也为未来展望铺平了道路。\n同时，我们期待着更连贯、更智能、更多功能的AI系统的出现。通过我们的努力和技术的进步，未来通用人工智能的愿景将逐渐变为现实。我们将继续探索实现这一未来目标。"
        ],
        "recommend_reason": "这位学生对多模态技术表现出强烈的兴趣，并且对AI应用展现出好奇心和探索动机。选中的内容涉及多模态大模型的实际应用，能引导学生从理论兴趣转向实际模型应用的理解和探索，契合其长远目标中的实际应用探索和短期目标中的理解图像与文本的向量空间映射，提升其对现代AI应用场景（如自动驾驶和医疗）中的多模态技术的认知水平。",
        "adaptation_result": {
            "start_speech": "同学，接下来我们从刚刚讨论的多模态智能出发，来探讨这个技术如何通过不同数据的序列化来实现多模态的统一建模。",
            "refined_scripts": [
                "我们刚才谈到了多模态智能的关键性，现在来看如何将不同类型的数据进行序列化处理。通过这种处理，模型可以统一地学习和处理多个模态的数据，比如语言可以分解成单词或符号的序列，而图像可以通过编码技术转化为一系列图像特征。相似地，DNA作为生物数据也是字符形式的序列。在工具使用方面，行为可以被描述成一系列的动作序列，比如“搜索”或“翻译”。此外，声音信号同样能被转换为振幅或频率的数据点。这样的序列化处理方法让不同领域的数据可以被整合进单一模型中，使得AI应用无论在文本、图像还是其他数据形态之间都更加灵活和有效。在接下来的讨论中，我们继续深入探讨这种序列化在实际应用中的影响。",
                "同学们，我们刚才提到了多模态智能模型的实际应用。这里我们看到一种模块化多模态大模型的概念，通过在中心使用语言模型处理多种数据模态，包括文本、图像、音频与视频。各模态数据首先通过特定编码器转换为统一格式，然后进入共享的输入投影空间。语言模型将这些多模态输入投影到统一的语义空间，实现跨模态的信息整合与任务执行。这不仅提升了AI的认知能力，还促进了自动化内容创造、实时互动通信与高级分析等方面的显著进展。通过这样的设计，AI系统拥有更高的灵活性和效率，并为未来人工智能的运用开辟了新的方向。",
                "在这里，同学注意，符号化多模态模型是怎样工作的呢？这类模型通过将信息转化为Token，然后利用语言模型框架进行学习。比如Google的Gemini模型，它将不同模态的输入序列符号化，然后通过Transformer结构进行处理，以生成有用的解码结果。这种方法有助于从无标注数据中提取大量信息，而无需明确标签。这一过程提高了模型的泛化能力，但也面临符号化过程中可能丢失细节信息的挑战。我们要继续发展符号化技术，以确保数据的关键信息得到更好地保留与传递。",
                "同学们接下来了解内置化多模态大模型的理念。这种模型通过消除特化模块，将不同模态的原始数据映射到一个统一的模型空间来处理。由于直接处置原始数据，这种方法融合了各种模态的数据，要求更高的计算成本。尽管如此，模型架构的统一化带来了处理变得更加一致的优势。这种应用有助于我们思考如何平衡模型的学习复杂度与计算负担，从而更好地解析实际问题。",
                "我们刚刚谈到了预训练，接下来让我们看看多模态大模型学习人类知识的一系列步骤。首先是多模态预训练，通过跨模态数据理解世界。然后是有监督微调，用标注数据来优化模型表现。在学习过程中，模型也从人类反馈中不断调整与改进预测和决策，模拟与实践提供了深刻认识世界的能力。这种多层次学习确保了模型能够有效地解决复杂任务。",
                "同学，关于多模态预训练阶段，这里使用大片图文数据对齐进行训练，模型需要基于给定模态预测后续内容。这种预测像是'单字接龙'，当看到错误输出时，通过调整来纠正其生成结果。这样的多模态训练提升了模型从视觉到文本的转换理解能力，是增强AI生成能力的重要步骤。",
                "在这里看看有监督微调的作用，它是通过人工标注数据帮助模型训练，目标是提升模型理解用户意图的准确性。这个过程中模型改进了多模态数据处理的能力，在不同应用场景中能够更好地回应和生成内容。这种微调就像'刷题'一样不断让模型更精准地予以响应。",
                "同学，我们继续看第三阶段：从人类反馈中学习。这阶段通过质量打分帮助模型自我调整，就像模拟考试后的反馈。模型依据这些分数优化其输出，确保未来回答更符合用户的期望。这种从反馈中学习对多变的现实情境至关重要，持续提高模型的表现。",
                "接下来，我们看些应用与未来展望。",
                "对多模态大模型的应用有多广呢？从艺术到商业分析，再到健康医学，科技与工程，模型可以处理不同领域的数据并提供有力的支持。比如艺术设计中辨识音乐谱号，在商业上处理市场数据，科学问题解答，医疗图像诊断，社会历史及科技电子电路分析。随着技术的进步，模型将在更多领域推动创新和效率。",
                "同学们，我们讨论多模态模型在自动驾驶、医疗诊断与数字孪生技术中的应用实例。自动驾驶通过多模态信号提升智能驾驶；医疗诊断通过整合影像、文本提高疾病识别率；数字孪生则通过实时数据管理城市基础设施。模型能力的增强会在更多领域产生关键影响。",
                "自动驾驶应用中，车辆集成了多传感器数据用于安全导航，模型理解复杂场景并预测变化。这一技术正为实现完全智能化驾驶奠基，期待它能更好地提升交通安全和效率。",
                "看多模态AI在医疗自动诊断上的表现，尤其是X光图像分析中。模型整合多种模态数据进行精准诊断，不仅提高了自动识别能力，还在多源健康数据处理中发挥作用，给个性化医疗解决方案带来了巨大潜力。",
                "介绍数字孪生技术在智慧城市中的角色。模型整合交通、能耗等多领域数据，促进城市自动化管理与质量改善。这说明了AI技术在社会管理上的革命性影响。",
                "关于多模态智能模型的未来展望，理解语言时通过预测Token，世界模型则通过预测State，需掌握跨时间轨迹变化。",
                "同学们，我们还讨论了具身智能对环境交互的意义。智能体需转换视角以完成复杂任务，应用大语言模型助机器人执行多样动作，体现出在空间认知与操控上的能力，未来会在联结智能交互与自动化上开展新的探索。",
                "总结下我们对Transformer的应用，从模态对齐到下游应用，变革多模态智能领域，我们期望未来更智能化的系统驱动AI发展。继续努力，期待将未来愿景变成现实。"
            ],
            "end_speech": "同学，请保持对多模态技术的好奇与探索，它为我们的AI学习和实践提供了无限可能。"
        }
    }
]