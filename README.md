# ðŸ“š **Pxplore: Personalized Learning Path Planning with Goal-Driven Learner State Modeling**

> *Personalized Learning Path Planning with Goal-Driven Learner State Modeling* has been **submitted to The Web Conference (WWW 2026)**.
> The full paper will be released soon.

## Overview

**Pxplore** is an open-source adaptive learning path planning framework that personalizes learning experiences through **fine-grained learner state modeling** and **goal-driven reinforcement learning**.

Built on **large language models (LLMs)**, Pxplore dynamically constructs learner profiles, plans optimal content paths, and adapts teaching delivery to cognitive levels and learning styles â€” forming a closed pedagogical feedback loop between **profiling â†’ planning â†’ delivery â†’ evaluation**.


## Key Features

| Module                        | Description                                                                                        |
| ----------------------------- | -------------------------------------------------------------------------------------------------- |
| ðŸ§  **Learner Profiling**      | Extracts cognitive and linguistic signals from student discussions, quizzes, and activity logs.    |
| ðŸ“– **Learning Path Planning** | Combines hybrid retrieval and policy optimization to recommend fine-grained content snippets.      |
| ðŸŽ¨ **Adaptive Delivery**      | Transforms recommended content into personalized instructional scripts using LLM-based adaptation. |
| ðŸ’¬ **Session Management**     | Maintains conversational continuity, progress tracking, and contextual response generation.        |


## System Architecture

```
Pxplore/
â”œâ”€ app.py                 # Application entry point
â”œâ”€ config.py              # Environment configuration
â”œâ”€ base.py                # Core data model definitions
â”œâ”€ requirements.txt       # Dependency list
â”œâ”€ data/                  # Data structure definitions
â”‚   â”œâ”€ profile.py         # Learner profile schema
â”‚   â”œâ”€ session.py         # Session model
â”‚   â”œâ”€ snippet.py         # Learning content unit
â”‚   â””â”€ task.py            # Task and pipeline orchestration
â”œâ”€ dataset/               # Dataset preparation scripts
â”‚   â”œâ”€ gen_label.py
â”‚   â”œâ”€ import_data.py
â”‚   â”œâ”€ parse_snippets.py
â”‚   â””â”€ prompts/
â”œâ”€ model/                 # Training and evaluation modules
â”‚   â”œâ”€ calculate_reward.py
â”‚   â”œâ”€ data_preprocessing.py
â”‚   â”œâ”€ evaluation.py
â”‚   â”œâ”€ prepare_data.py
â”‚   â”œâ”€ prompts/
â”‚   â””â”€ test/
â””â”€ service/
    â”œâ”€ llm/               # LLM service integration
    â”œâ”€ scripts/
    â”‚   â”œâ”€ hybrid_retriever.py
    â”‚   â”œâ”€ snippet_recommender.py
    â”‚   â”œâ”€ student_profiling.py
    â”‚   â”œâ”€ style_adaptation.py
    â”‚   â””â”€ session_controller.py
    â”œâ”€ utils/
    â”‚   â”œâ”€ dense_embedding.py
    â”‚   â”œâ”€ data_transformer.py
    â”‚   â””â”€ episodes_processor.py
    â””â”€ test/
```

## ðŸš€ Getting Started

### Prerequisites

* Python **3.12+**
* **FastAPI**
* LLM provider (OpenAI GPT / Qwen / compatible APIs)
* *(Optional)* [Qdrant](https://qdrant.tech/) vector database for dense retrieval

### Installation

```bash
git clone https://github.com/Pxplore/pxplore-algo.git
cd pxplore-algo
pip install -r requirements.txt
```

### Configuration

Update `config.py` with your LLM API credentials and model settings.

### Run the Service

```bash
python -m app
```

Server starts at: [http://localhost:8899](http://localhost:8899)

---

## API Reference

### Learner Profiling

```http
POST /student_profile
Content-Type: application/json
{
  "behavioral_data": {
    "discussion_threads": [...],
    "page_interactions": [...],
    "review_loops": [...],
    "quizzes": [...]
  }
}
```

### Learning Path Planning

```http
POST /plan
{
  "student_profile": {...},
  "interaction_history": "previous context",
  "title": "current topic",
  "model": "model_id"
}
```

### Adaptive Delivery

```http
POST /style_adapt
{
  "student_profile": {...},
  "history_content": "...",
  "title": "current topic",
  "recommend_id": "snippet_id",
  "recommend_reason": "reason"
}
```


## Core Algorithms

### Hybrid Retrieval

Balances dense and sparse representations for optimal recall:

```math
HybridScore = Î± Ã— BM25 + (1 âˆ’ Î±) Ã— DenseSim
```

### Learner Cognitive Modeling

* Follows **Bloomâ€™s Taxonomy** (Knowledge â†’ Understanding â†’ Application â†’ Analysis â†’ Synthesis â†’ Evaluation)
* Tracks cognitive evolution with **adaptive window analysis** and **trend regression**

### Policy Optimization

Employs **Group Relative Policy Optimization (GRPO)** guided by a **pedagogical reward function**, enabling reinforcement-based adaptation toward learnersâ€™ long-term developmental goals.


## Data Schemas

### Example â€” Learner Behavior Data

```json
{
  "discussion_threads": [
    {
      "thread_id": "thread_001",
      "messages": [
        {"author_type": "student", "content": "I think...", "timestamp": "2025-05-21T10:00:00Z"}
      ]
    }
  ],
  "page_interactions": [...],
  "review_loops": [...],
  "quizzes": [...]
}
```

### Example â€” Recommendation Output

```json
{
  "selected_candidate": {
    "id": "snippet_002",
    "bloom_level": "analysis",
    "summary": "Explains reinforcement learning adaptation.",
    "content": "..."
  },
  "reason": "Aligned with learnerâ€™s current cognitive stage."
}
```

---

## ðŸ“® Citation

If you find our work helpful, please cite:

```bibtex
[coming soon]
```